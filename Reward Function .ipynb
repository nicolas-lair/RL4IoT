{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:51:50.554855Z",
     "start_time": "2020-09-02T14:51:50.538382Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T15:04:31.022350Z",
     "start_time": "2020-09-02T15:04:30.173200Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'src/')\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import joblib\n",
    "from torch import nn \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from reward_evaluation import RewardComparision\n",
    "from architecture.reward import StateDataset, EpisodeDataset, ImbalancedDatasetSampler, RewardModel\n",
    "from architecture.language_model import LanguageModel\n",
    "from simulator.description_embedder import Description_embedder\n",
    "from simulator.Environment import preprocess_raw_observation\n",
    "from simulator.Items import ITEM_TYPE\n",
    "from config import generate_params\n",
    "\n",
    "params = generate_params(save_path=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:52:00.673725Z",
     "start_time": "2020-09-02T14:52:00.642854Z"
    }
   },
   "outputs": [],
   "source": [
    "# EpisodeRecord = namedtuple('EpisodeRecord', ('initial_state', 'final_state', 'instruction', 'reward'))\n",
    "# episode_path = 'results/episodes_records.jbl'\n",
    "# episodes = joblib.load(episode_path)\n",
    "\n",
    "StateRecord = namedtuple('StateRecord', ('state', 'instruction', 'reward'))\n",
    "EpisodeRecord = namedtuple('EpisodeRecord', ('initial_state', 'final_state', 'instruction', 'reward'))\n",
    "\n",
    "state_path = 'results/state_records3.jbl'\n",
    "train_episode = 'results/episodes_records4.jbl'\n",
    "test_episode = 'results/episodes_records3.jbl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:52:32.856442Z",
     "start_time": "2020-09-02T14:52:01.586886Z"
    }
   },
   "outputs": [],
   "source": [
    "description_embedder = Description_embedder(**params['env_params']['description_embedder_params'])\n",
    "\n",
    "item_type_embedder = OneHotEncoder(sparse=False)\n",
    "item_type_embedder.fit(np.array(ITEM_TYPE).reshape(-1, 1))\n",
    "\n",
    "from functools import partial\n",
    "transformer = partial(preprocess_raw_observation, description_embedder=description_embedder, item_type_embedder=item_type_embedder, raw_state_size=3, \n",
    "                      pytorch=True, device=params['device'])\n",
    "\n",
    "\n",
    "# dts = StateDataset.from_files(state_path, raw_state_transformer=transformer, max_size=5000)\n",
    "# dts = EpisodeDataset.from_files(episode_path, raw_state_transformer=transformer)\n",
    "# dts_loader = DataLoader(dts, batch_size=len(dts))\n",
    "# train_dts, test_dts = dts.split(train_test_ratio = 0.85)\n",
    "\n",
    "train_dts = EpisodeDataset.from_files(train_episode, raw_state_transformer=transformer)\n",
    "test_dts = EpisodeDataset.from_files(test_episode, raw_state_transformer=transformer, max_size=5000)\n",
    "\n",
    "sampler = ImbalancedDatasetSampler(train_dts, num_samples=20000, pos_weight=0.2)\n",
    "# train_loader = DataLoader(dataset=train_dts, sampler=sampler, batch_size=128)\n",
    "test_loader = DataLoader(test_dts, batch_size=len(test_dts))\n",
    "test_batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T17:24:38.000931Z",
     "start_time": "2020-08-28T17:24:37.957588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>%pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>You increased the luminosity of first light bulb</th>\n",
       "      <td>4995</td>\n",
       "      <td>8603</td>\n",
       "      <td>0.367333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first plug</th>\n",
       "      <td>4905</td>\n",
       "      <td>8766</td>\n",
       "      <td>0.358789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb warmer</th>\n",
       "      <td>4292</td>\n",
       "      <td>8980</td>\n",
       "      <td>0.323388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to orange</th>\n",
       "      <td>247</td>\n",
       "      <td>9818</td>\n",
       "      <td>0.024540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now average</th>\n",
       "      <td>473</td>\n",
       "      <td>9816</td>\n",
       "      <td>0.045971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to purple</th>\n",
       "      <td>217</td>\n",
       "      <td>10073</td>\n",
       "      <td>0.021088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You decreased the luminosity of first light bulb</th>\n",
       "      <td>2047</td>\n",
       "      <td>9516</td>\n",
       "      <td>0.177030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now high</th>\n",
       "      <td>2070</td>\n",
       "      <td>9527</td>\n",
       "      <td>0.178494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now low</th>\n",
       "      <td>440</td>\n",
       "      <td>9958</td>\n",
       "      <td>0.042316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb colder</th>\n",
       "      <td>4356</td>\n",
       "      <td>8881</td>\n",
       "      <td>0.329078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to red</th>\n",
       "      <td>235</td>\n",
       "      <td>9989</td>\n",
       "      <td>0.022985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to green</th>\n",
       "      <td>178</td>\n",
       "      <td>10057</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first light bulb</th>\n",
       "      <td>3406</td>\n",
       "      <td>9168</td>\n",
       "      <td>0.270876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to blue</th>\n",
       "      <td>188</td>\n",
       "      <td>9980</td>\n",
       "      <td>0.018489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first plug</th>\n",
       "      <td>5074</td>\n",
       "      <td>8784</td>\n",
       "      <td>0.366142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to yellow</th>\n",
       "      <td>232</td>\n",
       "      <td>9938</td>\n",
       "      <td>0.022812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very low</th>\n",
       "      <td>850</td>\n",
       "      <td>9785</td>\n",
       "      <td>0.079925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very high</th>\n",
       "      <td>1231</td>\n",
       "      <td>9622</td>\n",
       "      <td>0.113425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to pink</th>\n",
       "      <td>218</td>\n",
       "      <td>9798</td>\n",
       "      <td>0.021765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first light bulb</th>\n",
       "      <td>878</td>\n",
       "      <td>9896</td>\n",
       "      <td>0.081492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>36532</td>\n",
       "      <td>190955</td>\n",
       "      <td>0.160589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      pos     neg      %pos\n",
       "You increased the luminosity of first light bulb     4995    8603  0.367333\n",
       "You turned off the first plug                        4905    8766  0.358789\n",
       "You made the light of first light bulb warmer        4292    8980  0.323388\n",
       "You set the color of first light bulb to orange       247    9818  0.024540\n",
       "The luminosity of first light bulb is now average     473    9816  0.045971\n",
       "You set the color of first light bulb to purple       217   10073  0.021088\n",
       "You decreased the luminosity of first light bulb     2047    9516  0.177030\n",
       "The luminosity of first light bulb is now high       2070    9527  0.178494\n",
       "The luminosity of first light bulb is now low         440    9958  0.042316\n",
       "You made the light of first light bulb colder        4356    8881  0.329078\n",
       "You set the color of first light bulb to red          235    9989  0.022985\n",
       "You set the color of first light bulb to green        178   10057  0.017391\n",
       "You turned on the first light bulb                   3406    9168  0.270876\n",
       "You set the color of first light bulb to blue         188    9980  0.018489\n",
       "You turned on the first plug                         5074    8784  0.366142\n",
       "You set the color of first light bulb to yellow       232    9938  0.022812\n",
       "The luminosity of first light bulb is now very low    850    9785  0.079925\n",
       "The luminosity of first light bulb is now very ...   1231    9622  0.113425\n",
       "You set the color of first light bulb to pink         218    9798  0.021765\n",
       "You turned off the first light bulb                   878    9896  0.081492\n",
       "overall                                             36532  190955  0.160589"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_count = [len(v) for v in dts.positive_record.values()]\n",
    "negative_count = [len(v) for v in dts.negative_record.values()]\n",
    "df = pd.DataFrame([positive_count, negative_count]).T\n",
    "df.index = list(dts.positive_record)\n",
    "df.columns = columns = ['pos', 'neg']\n",
    "df_overall = pd.DataFrame(df.sum()).T\n",
    "df_overall.index = ['overall']\n",
    "df = pd.concat([df, df_overall])\n",
    "df['%pos'] = df.pos / (df.pos + df.neg)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T17:23:22.903049Z",
     "start_time": "2020-08-28T17:23:22.862477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>%pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>You increased the luminosity of first light bulb</th>\n",
       "      <td>4995.0</td>\n",
       "      <td>8603.0</td>\n",
       "      <td>0.367333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first plug</th>\n",
       "      <td>4905.0</td>\n",
       "      <td>8766.0</td>\n",
       "      <td>0.358789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb warmer</th>\n",
       "      <td>4292.0</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>0.323388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to orange</th>\n",
       "      <td>247.0</td>\n",
       "      <td>9818.0</td>\n",
       "      <td>0.024540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now average</th>\n",
       "      <td>473.0</td>\n",
       "      <td>9816.0</td>\n",
       "      <td>0.045971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to purple</th>\n",
       "      <td>217.0</td>\n",
       "      <td>10073.0</td>\n",
       "      <td>0.021088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You decreased the luminosity of first light bulb</th>\n",
       "      <td>2047.0</td>\n",
       "      <td>9516.0</td>\n",
       "      <td>0.177030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now high</th>\n",
       "      <td>2070.0</td>\n",
       "      <td>9527.0</td>\n",
       "      <td>0.178494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now low</th>\n",
       "      <td>440.0</td>\n",
       "      <td>9958.0</td>\n",
       "      <td>0.042316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb colder</th>\n",
       "      <td>4356.0</td>\n",
       "      <td>8881.0</td>\n",
       "      <td>0.329078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to red</th>\n",
       "      <td>235.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>0.022985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to green</th>\n",
       "      <td>178.0</td>\n",
       "      <td>10057.0</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first light bulb</th>\n",
       "      <td>3406.0</td>\n",
       "      <td>9168.0</td>\n",
       "      <td>0.270876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to blue</th>\n",
       "      <td>188.0</td>\n",
       "      <td>9980.0</td>\n",
       "      <td>0.018489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first plug</th>\n",
       "      <td>5074.0</td>\n",
       "      <td>8784.0</td>\n",
       "      <td>0.366142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to yellow</th>\n",
       "      <td>232.0</td>\n",
       "      <td>9938.0</td>\n",
       "      <td>0.022812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very low</th>\n",
       "      <td>850.0</td>\n",
       "      <td>9785.0</td>\n",
       "      <td>0.079925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very high</th>\n",
       "      <td>1231.0</td>\n",
       "      <td>9622.0</td>\n",
       "      <td>0.113425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to pink</th>\n",
       "      <td>218.0</td>\n",
       "      <td>9798.0</td>\n",
       "      <td>0.021765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first light bulb</th>\n",
       "      <td>878.0</td>\n",
       "      <td>9896.0</td>\n",
       "      <td>0.081492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36532.0</td>\n",
       "      <td>190955.0</td>\n",
       "      <td>2.883332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        pos       neg  \\\n",
       "You increased the luminosity of first light bulb     4995.0    8603.0   \n",
       "You turned off the first plug                        4905.0    8766.0   \n",
       "You made the light of first light bulb warmer        4292.0    8980.0   \n",
       "You set the color of first light bulb to orange       247.0    9818.0   \n",
       "The luminosity of first light bulb is now average     473.0    9816.0   \n",
       "You set the color of first light bulb to purple       217.0   10073.0   \n",
       "You decreased the luminosity of first light bulb     2047.0    9516.0   \n",
       "The luminosity of first light bulb is now high       2070.0    9527.0   \n",
       "The luminosity of first light bulb is now low         440.0    9958.0   \n",
       "You made the light of first light bulb colder        4356.0    8881.0   \n",
       "You set the color of first light bulb to red          235.0    9989.0   \n",
       "You set the color of first light bulb to green        178.0   10057.0   \n",
       "You turned on the first light bulb                   3406.0    9168.0   \n",
       "You set the color of first light bulb to blue         188.0    9980.0   \n",
       "You turned on the first plug                         5074.0    8784.0   \n",
       "You set the color of first light bulb to yellow       232.0    9938.0   \n",
       "The luminosity of first light bulb is now very low    850.0    9785.0   \n",
       "The luminosity of first light bulb is now very ...   1231.0    9622.0   \n",
       "You set the color of first light bulb to pink         218.0    9798.0   \n",
       "You turned off the first light bulb                   878.0    9896.0   \n",
       "0                                                   36532.0  190955.0   \n",
       "\n",
       "                                                        %pos  \n",
       "You increased the luminosity of first light bulb    0.367333  \n",
       "You turned off the first plug                       0.358789  \n",
       "You made the light of first light bulb warmer       0.323388  \n",
       "You set the color of first light bulb to orange     0.024540  \n",
       "The luminosity of first light bulb is now average   0.045971  \n",
       "You set the color of first light bulb to purple     0.021088  \n",
       "You decreased the luminosity of first light bulb    0.177030  \n",
       "The luminosity of first light bulb is now high      0.178494  \n",
       "The luminosity of first light bulb is now low       0.042316  \n",
       "You made the light of first light bulb colder       0.329078  \n",
       "You set the color of first light bulb to red        0.022985  \n",
       "You set the color of first light bulb to green      0.017391  \n",
       "You turned on the first light bulb                  0.270876  \n",
       "You set the color of first light bulb to blue       0.018489  \n",
       "You turned on the first plug                        0.366142  \n",
       "You set the color of first light bulb to yellow     0.022812  \n",
       "The luminosity of first light bulb is now very low  0.079925  \n",
       "The luminosity of first light bulb is now very ...  0.113425  \n",
       "You set the color of first light bulb to pink       0.021765  \n",
       "You turned off the first light bulb                 0.081492  \n",
       "0                                                   2.883332  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overall = pd.DataFrame(df.sum()).T\n",
    "df.index = ['overall']\n",
    "pd.concat([df, pd.DataFrame(df.sum()).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T09:16:53.501536Z",
     "start_time": "2020-09-01T09:16:50.778155Z"
    }
   },
   "outputs": [],
   "source": [
    "language_model = LanguageModel(**params['language_model_params'])\n",
    "reward_function = LearnedReward(context_model=params['model_params']['context_model'], language_model=language_model, reward_params=params['reward_model_params'])\n",
    "reward_function.to(params['device'])\n",
    "\n",
    "from torch import optim\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = optim.Adam(reward_function.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T12:58:26.607793Z",
     "start_time": "2020-09-01T12:10:39.050394Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95bbcb6cd5545c19b435d8c65d61a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 0.05711089447140694\n",
      "0 1 loss: 0.0653453916311264\n",
      "0 2 loss: 0.061978090554475784\n",
      "0 3 loss: 0.053842462599277496\n",
      "0 4 loss: 0.074861079454422\n",
      "0 5 loss: 0.07310312986373901\n",
      "0 6 loss: 0.0656624585390091\n",
      "0 7 loss: 0.08667128533124924\n",
      "0 8 loss: 0.07506480067968369\n",
      "0 9 loss: 0.1087091863155365\n",
      "0 10 loss: 0.038395702838897705\n",
      "0 11 loss: 0.04237275943160057\n",
      "0 12 loss: 0.04104701429605484\n",
      "0 13 loss: 0.07748584449291229\n",
      "0 14 loss: 0.07600108534097672\n",
      "0 15 loss: 0.1359160989522934\n",
      "0 16 loss: 0.053344376385211945\n",
      "0 17 loss: 0.04987293854355812\n",
      "0 18 loss: 0.07306171953678131\n",
      "0 19 loss: 0.064381904900074\n",
      "0 20 loss: 0.05508366972208023\n",
      "0 21 loss: 0.10977333039045334\n",
      "0 22 loss: 0.056368082761764526\n",
      "0 23 loss: 0.04375394433736801\n",
      "0 24 loss: 0.04222206771373749\n",
      "0 25 loss: 0.031051531434059143\n",
      "0 26 loss: 0.0839010626077652\n",
      "0 27 loss: 0.06733690202236176\n",
      "0 28 loss: 0.07599324733018875\n",
      "0 29 loss: 0.06937453150749207\n",
      "0 30 loss: 0.07159052789211273\n",
      "0 31 loss: 0.057998619973659515\n",
      "0 32 loss: 0.03595270216464996\n",
      "0 33 loss: 0.07779665291309357\n",
      "0 34 loss: 0.07907260209321976\n",
      "0 35 loss: 0.03191104158759117\n",
      "0 36 loss: 0.028607219457626343\n",
      "0 37 loss: 0.010440594516694546\n",
      "0 38 loss: 0.0378754660487175\n",
      "0 39 loss: 0.06906694173812866\n",
      "0 40 loss: 0.045318059623241425\n",
      "0 41 loss: 0.06628718972206116\n",
      "0 42 loss: 0.10147949308156967\n",
      "0 43 loss: 0.03215913847088814\n",
      "0 44 loss: 0.03243127465248108\n",
      "0 45 loss: 0.09827975928783417\n",
      "0 46 loss: 0.024802878499031067\n",
      "0 47 loss: 0.03167916089296341\n",
      "0 48 loss: 0.029630539938807487\n",
      "0 49 loss: 0.03611946478486061\n",
      "0 50 loss: 0.06278256326913834\n",
      "0 51 loss: 0.0753004252910614\n",
      "0 52 loss: 0.07849644869565964\n",
      "0 53 loss: 0.039816226810216904\n",
      "0 54 loss: 0.05631844699382782\n",
      "0 55 loss: 0.051425427198410034\n",
      "0 56 loss: 0.023512104526162148\n",
      "0 57 loss: 0.055132146924734116\n",
      "0 58 loss: 0.09369738399982452\n",
      "0 59 loss: 0.07882295548915863\n",
      "0 60 loss: 0.05677516758441925\n",
      "0 61 loss: 0.0347428061068058\n",
      "0 62 loss: 0.034745119512081146\n",
      "0 63 loss: 0.03072863072156906\n",
      "0 64 loss: 0.05897504836320877\n",
      "0 65 loss: 0.035469941794872284\n",
      "0 66 loss: 0.05779623985290527\n",
      "0 67 loss: 0.08001264929771423\n",
      "0 68 loss: 0.06170827895402908\n",
      "0 69 loss: 0.01691615954041481\n",
      "0 70 loss: 0.07212868332862854\n",
      "0 71 loss: 0.038768842816352844\n",
      "0 72 loss: 0.08532314747571945\n",
      "0 73 loss: 0.10346023738384247\n",
      "0 74 loss: 0.06986840069293976\n",
      "0 75 loss: 0.04974285513162613\n",
      "0 76 loss: 0.09304869920015335\n",
      "0 77 loss: 0.048480261117219925\n",
      "0 78 loss: 0.07087154686450958\n",
      "0 79 loss: 0.0723671093583107\n",
      "0 80 loss: 0.06394073367118835\n",
      "0 81 loss: 0.05235328525304794\n",
      "0 82 loss: 0.03644312173128128\n",
      "0 83 loss: 0.03083658404648304\n",
      "0 84 loss: 0.020208794623613358\n",
      "0 85 loss: 0.05163681507110596\n",
      "0 86 loss: 0.08432194590568542\n",
      "0 87 loss: 0.06388479471206665\n",
      "0 88 loss: 0.0494452603161335\n",
      "0 89 loss: 0.05391246825456619\n",
      "0 90 loss: 0.03379769250750542\n",
      "0 91 loss: 0.08848202973604202\n",
      "0 92 loss: 0.03456128388643265\n",
      "0 93 loss: 0.06879232078790665\n",
      "0 94 loss: 0.061069734394550323\n",
      "0 95 loss: 0.05168883502483368\n",
      "0 96 loss: 0.048068106174468994\n",
      "0 97 loss: 0.02001260593533516\n",
      "0 98 loss: 0.050078023225069046\n",
      "0 99 loss: 0.05846952646970749\n",
      "0 100 loss: 0.011673910543322563\n",
      "0 101 loss: 0.025349464267492294\n",
      "0 102 loss: 0.06941615045070648\n",
      "0 103 loss: 0.03276997432112694\n",
      "0 104 loss: 0.05730106681585312\n",
      "0 105 loss: 0.03155023977160454\n",
      "0 106 loss: 0.05343674123287201\n",
      "0 107 loss: 0.031084420159459114\n",
      "0 108 loss: 0.06881095468997955\n",
      "0 109 loss: 0.061961300671100616\n",
      "0 110 loss: 0.021634530276060104\n",
      "0 111 loss: 0.04533550888299942\n",
      "0 112 loss: 0.021902257576584816\n",
      "0 113 loss: 0.07133916765451431\n",
      "0 114 loss: 0.04024428874254227\n",
      "0 115 loss: 0.03545926511287689\n",
      "0 116 loss: 0.059215642511844635\n",
      "0 117 loss: 0.016710083931684494\n",
      "0 118 loss: 0.07327369600534439\n",
      "0 119 loss: 0.04184645786881447\n",
      "0 120 loss: 0.020501067861914635\n",
      "0 121 loss: 0.06485804915428162\n",
      "0 122 loss: 0.02534697763621807\n",
      "0 123 loss: 0.11894070357084274\n",
      "0 124 loss: 0.02822985127568245\n",
      "0 125 loss: 0.05809929594397545\n",
      "0 126 loss: 0.0802251324057579\n",
      "0 127 loss: 0.05027451738715172\n",
      "0 128 loss: 0.03650575876235962\n",
      "0 129 loss: 0.10086236894130707\n",
      "0 130 loss: 0.021996937692165375\n",
      "0 131 loss: 0.08428944647312164\n",
      "0 132 loss: 0.02073003351688385\n",
      "0 133 loss: 0.020012784749269485\n",
      "0 134 loss: 0.02311522513628006\n",
      "0 135 loss: 0.034687213599681854\n",
      "0 136 loss: 0.014570015482604504\n",
      "0 137 loss: 0.02727663144469261\n",
      "0 138 loss: 0.028237689286470413\n",
      "0 139 loss: 0.060404323041439056\n",
      "0 140 loss: 0.04126449301838875\n",
      "0 141 loss: 0.04068024456501007\n",
      "0 142 loss: 0.06909135729074478\n",
      "0 143 loss: 0.1308314949274063\n",
      "0 144 loss: 0.04408314451575279\n",
      "0 145 loss: 0.018356692045927048\n",
      "0 146 loss: 0.05394884943962097\n",
      "0 147 loss: 0.010929422453045845\n",
      "0 148 loss: 0.06151995807886124\n",
      "0 149 loss: 0.028731083497405052\n",
      "0 150 loss: 0.0398017093539238\n",
      "0 151 loss: 0.029882419854402542\n",
      "0 152 loss: 0.11723527312278748\n",
      "0 153 loss: 0.013133436441421509\n",
      "0 154 loss: 0.04385508969426155\n",
      "0 155 loss: 0.011196877807378769\n",
      "0 156 loss: 0.04412289708852768\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d902805c8f4ec0a63d613f3fd38281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 loss: 0.09296280145645142\n",
      "1 1 loss: 0.08203186094760895\n",
      "1 2 loss: 0.024309052154421806\n",
      "1 3 loss: 0.0258091501891613\n",
      "1 4 loss: 0.06984315067529678\n",
      "1 5 loss: 0.07733271270990372\n",
      "1 6 loss: 0.0597383975982666\n",
      "1 7 loss: 0.09382972121238708\n",
      "1 8 loss: 0.12280167639255524\n",
      "1 9 loss: 0.014874305576086044\n",
      "1 10 loss: 0.10073670744895935\n",
      "1 11 loss: 0.015416206791996956\n",
      "1 12 loss: 0.058806151151657104\n",
      "1 13 loss: 0.06679844856262207\n",
      "1 14 loss: 0.07519792020320892\n",
      "1 15 loss: 0.0751529112458229\n",
      "1 16 loss: 0.05818849056959152\n",
      "1 17 loss: 0.07148868590593338\n",
      "1 18 loss: 0.12956681847572327\n",
      "1 19 loss: 0.06178022921085358\n",
      "1 20 loss: 0.024018920958042145\n",
      "1 21 loss: 0.053804103285074234\n",
      "1 22 loss: 0.03466997295618057\n",
      "1 23 loss: 0.02485303208231926\n",
      "1 24 loss: 0.028028912842273712\n",
      "1 25 loss: 0.04680359736084938\n",
      "1 26 loss: 0.06093886122107506\n",
      "1 27 loss: 0.06623439490795135\n",
      "1 28 loss: 0.06572945415973663\n",
      "1 29 loss: 0.04558172821998596\n",
      "1 30 loss: 0.01725270226597786\n",
      "1 31 loss: 0.03375369310379028\n",
      "1 32 loss: 0.04659157246351242\n",
      "1 33 loss: 0.14924094080924988\n",
      "1 34 loss: 0.08724310994148254\n",
      "1 35 loss: 0.02748267352581024\n",
      "1 36 loss: 0.0448930487036705\n",
      "1 37 loss: 0.015165075659751892\n",
      "1 38 loss: 0.07411299645900726\n",
      "1 39 loss: 0.0210343599319458\n",
      "1 40 loss: 0.047127217054367065\n",
      "1 41 loss: 0.0826951265335083\n",
      "1 42 loss: 0.040700532495975494\n",
      "1 43 loss: 0.03994252532720566\n",
      "1 44 loss: 0.02895757183432579\n",
      "1 45 loss: 0.04131942242383957\n",
      "1 46 loss: 0.08187678456306458\n",
      "1 47 loss: 0.04590339958667755\n",
      "1 48 loss: 0.04483941197395325\n",
      "1 49 loss: 0.02439635992050171\n",
      "1 50 loss: 0.06787619739770889\n",
      "1 51 loss: 0.06810176372528076\n",
      "1 52 loss: 0.05614900216460228\n",
      "1 53 loss: 0.008068535476922989\n",
      "1 54 loss: 0.11957763135433197\n",
      "1 55 loss: 0.053961463272571564\n",
      "1 56 loss: 0.022478371858596802\n",
      "1 57 loss: 0.056815292686223984\n",
      "1 58 loss: 0.08557437360286713\n",
      "1 59 loss: 0.07719174772500992\n",
      "1 60 loss: 0.0573120042681694\n",
      "1 61 loss: 0.03432370722293854\n",
      "1 62 loss: 0.0670040026307106\n",
      "1 63 loss: 0.044549308717250824\n",
      "1 64 loss: 0.04026050865650177\n",
      "1 65 loss: 0.09406211972236633\n",
      "1 66 loss: 0.022744543850421906\n",
      "1 67 loss: 0.0709645226597786\n",
      "1 68 loss: 0.023946985602378845\n",
      "1 69 loss: 0.06087411195039749\n",
      "1 70 loss: 0.042719729244709015\n",
      "1 71 loss: 0.020906906574964523\n",
      "1 72 loss: 0.02866809442639351\n",
      "1 73 loss: 0.06278032064437866\n",
      "1 74 loss: 0.05983685702085495\n",
      "1 75 loss: 0.05758901685476303\n",
      "1 76 loss: 0.03536015376448631\n",
      "1 77 loss: 0.16407912969589233\n",
      "1 78 loss: 0.05030248314142227\n",
      "1 79 loss: 0.07297971844673157\n",
      "1 80 loss: 0.03410111740231514\n",
      "1 81 loss: 0.01640959084033966\n",
      "1 82 loss: 0.044510290026664734\n",
      "1 83 loss: 0.018430016934871674\n",
      "1 84 loss: 0.06928229331970215\n",
      "1 85 loss: 0.09386615455150604\n",
      "1 86 loss: 0.03009883314371109\n",
      "1 87 loss: 0.042032189667224884\n",
      "1 88 loss: 0.03727074712514877\n",
      "1 89 loss: 0.013730821199715137\n",
      "1 90 loss: 0.031922418624162674\n",
      "1 91 loss: 0.03091539815068245\n",
      "1 92 loss: 0.07571877539157867\n",
      "1 93 loss: 0.06283688545227051\n",
      "1 94 loss: 0.05879209190607071\n",
      "1 95 loss: 0.019850846379995346\n",
      "1 96 loss: 0.09012351930141449\n",
      "1 97 loss: 0.18942508101463318\n",
      "1 98 loss: 0.029164355248212814\n",
      "1 99 loss: 0.0251226294785738\n",
      "1 100 loss: 0.028420768678188324\n",
      "1 101 loss: 0.05934823304414749\n",
      "1 102 loss: 0.03156641870737076\n",
      "1 103 loss: 0.03530505299568176\n",
      "1 104 loss: 0.03438050299882889\n",
      "1 105 loss: 0.040553636848926544\n",
      "1 106 loss: 0.07372190058231354\n",
      "1 107 loss: 0.045956481248140335\n",
      "1 108 loss: 0.03961518779397011\n",
      "1 109 loss: 0.04255523532629013\n",
      "1 110 loss: 0.02064201794564724\n",
      "1 111 loss: 0.03906341642141342\n",
      "1 112 loss: 0.04174010455608368\n",
      "1 113 loss: 0.011290760710835457\n",
      "1 114 loss: 0.040860310196876526\n",
      "1 115 loss: 0.05330333858728409\n",
      "1 116 loss: 0.045054659247398376\n",
      "1 117 loss: 0.01922745443880558\n",
      "1 118 loss: 0.02429976314306259\n",
      "1 119 loss: 0.06870950758457184\n",
      "1 120 loss: 0.018027616664767265\n",
      "1 121 loss: 0.048188790678977966\n",
      "1 122 loss: 0.009522108361124992\n",
      "1 123 loss: 0.023500356823205948\n",
      "1 124 loss: 0.021891996264457703\n",
      "1 125 loss: 0.03018791601061821\n",
      "1 126 loss: 0.027277721092104912\n",
      "1 127 loss: 0.0388309620320797\n",
      "1 128 loss: 0.04500575363636017\n",
      "1 129 loss: 0.04383520781993866\n",
      "1 130 loss: 0.01887650042772293\n",
      "1 131 loss: 0.01838642917573452\n",
      "1 132 loss: 0.016042079776525497\n",
      "1 133 loss: 0.0574653297662735\n",
      "1 134 loss: 0.06416169553995132\n",
      "1 135 loss: 0.038948141038417816\n",
      "1 136 loss: 0.026414580643177032\n",
      "1 137 loss: 0.046982087194919586\n",
      "1 138 loss: 0.07830511778593063\n",
      "1 139 loss: 0.022509757429361343\n",
      "1 140 loss: 0.07384306192398071\n",
      "1 141 loss: 0.058316320180892944\n",
      "1 142 loss: 0.08797510713338852\n",
      "1 143 loss: 0.09262531250715256\n",
      "1 144 loss: 0.06940650939941406\n",
      "1 145 loss: 0.03830721974372864\n",
      "1 146 loss: 0.06977706402540207\n",
      "1 147 loss: 0.04132929444313049\n",
      "1 148 loss: 0.04009024798870087\n",
      "1 149 loss: 0.03276665508747101\n",
      "1 150 loss: 0.044972196221351624\n",
      "1 151 loss: 0.021962611004710197\n",
      "1 152 loss: 0.04234451428055763\n",
      "1 153 loss: 0.015107657760381699\n",
      "1 154 loss: 0.026845764368772507\n",
      "1 155 loss: 0.04243515804409981\n",
      "1 156 loss: 0.014171889051795006\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76e306b74b64f078d935f4e8245d25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0 loss: 0.03337174654006958\n",
      "2 1 loss: 0.04682227596640587\n",
      "2 2 loss: 0.03618162125349045\n",
      "2 3 loss: 0.032740119844675064\n",
      "2 4 loss: 0.04480356350541115\n",
      "2 5 loss: 0.042017433792352676\n",
      "2 6 loss: 0.041028186678886414\n",
      "2 7 loss: 0.03448895364999771\n",
      "2 8 loss: 0.04038792848587036\n",
      "2 9 loss: 0.017448697239160538\n",
      "2 10 loss: 0.04377584159374237\n",
      "2 11 loss: 0.04479197412729263\n",
      "2 12 loss: 0.019688330590724945\n",
      "2 13 loss: 0.0472196526825428\n",
      "2 14 loss: 0.061010461300611496\n",
      "2 15 loss: 0.03218396008014679\n",
      "2 16 loss: 0.034729816019535065\n",
      "2 17 loss: 0.00994601659476757\n",
      "2 18 loss: 0.06617330014705658\n",
      "2 19 loss: 0.04089813306927681\n",
      "2 20 loss: 0.03483204171061516\n",
      "2 21 loss: 0.06146489828824997\n",
      "2 22 loss: 0.06752562522888184\n",
      "2 23 loss: 0.045651137828826904\n",
      "2 24 loss: 0.050140395760536194\n",
      "2 25 loss: 0.030463771894574165\n",
      "2 26 loss: 0.04521387815475464\n",
      "2 27 loss: 0.07195288687944412\n",
      "2 28 loss: 0.06800715625286102\n",
      "2 29 loss: 0.07367274165153503\n",
      "2 30 loss: 0.04514716938138008\n",
      "2 31 loss: 0.046817611902952194\n",
      "2 32 loss: 0.058421291410923004\n",
      "2 33 loss: 0.0261383093893528\n",
      "2 34 loss: 0.027569489553570747\n",
      "2 35 loss: 0.036438897252082825\n",
      "2 36 loss: 0.015977052971720695\n",
      "2 37 loss: 0.04641135036945343\n",
      "2 38 loss: 0.03326763957738876\n",
      "2 39 loss: 0.052094101905822754\n",
      "2 40 loss: 0.025601930916309357\n",
      "2 41 loss: 0.028774429112672806\n",
      "2 42 loss: 0.00820594560354948\n",
      "2 43 loss: 0.04115276783704758\n",
      "2 44 loss: 0.012816364876925945\n",
      "2 45 loss: 0.029358219355344772\n",
      "2 46 loss: 0.009335728362202644\n",
      "2 47 loss: 0.05563335865736008\n",
      "2 48 loss: 0.022574758157134056\n",
      "2 49 loss: 0.017577240243554115\n",
      "2 50 loss: 0.12274692952632904\n",
      "2 51 loss: 0.02081712707877159\n",
      "2 52 loss: 0.02314089983701706\n",
      "2 53 loss: 0.03961874544620514\n",
      "2 54 loss: 0.038596417754888535\n",
      "2 55 loss: 0.019321825355291367\n",
      "2 56 loss: 0.01799478940665722\n",
      "2 57 loss: 0.01881691999733448\n",
      "2 58 loss: 0.01222786121070385\n",
      "2 59 loss: 0.04226352646946907\n",
      "2 60 loss: 0.037376709282398224\n",
      "2 61 loss: 0.03136860951781273\n",
      "2 62 loss: 0.08752866089344025\n",
      "2 63 loss: 0.04798570275306702\n",
      "2 64 loss: 0.03440261632204056\n",
      "2 65 loss: 0.11272848397493362\n",
      "2 66 loss: 0.08025992661714554\n",
      "2 67 loss: 0.07718207687139511\n",
      "2 68 loss: 0.038815468549728394\n",
      "2 69 loss: 0.02239801362156868\n",
      "2 70 loss: 0.05264947563409805\n",
      "2 71 loss: 0.05399905517697334\n",
      "2 72 loss: 0.052411604672670364\n",
      "2 73 loss: 0.06339318305253983\n",
      "2 74 loss: 0.07877866923809052\n",
      "2 75 loss: 0.041987910866737366\n",
      "2 76 loss: 0.08211294561624527\n",
      "2 77 loss: 0.06264446675777435\n",
      "2 78 loss: 0.03522193431854248\n",
      "2 79 loss: 0.037528157234191895\n",
      "2 80 loss: 0.0716758742928505\n",
      "2 81 loss: 0.06157517433166504\n",
      "2 82 loss: 0.017735455185174942\n",
      "2 83 loss: 0.030932653695344925\n",
      "2 84 loss: 0.06835418939590454\n",
      "2 85 loss: 0.04841016232967377\n",
      "2 86 loss: 0.028049400076270103\n",
      "2 87 loss: 0.024755481630563736\n",
      "2 88 loss: 0.02957085892558098\n",
      "2 89 loss: 0.034406110644340515\n",
      "2 90 loss: 0.0878620371222496\n",
      "2 91 loss: 0.028619632124900818\n",
      "2 92 loss: 0.05926420912146568\n",
      "2 93 loss: 0.03638176620006561\n",
      "2 94 loss: 0.034761056303977966\n",
      "2 95 loss: 0.03111829236149788\n",
      "2 96 loss: 0.030549027025699615\n",
      "2 97 loss: 0.01370438002049923\n",
      "2 98 loss: 0.06048167124390602\n",
      "2 99 loss: 0.07088764011859894\n",
      "2 100 loss: 0.028204312548041344\n",
      "2 101 loss: 0.04634013772010803\n",
      "2 102 loss: 0.023207934573292732\n",
      "2 103 loss: 0.0074758753180503845\n",
      "2 104 loss: 0.02098572999238968\n",
      "2 105 loss: 0.051540520042181015\n",
      "2 106 loss: 0.03340742737054825\n",
      "2 107 loss: 0.03319781273603439\n",
      "2 108 loss: 0.06447380781173706\n",
      "2 109 loss: 0.019309137016534805\n",
      "2 110 loss: 0.043827418237924576\n",
      "2 111 loss: 0.018725525587797165\n",
      "2 112 loss: 0.0348159484565258\n",
      "2 113 loss: 0.03142082691192627\n",
      "2 114 loss: 0.012551901862025261\n",
      "2 115 loss: 0.02106790617108345\n",
      "2 116 loss: 0.04325852915644646\n",
      "2 117 loss: 0.012880458496510983\n",
      "2 118 loss: 0.04127878695726395\n",
      "2 119 loss: 0.03359759598970413\n",
      "2 120 loss: 0.04095325246453285\n",
      "2 121 loss: 0.04784088581800461\n",
      "2 122 loss: 0.042473576962947845\n",
      "2 123 loss: 0.036306045949459076\n",
      "2 124 loss: 0.006496397778391838\n",
      "2 125 loss: 0.07073831558227539\n",
      "2 126 loss: 0.032928191125392914\n",
      "2 127 loss: 0.044165678322315216\n",
      "2 128 loss: 0.014815062284469604\n",
      "2 129 loss: 0.03006564825773239\n",
      "2 130 loss: 0.07919618487358093\n",
      "2 131 loss: 0.005973903462290764\n",
      "2 132 loss: 0.0043392544612288475\n",
      "2 133 loss: 0.044336915016174316\n",
      "2 134 loss: 0.011444779112935066\n",
      "2 135 loss: 0.034851014614105225\n",
      "2 136 loss: 0.01314978115260601\n",
      "2 137 loss: 0.049204930663108826\n",
      "2 138 loss: 0.012133272364735603\n",
      "2 139 loss: 0.09316346049308777\n",
      "2 140 loss: 0.1256101429462433\n",
      "2 141 loss: 0.037628188729286194\n",
      "2 142 loss: 0.08303094655275345\n",
      "2 143 loss: 0.024487966671586037\n",
      "2 144 loss: 0.03214091807603836\n",
      "2 145 loss: 0.0923914909362793\n",
      "2 146 loss: 0.04131545498967171\n",
      "2 147 loss: 0.04786060005426407\n",
      "2 148 loss: 0.0561491996049881\n",
      "2 149 loss: 0.028944537043571472\n",
      "2 150 loss: 0.030805112794041634\n",
      "2 151 loss: 0.0494389683008194\n",
      "2 152 loss: 0.03517322987318039\n",
      "2 153 loss: 0.024743642657995224\n",
      "2 154 loss: 0.025751236826181412\n",
      "2 155 loss: 0.08281907439231873\n",
      "2 156 loss: 0.012079478241503239\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818246b97d9b486e810e17a81892b001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0 loss: 0.08428271114826202\n",
      "3 1 loss: 0.027456112205982208\n",
      "3 2 loss: 0.09462219476699829\n",
      "3 3 loss: 0.01566447876393795\n",
      "3 4 loss: 0.04718851298093796\n",
      "3 5 loss: 0.027409913018345833\n",
      "3 6 loss: 0.08315487951040268\n",
      "3 7 loss: 0.05002908036112785\n",
      "3 8 loss: 0.04749758541584015\n",
      "3 9 loss: 0.06074657291173935\n",
      "3 10 loss: 0.05208876356482506\n",
      "3 11 loss: 0.007057345937937498\n",
      "3 12 loss: 0.04072653502225876\n",
      "3 13 loss: 0.016785304993391037\n",
      "3 14 loss: 0.02056990936398506\n",
      "3 15 loss: 0.03867800161242485\n",
      "3 16 loss: 0.015535256825387478\n",
      "3 17 loss: 0.04713313281536102\n",
      "3 18 loss: 0.009257483296096325\n",
      "3 19 loss: 0.03119269385933876\n",
      "3 20 loss: 0.013982422649860382\n",
      "3 21 loss: 0.09666761755943298\n",
      "3 22 loss: 0.015513461083173752\n",
      "3 23 loss: 0.030811738222837448\n",
      "3 24 loss: 0.05484171211719513\n",
      "3 25 loss: 0.014986051246523857\n",
      "3 26 loss: 0.02442403882741928\n",
      "3 27 loss: 0.015021842904388905\n",
      "3 28 loss: 0.017285803332924843\n",
      "3 29 loss: 0.06836239248514175\n",
      "3 30 loss: 0.02588675729930401\n",
      "3 31 loss: 0.0904235988855362\n",
      "3 32 loss: 0.01737772487103939\n",
      "3 33 loss: 0.03757442533969879\n",
      "3 34 loss: 0.033628884702920914\n",
      "3 35 loss: 0.035273514688014984\n",
      "3 36 loss: 0.014680217951536179\n",
      "3 37 loss: 0.02638126164674759\n",
      "3 38 loss: 0.035554975271224976\n",
      "3 39 loss: 0.02750128135085106\n",
      "3 40 loss: 0.03338387608528137\n",
      "3 41 loss: 0.017376098781824112\n",
      "3 42 loss: 0.031265243887901306\n",
      "3 43 loss: 0.0488462969660759\n",
      "3 44 loss: 0.0350094772875309\n",
      "3 45 loss: 0.013411186635494232\n",
      "3 46 loss: 0.0972742885351181\n",
      "3 47 loss: 0.04473620653152466\n",
      "3 48 loss: 0.04993786662817001\n",
      "3 49 loss: 0.03422188013792038\n",
      "3 50 loss: 0.06910990178585052\n",
      "3 51 loss: 0.018848545849323273\n",
      "3 52 loss: 0.06431359052658081\n",
      "3 53 loss: 0.03801153600215912\n",
      "3 54 loss: 0.12077262997627258\n",
      "3 55 loss: 0.013371682725846767\n",
      "3 56 loss: 0.05740709975361824\n",
      "3 57 loss: 0.027581363916397095\n",
      "3 58 loss: 0.021757330745458603\n",
      "3 59 loss: 0.04840648174285889\n",
      "3 60 loss: 0.008592545986175537\n",
      "3 61 loss: 0.04056508094072342\n",
      "3 62 loss: 0.01647983305156231\n",
      "3 63 loss: 0.03893415629863739\n",
      "3 64 loss: 0.15523400902748108\n",
      "3 65 loss: 0.046484511345624924\n",
      "3 66 loss: 0.047531433403491974\n",
      "3 67 loss: 0.09228713065385818\n",
      "3 68 loss: 0.04018833115696907\n",
      "3 69 loss: 0.048560816794633865\n",
      "3 70 loss: 0.030591659247875214\n",
      "3 71 loss: 0.013016331940889359\n",
      "3 72 loss: 0.030692221596837044\n",
      "3 73 loss: 0.06379516422748566\n",
      "3 74 loss: 0.016293376684188843\n",
      "3 75 loss: 0.08511333167552948\n",
      "3 76 loss: 0.027912719175219536\n",
      "3 77 loss: 0.029691483825445175\n",
      "3 78 loss: 0.006311063654720783\n",
      "3 79 loss: 0.03071737475693226\n",
      "3 80 loss: 0.03652308136224747\n",
      "3 81 loss: 0.06139637157320976\n",
      "3 82 loss: 0.04728946462273598\n",
      "3 83 loss: 0.051567669957876205\n",
      "3 84 loss: 0.054546743631362915\n",
      "3 85 loss: 0.01265235710889101\n",
      "3 86 loss: 0.07074439525604248\n",
      "3 87 loss: 0.04133479297161102\n",
      "3 88 loss: 0.025312263518571854\n",
      "3 89 loss: 0.028914909809827805\n",
      "3 90 loss: 0.020821508020162582\n",
      "3 91 loss: 0.01625891961157322\n",
      "3 92 loss: 0.0689539685845375\n",
      "3 93 loss: 0.024069804698228836\n",
      "3 94 loss: 0.01451351772993803\n",
      "3 95 loss: 0.029685035347938538\n",
      "3 96 loss: 0.01704200729727745\n",
      "3 97 loss: 0.007731557823717594\n",
      "3 98 loss: 0.0470685176551342\n",
      "3 99 loss: 0.008682279847562313\n",
      "3 100 loss: 0.04799873009324074\n",
      "3 101 loss: 0.01851477101445198\n",
      "3 102 loss: 0.02074309065937996\n",
      "3 103 loss: 0.011478498578071594\n",
      "3 104 loss: 0.045339133590459824\n",
      "3 105 loss: 0.023647338151931763\n",
      "3 106 loss: 0.046162158250808716\n",
      "3 107 loss: 0.04033658280968666\n",
      "3 108 loss: 0.047455430030822754\n",
      "3 109 loss: 0.02485867403447628\n",
      "3 110 loss: 0.009233664721250534\n",
      "3 111 loss: 0.004434369038790464\n",
      "3 112 loss: 0.03321908414363861\n",
      "3 113 loss: 0.005907691083848476\n",
      "3 114 loss: 0.02447359636425972\n",
      "3 115 loss: 0.08450479805469513\n",
      "3 116 loss: 0.12415392696857452\n",
      "3 117 loss: 0.06708189100027084\n",
      "3 118 loss: 0.03858417645096779\n",
      "3 119 loss: 0.05037597939372063\n",
      "3 120 loss: 0.046543896198272705\n",
      "3 121 loss: 0.03189874440431595\n",
      "3 122 loss: 0.010764895007014275\n",
      "3 123 loss: 0.06822045147418976\n",
      "3 124 loss: 0.023304253816604614\n",
      "3 125 loss: 0.09722770005464554\n",
      "3 126 loss: 0.07238644361495972\n",
      "3 127 loss: 0.021761704236268997\n",
      "3 128 loss: 0.03440236672759056\n",
      "3 129 loss: 0.04039965569972992\n",
      "3 130 loss: 0.05970154330134392\n",
      "3 131 loss: 0.018824052065610886\n",
      "3 132 loss: 0.04139286279678345\n",
      "3 133 loss: 0.043028924614191055\n",
      "3 134 loss: 0.04517132788896561\n",
      "3 135 loss: 0.0393163338303566\n",
      "3 136 loss: 0.04318857565522194\n",
      "3 137 loss: 0.02721933089196682\n",
      "3 138 loss: 0.01469184085726738\n",
      "3 139 loss: 0.04259507358074188\n",
      "3 140 loss: 0.06147010251879692\n",
      "3 141 loss: 0.05888520926237106\n",
      "3 142 loss: 0.06354875862598419\n",
      "3 143 loss: 0.1337590515613556\n",
      "3 144 loss: 0.028457242995500565\n",
      "3 145 loss: 0.011650672182440758\n",
      "3 146 loss: 0.05584220960736275\n",
      "3 147 loss: 0.06944568455219269\n",
      "3 148 loss: 0.03348175808787346\n",
      "3 149 loss: 0.02526528388261795\n",
      "3 150 loss: 0.13804446160793304\n",
      "3 151 loss: 0.012908244505524635\n",
      "3 152 loss: 0.03515974432229996\n",
      "3 153 loss: 0.010601343587040901\n",
      "3 154 loss: 0.054673001170158386\n",
      "3 155 loss: 0.08745772391557693\n",
      "3 156 loss: 0.13200192153453827\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e287a11e5e944319b996c0084ab25ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0 loss: 0.04151609167456627\n",
      "4 1 loss: 0.016714025288820267\n",
      "4 2 loss: 0.03581998497247696\n",
      "4 3 loss: 0.051441218703985214\n",
      "4 4 loss: 0.03564375266432762\n",
      "4 5 loss: 0.028141947463154793\n",
      "4 6 loss: 0.017577195540070534\n",
      "4 7 loss: 0.10522892326116562\n",
      "4 8 loss: 0.01462179608643055\n",
      "4 9 loss: 0.013045523315668106\n",
      "4 10 loss: 0.024240415543317795\n",
      "4 11 loss: 0.05541915446519852\n",
      "4 12 loss: 0.047104496508836746\n",
      "4 13 loss: 0.054926276206970215\n",
      "4 14 loss: 0.03547455742955208\n",
      "4 15 loss: 0.01032279059290886\n",
      "4 16 loss: 0.046620212495326996\n",
      "4 17 loss: 0.0688522532582283\n",
      "4 18 loss: 0.02677685208618641\n",
      "4 19 loss: 0.0452757328748703\n",
      "4 20 loss: 0.05904532968997955\n",
      "4 21 loss: 0.005617184564471245\n",
      "4 22 loss: 0.02785094641149044\n",
      "4 23 loss: 0.017500318586826324\n",
      "4 24 loss: 0.029569869861006737\n",
      "4 25 loss: 0.07705800235271454\n",
      "4 26 loss: 0.017062749713659286\n",
      "4 27 loss: 0.06715104728937149\n",
      "4 28 loss: 0.039408788084983826\n",
      "4 29 loss: 0.0680784061551094\n",
      "4 30 loss: 0.014094913378357887\n",
      "4 31 loss: 0.008426228538155556\n",
      "4 32 loss: 0.051100119948387146\n",
      "4 33 loss: 0.04713303595781326\n",
      "4 34 loss: 0.03485690429806709\n",
      "4 35 loss: 0.05863695964217186\n",
      "4 36 loss: 0.08448340743780136\n",
      "4 37 loss: 0.10726951062679291\n",
      "4 38 loss: 0.1046428233385086\n",
      "4 39 loss: 0.01361125148832798\n",
      "4 40 loss: 0.07973486185073853\n",
      "4 41 loss: 0.04073375090956688\n",
      "4 42 loss: 0.02158484235405922\n",
      "4 43 loss: 0.03133559599518776\n",
      "4 44 loss: 0.030147595331072807\n",
      "4 45 loss: 0.06090834364295006\n",
      "4 46 loss: 0.02326429821550846\n",
      "4 47 loss: 0.0462305061519146\n",
      "4 48 loss: 0.022046566009521484\n",
      "4 49 loss: 0.030867576599121094\n",
      "4 50 loss: 0.029239285737276077\n",
      "4 51 loss: 0.014242827892303467\n",
      "4 52 loss: 0.054117754101753235\n",
      "4 53 loss: 0.025954803451895714\n",
      "4 54 loss: 0.056411903351545334\n",
      "4 55 loss: 0.03140315040946007\n",
      "4 56 loss: 0.03428281098604202\n",
      "4 57 loss: 0.028653260320425034\n",
      "4 58 loss: 0.035262078046798706\n",
      "4 59 loss: 0.026884932070970535\n",
      "4 60 loss: 0.045489728450775146\n",
      "4 61 loss: 0.05425616353750229\n",
      "4 62 loss: 0.037406861782073975\n",
      "4 63 loss: 0.01087139267474413\n",
      "4 64 loss: 0.01856418326497078\n",
      "4 65 loss: 0.09949804842472076\n",
      "4 66 loss: 0.015458483248949051\n",
      "4 67 loss: 0.07814359664916992\n",
      "4 68 loss: 0.036380521953105927\n",
      "4 69 loss: 0.035001274198293686\n",
      "4 70 loss: 0.04920694977045059\n",
      "4 71 loss: 0.017145931720733643\n",
      "4 72 loss: 0.025769874453544617\n",
      "4 73 loss: 0.04337986558675766\n",
      "4 74 loss: 0.03595782816410065\n",
      "4 75 loss: 0.00889378972351551\n",
      "4 76 loss: 0.032973114401102066\n",
      "4 77 loss: 0.042119383811950684\n",
      "4 78 loss: 0.036643657833337784\n",
      "4 79 loss: 0.040711574256420135\n",
      "4 80 loss: 0.04016866534948349\n",
      "4 81 loss: 0.024962281808257103\n",
      "4 82 loss: 0.05108613893389702\n",
      "4 83 loss: 0.02732991985976696\n",
      "4 84 loss: 0.07896997034549713\n",
      "4 85 loss: 0.03785848617553711\n",
      "4 86 loss: 0.03810194134712219\n",
      "4 87 loss: 0.09432682394981384\n",
      "4 88 loss: 0.010550398379564285\n",
      "4 89 loss: 0.023958537727594376\n",
      "4 90 loss: 0.029231904074549675\n",
      "4 91 loss: 0.07384424656629562\n",
      "4 92 loss: 0.04844549298286438\n",
      "4 93 loss: 0.04270058870315552\n",
      "4 94 loss: 0.049911774694919586\n",
      "4 95 loss: 0.014796270057559013\n",
      "4 96 loss: 0.03953130170702934\n",
      "4 97 loss: 0.008402409963309765\n",
      "4 98 loss: 0.023793760687112808\n",
      "4 99 loss: 0.02001543529331684\n",
      "4 100 loss: 0.053397826850414276\n",
      "4 101 loss: 0.0678558349609375\n",
      "4 102 loss: 0.0444057323038578\n",
      "4 103 loss: 0.01578664407134056\n",
      "4 104 loss: 0.022596755996346474\n",
      "4 105 loss: 0.03318489342927933\n",
      "4 106 loss: 0.04902481287717819\n",
      "4 107 loss: 0.04145336151123047\n",
      "4 108 loss: 0.014673423953354359\n",
      "4 109 loss: 0.05093863606452942\n",
      "4 110 loss: 0.007030514534562826\n",
      "4 111 loss: 0.06262323260307312\n",
      "4 112 loss: 0.03399147838354111\n",
      "4 113 loss: 0.058542728424072266\n",
      "4 114 loss: 0.06412804126739502\n",
      "4 115 loss: 0.02379445731639862\n",
      "4 116 loss: 0.027904096990823746\n",
      "4 117 loss: 0.09128746390342712\n",
      "4 118 loss: 0.034768279641866684\n",
      "4 119 loss: 0.047431398183107376\n",
      "4 120 loss: 0.029417768120765686\n",
      "4 121 loss: 0.041812144219875336\n",
      "4 122 loss: 0.027347896248102188\n",
      "4 123 loss: 0.028755519539117813\n",
      "4 124 loss: 0.016626732423901558\n",
      "4 125 loss: 0.026133380830287933\n",
      "4 126 loss: 0.03466697409749031\n",
      "4 127 loss: 0.05802921950817108\n",
      "4 128 loss: 0.03717875853180885\n",
      "4 129 loss: 0.04825291782617569\n",
      "4 130 loss: 0.03444802016019821\n",
      "4 131 loss: 0.00587043259292841\n",
      "4 132 loss: 0.009432997554540634\n",
      "4 133 loss: 0.06449181586503983\n",
      "4 134 loss: 0.004786293022334576\n",
      "4 135 loss: 0.011754587292671204\n",
      "4 136 loss: 0.007500652223825455\n",
      "4 137 loss: 0.08314171433448792\n",
      "4 138 loss: 0.022125445306301117\n",
      "4 139 loss: 0.03391893208026886\n",
      "4 140 loss: 0.012513385154306889\n",
      "4 141 loss: 0.06824366003274918\n",
      "4 142 loss: 0.04931630566716194\n",
      "4 143 loss: 0.010309343226253986\n",
      "4 144 loss: 0.04366175830364227\n",
      "4 145 loss: 0.009046504274010658\n",
      "4 146 loss: 0.04123184084892273\n",
      "4 147 loss: 0.01836789771914482\n",
      "4 148 loss: 0.044979460537433624\n",
      "4 149 loss: 0.018159963190555573\n",
      "4 150 loss: 0.005692729726433754\n",
      "4 151 loss: 0.016795113682746887\n",
      "4 152 loss: 0.01265965960919857\n",
      "4 153 loss: 0.07407763600349426\n",
      "4 154 loss: 0.03846246376633644\n",
      "4 155 loss: 0.027391541749238968\n",
      "4 156 loss: 0.0014727325178682804\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb3afebba0541bea16f428ec9853302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0 loss: 0.02487873286008835\n",
      "5 1 loss: 0.017625126987695694\n",
      "5 2 loss: 0.028506778180599213\n",
      "5 3 loss: 0.05777512490749359\n",
      "5 4 loss: 0.07290294766426086\n",
      "5 5 loss: 0.0035803494974970818\n",
      "5 6 loss: 0.06062190234661102\n",
      "5 7 loss: 0.06503872573375702\n",
      "5 8 loss: 0.009206163696944714\n",
      "5 9 loss: 0.01964116469025612\n",
      "5 10 loss: 0.008190211839973927\n",
      "5 11 loss: 0.04114226996898651\n",
      "5 12 loss: 0.04496324807405472\n",
      "5 13 loss: 0.02345137856900692\n",
      "5 14 loss: 0.006047535687685013\n",
      "5 15 loss: 0.012164125218987465\n",
      "5 16 loss: 0.015861481428146362\n",
      "5 17 loss: 0.016988538205623627\n",
      "5 18 loss: 0.04316067323088646\n",
      "5 19 loss: 0.01582210324704647\n",
      "5 20 loss: 0.03468608111143112\n",
      "5 21 loss: 0.03625842183828354\n",
      "5 22 loss: 0.01676987111568451\n",
      "5 23 loss: 0.06328435987234116\n",
      "5 24 loss: 0.009411057457327843\n",
      "5 25 loss: 0.039825793355703354\n",
      "5 26 loss: 0.008562315255403519\n",
      "5 27 loss: 0.035968679934740067\n",
      "5 28 loss: 0.005906516686081886\n",
      "5 29 loss: 0.033390700817108154\n",
      "5 30 loss: 0.03071518987417221\n",
      "5 31 loss: 0.032631196081638336\n",
      "5 32 loss: 0.03729239106178284\n",
      "5 33 loss: 0.05961592122912407\n",
      "5 34 loss: 0.0048819659277796745\n",
      "5 35 loss: 0.03444381803274155\n",
      "5 36 loss: 0.005519529804587364\n",
      "5 37 loss: 0.03127995878458023\n",
      "5 38 loss: 0.02923761121928692\n",
      "5 39 loss: 0.010395674034953117\n",
      "5 40 loss: 0.013227654621005058\n",
      "5 41 loss: 0.047410838305950165\n",
      "5 42 loss: 0.08568326383829117\n",
      "5 43 loss: 0.006044779904186726\n",
      "5 44 loss: 0.03411554545164108\n",
      "5 45 loss: 0.008178925141692162\n",
      "5 46 loss: 0.030458450317382812\n",
      "5 47 loss: 0.0701703131198883\n",
      "5 48 loss: 0.07101763784885406\n",
      "5 49 loss: 0.021524066105484962\n",
      "5 50 loss: 0.02769983746111393\n",
      "5 51 loss: 0.022733766585588455\n",
      "5 52 loss: 0.021824374794960022\n",
      "5 53 loss: 0.0471329540014267\n",
      "5 54 loss: 0.04257011041045189\n",
      "5 55 loss: 0.006485605612397194\n",
      "5 56 loss: 0.015021268278360367\n",
      "5 57 loss: 0.011808321811258793\n",
      "5 58 loss: 0.0511837974190712\n",
      "5 59 loss: 0.019439158961176872\n",
      "5 60 loss: 0.0020684106275439262\n",
      "5 61 loss: 0.03326750546693802\n",
      "5 62 loss: 0.009117797017097473\n",
      "5 63 loss: 0.012999971397221088\n",
      "5 64 loss: 0.018455540761351585\n",
      "5 65 loss: 0.014021746814250946\n",
      "5 66 loss: 0.028234954923391342\n",
      "5 67 loss: 0.023047393187880516\n",
      "5 68 loss: 0.0933445394039154\n",
      "5 69 loss: 0.07722659409046173\n",
      "5 70 loss: 0.01158660463988781\n",
      "5 71 loss: 0.02344861812889576\n",
      "5 72 loss: 0.14049962162971497\n",
      "5 73 loss: 0.02971203252673149\n",
      "5 74 loss: 0.13374394178390503\n",
      "5 75 loss: 0.0788910984992981\n",
      "5 76 loss: 0.06474550068378448\n",
      "5 77 loss: 0.007514986675232649\n",
      "5 78 loss: 0.07615061104297638\n",
      "5 79 loss: 0.013589016161859035\n",
      "5 80 loss: 0.008243953809142113\n",
      "5 81 loss: 0.030804231762886047\n",
      "5 82 loss: 0.03345026075839996\n",
      "5 83 loss: 0.007480404805392027\n",
      "5 84 loss: 0.0690239891409874\n",
      "5 85 loss: 0.07270321249961853\n",
      "5 86 loss: 0.05382856726646423\n",
      "5 87 loss: 0.029430214315652847\n",
      "5 88 loss: 0.037064362317323685\n",
      "5 89 loss: 0.05488419532775879\n",
      "5 90 loss: 0.02617897093296051\n",
      "5 91 loss: 0.049147918820381165\n",
      "5 92 loss: 0.036902036517858505\n",
      "5 93 loss: 0.030477963387966156\n",
      "5 94 loss: 0.0197400264441967\n",
      "5 95 loss: 0.016305550932884216\n",
      "5 96 loss: 0.005177582614123821\n",
      "5 97 loss: 0.03497350215911865\n",
      "5 98 loss: 0.036842796951532364\n",
      "5 99 loss: 0.06215120851993561\n",
      "5 100 loss: 0.030001133680343628\n",
      "5 101 loss: 0.04491383582353592\n",
      "5 102 loss: 0.05426706746220589\n",
      "5 103 loss: 0.030302230268716812\n",
      "5 104 loss: 0.013186486437916756\n",
      "5 105 loss: 0.1076245978474617\n",
      "5 106 loss: 0.03990977257490158\n",
      "5 107 loss: 0.023530423641204834\n",
      "5 108 loss: 0.02280268445611\n",
      "5 109 loss: 0.04656187444925308\n",
      "5 110 loss: 0.025218769907951355\n",
      "5 111 loss: 0.050241582095623016\n",
      "5 112 loss: 0.012388002127408981\n",
      "5 113 loss: 0.025397690013051033\n",
      "5 114 loss: 0.027404475957155228\n",
      "5 115 loss: 0.025905994698405266\n",
      "5 116 loss: 0.024691738188266754\n",
      "5 117 loss: 0.056199800223112106\n",
      "5 118 loss: 0.008391546085476875\n",
      "5 119 loss: 0.004625828471034765\n",
      "5 120 loss: 0.009390631690621376\n",
      "5 121 loss: 0.026480399072170258\n",
      "5 122 loss: 0.03331562876701355\n",
      "5 123 loss: 0.004450722131878138\n",
      "5 124 loss: 0.009167907759547234\n",
      "5 125 loss: 0.011713879182934761\n",
      "5 126 loss: 0.03154141455888748\n",
      "5 127 loss: 0.00785364955663681\n",
      "5 128 loss: 0.06033967435359955\n",
      "5 129 loss: 0.03752803057432175\n",
      "5 130 loss: 0.0587063804268837\n",
      "5 131 loss: 0.10061168670654297\n",
      "5 132 loss: 0.005802865140140057\n",
      "5 133 loss: 0.016320636495947838\n",
      "5 134 loss: 0.015187320299446583\n",
      "5 135 loss: 0.03701065853238106\n",
      "5 136 loss: 0.015792101621627808\n",
      "5 137 loss: 0.013345904648303986\n",
      "5 138 loss: 0.02450438216328621\n",
      "5 139 loss: 0.04118744283914566\n",
      "5 140 loss: 0.010499950498342514\n",
      "5 141 loss: 0.04606416076421738\n",
      "5 142 loss: 0.012304672040045261\n",
      "5 143 loss: 0.03556457534432411\n",
      "5 144 loss: 0.021624110639095306\n",
      "5 145 loss: 0.026454519480466843\n",
      "5 146 loss: 0.02605164423584938\n",
      "5 147 loss: 0.08388230949640274\n",
      "5 148 loss: 0.028140084818005562\n",
      "5 149 loss: 0.01031727809458971\n",
      "5 150 loss: 0.03208649903535843\n",
      "5 151 loss: 0.03246645629405975\n",
      "5 152 loss: 0.05150716006755829\n",
      "5 153 loss: 0.0332387275993824\n",
      "5 154 loss: 0.006799028255045414\n",
      "5 155 loss: 0.05372973531484604\n",
      "5 156 loss: 0.05478464066982269\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6201a9b0ce4e486a9af96c9c9fcead89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0 loss: 0.0174957737326622\n",
      "6 1 loss: 0.029902087524533272\n",
      "6 2 loss: 0.019992873072624207\n",
      "6 3 loss: 0.063207246363163\n",
      "6 4 loss: 0.04974423348903656\n",
      "6 5 loss: 0.037813350558280945\n",
      "6 6 loss: 0.05462123453617096\n",
      "6 7 loss: 0.02497820556163788\n",
      "6 8 loss: 0.01765792816877365\n",
      "6 9 loss: 0.03942863643169403\n",
      "6 10 loss: 0.045374587178230286\n",
      "6 11 loss: 0.028975270688533783\n",
      "6 12 loss: 0.02900547906756401\n",
      "6 13 loss: 0.010449102148413658\n",
      "6 14 loss: 0.01505528949201107\n",
      "6 15 loss: 0.008378137834370136\n",
      "6 16 loss: 0.024292565882205963\n",
      "6 17 loss: 0.021400734782218933\n",
      "6 18 loss: 0.016789976507425308\n",
      "6 19 loss: 0.011960807256400585\n",
      "6 20 loss: 0.04436146467924118\n",
      "6 21 loss: 0.007910205982625484\n",
      "6 22 loss: 0.0057968199253082275\n",
      "6 23 loss: 0.012687984853982925\n",
      "6 24 loss: 0.02295568771660328\n",
      "6 25 loss: 0.0017038420774042606\n",
      "6 26 loss: 0.006316875107586384\n",
      "6 27 loss: 0.00771462544798851\n",
      "6 28 loss: 0.012723257765173912\n",
      "6 29 loss: 0.0588311143219471\n",
      "6 30 loss: 0.014124545268714428\n",
      "6 31 loss: 0.008092944510281086\n",
      "6 32 loss: 0.06342253088951111\n",
      "6 33 loss: 0.008295184001326561\n",
      "6 34 loss: 0.018519975244998932\n",
      "6 35 loss: 0.005666832439601421\n",
      "6 36 loss: 0.009308508597314358\n",
      "6 37 loss: 0.036660898476839066\n",
      "6 38 loss: 0.01024145819246769\n",
      "6 39 loss: 0.004049723967909813\n",
      "6 40 loss: 0.019061759114265442\n",
      "6 41 loss: 0.02813497930765152\n",
      "6 42 loss: 0.009569196030497551\n",
      "6 43 loss: 0.009134156629443169\n",
      "6 44 loss: 0.01127706654369831\n",
      "6 45 loss: 0.07128951698541641\n",
      "6 46 loss: 0.05641824007034302\n",
      "6 47 loss: 0.0941956415772438\n",
      "6 48 loss: 0.01839612051844597\n",
      "6 49 loss: 0.015201520174741745\n",
      "6 50 loss: 0.005277390591800213\n",
      "6 51 loss: 0.046674441546201706\n",
      "6 52 loss: 0.014499752782285213\n",
      "6 53 loss: 0.0043463315814733505\n",
      "6 54 loss: 0.010501131415367126\n",
      "6 55 loss: 0.020068777725100517\n",
      "6 56 loss: 0.0576503723859787\n",
      "6 57 loss: 0.016375476494431496\n",
      "6 58 loss: 0.005419147200882435\n",
      "6 59 loss: 0.04290696978569031\n",
      "6 60 loss: 0.005496304482221603\n",
      "6 61 loss: 0.008439131081104279\n",
      "6 62 loss: 0.05130918696522713\n",
      "6 63 loss: 0.011158855631947517\n",
      "6 64 loss: 0.04201598837971687\n",
      "6 65 loss: 0.021547816693782806\n",
      "6 66 loss: 0.013298660516738892\n",
      "6 67 loss: 0.009604590013623238\n",
      "6 68 loss: 0.05666337534785271\n",
      "6 69 loss: 0.041136063635349274\n",
      "6 70 loss: 0.026350902393460274\n",
      "6 71 loss: 0.06825631111860275\n",
      "6 72 loss: 0.027885155752301216\n",
      "6 73 loss: 0.04202405363321304\n",
      "6 74 loss: 0.02233150415122509\n",
      "6 75 loss: 0.03607197105884552\n",
      "6 76 loss: 0.03875172883272171\n",
      "6 77 loss: 0.09102372825145721\n",
      "6 78 loss: 0.062058985233306885\n",
      "6 79 loss: 0.013134118169546127\n",
      "6 80 loss: 0.060276757925748825\n",
      "6 81 loss: 0.020857175812125206\n",
      "6 82 loss: 0.060805048793554306\n",
      "6 83 loss: 0.01644490286707878\n",
      "6 84 loss: 0.037431750446558\n",
      "6 85 loss: 0.013894937001168728\n",
      "6 86 loss: 0.01185927726328373\n",
      "6 87 loss: 0.026921533048152924\n",
      "6 88 loss: 0.010669754818081856\n",
      "6 89 loss: 0.08777544647455215\n",
      "6 90 loss: 0.006103826686739922\n",
      "6 91 loss: 0.025760184973478317\n",
      "6 92 loss: 0.026307184249162674\n",
      "6 93 loss: 0.026699159294366837\n",
      "6 94 loss: 0.020955804735422134\n",
      "6 95 loss: 0.012811313383281231\n",
      "6 96 loss: 0.030231541022658348\n",
      "6 97 loss: 0.04112832993268967\n",
      "6 98 loss: 0.015525049529969692\n",
      "6 99 loss: 0.038582488894462585\n",
      "6 100 loss: 0.03080759383738041\n",
      "6 101 loss: 0.010407904163002968\n",
      "6 102 loss: 0.009823760017752647\n",
      "6 103 loss: 0.05555666983127594\n",
      "6 104 loss: 0.015462245792150497\n",
      "6 105 loss: 0.06594107300043106\n",
      "6 106 loss: 0.017680533230304718\n",
      "6 107 loss: 0.016851533204317093\n",
      "6 108 loss: 0.00897935125976801\n",
      "6 109 loss: 0.029197413474321365\n",
      "6 110 loss: 0.06126292794942856\n",
      "6 111 loss: 0.024074358865618706\n",
      "6 112 loss: 0.04772759974002838\n",
      "6 113 loss: 0.019474241882562637\n",
      "6 114 loss: 0.042431414127349854\n",
      "6 115 loss: 0.024029478430747986\n",
      "6 116 loss: 0.03725152462720871\n",
      "6 117 loss: 0.020015370100736618\n",
      "6 118 loss: 0.07956213504076004\n",
      "6 119 loss: 0.015790510922670364\n",
      "6 120 loss: 0.04670222848653793\n",
      "6 121 loss: 0.009833509102463722\n",
      "6 122 loss: 0.03591543808579445\n",
      "6 123 loss: 0.03940087556838989\n",
      "6 124 loss: 0.038342565298080444\n",
      "6 125 loss: 0.0067406464368104935\n",
      "6 126 loss: 0.05596642568707466\n",
      "6 127 loss: 0.015741508454084396\n",
      "6 128 loss: 0.05303702503442764\n",
      "6 129 loss: 0.03198374807834625\n",
      "6 130 loss: 0.06545068323612213\n",
      "6 131 loss: 0.03317633643746376\n",
      "6 132 loss: 0.012597404420375824\n",
      "6 133 loss: 0.008870337158441544\n",
      "6 134 loss: 0.020207298919558525\n",
      "6 135 loss: 0.04279603064060211\n",
      "6 136 loss: 0.033846981823444366\n",
      "6 137 loss: 0.10833359509706497\n",
      "6 138 loss: 0.01467363815754652\n",
      "6 139 loss: 0.04318758845329285\n",
      "6 140 loss: 0.01102880947291851\n",
      "6 141 loss: 0.03083728440105915\n",
      "6 142 loss: 0.015069273300468922\n",
      "6 143 loss: 0.003759493585675955\n",
      "6 144 loss: 0.0212416909635067\n",
      "6 145 loss: 0.016625892370939255\n",
      "6 146 loss: 0.0496993362903595\n",
      "6 147 loss: 0.006298336200416088\n",
      "6 148 loss: 0.06571287661790848\n",
      "6 149 loss: 0.0791611596941948\n",
      "6 150 loss: 0.07599680125713348\n",
      "6 151 loss: 0.04264512658119202\n",
      "6 152 loss: 0.03534922003746033\n",
      "6 153 loss: 0.036287810653448105\n",
      "6 154 loss: 0.022182125598192215\n",
      "6 155 loss: 0.04349012300372124\n",
      "6 156 loss: 0.005380113609135151\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a332addfaab41d897dca1d1bcf4ea17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0 loss: 0.04054620489478111\n",
      "7 1 loss: 0.041836775839328766\n",
      "7 2 loss: 0.05415312200784683\n",
      "7 3 loss: 0.008702607825398445\n",
      "7 4 loss: 0.07937103509902954\n",
      "7 5 loss: 0.04492174834012985\n",
      "7 6 loss: 0.045988086611032486\n",
      "7 7 loss: 0.009723380208015442\n",
      "7 8 loss: 0.005801290739327669\n",
      "7 9 loss: 0.04076473414897919\n",
      "7 10 loss: 0.04516184329986572\n",
      "7 11 loss: 0.050658851861953735\n",
      "7 12 loss: 0.032192543148994446\n",
      "7 13 loss: 0.01779092848300934\n",
      "7 14 loss: 0.016645904630422592\n",
      "7 15 loss: 0.006735478527843952\n",
      "7 16 loss: 0.021614184603095055\n",
      "7 17 loss: 0.03909049555659294\n",
      "7 18 loss: 0.04433457553386688\n",
      "7 19 loss: 0.006873713806271553\n",
      "7 20 loss: 0.007715141866356134\n",
      "7 21 loss: 0.00823896937072277\n",
      "7 22 loss: 0.016140883788466454\n",
      "7 23 loss: 0.037000883370637894\n",
      "7 24 loss: 0.025780072435736656\n",
      "7 25 loss: 0.03792339935898781\n",
      "7 26 loss: 0.006307824514806271\n",
      "7 27 loss: 0.015495715662837029\n",
      "7 28 loss: 0.02622387558221817\n",
      "7 29 loss: 0.008388319052755833\n",
      "7 30 loss: 0.016719672828912735\n",
      "7 31 loss: 0.024018559604883194\n",
      "7 32 loss: 0.005551510490477085\n",
      "7 33 loss: 0.05424714833498001\n",
      "7 34 loss: 0.005254602059721947\n",
      "7 35 loss: 0.05827309936285019\n",
      "7 36 loss: 0.005769533570855856\n",
      "7 37 loss: 0.02903902158141136\n",
      "7 38 loss: 0.011707654222846031\n",
      "7 39 loss: 0.008760640397667885\n",
      "7 40 loss: 0.019448397681117058\n",
      "7 41 loss: 0.01093992404639721\n",
      "7 42 loss: 0.019050108268857002\n",
      "7 43 loss: 0.0028171760495752096\n",
      "7 44 loss: 0.010227875784039497\n",
      "7 45 loss: 0.012409700080752373\n",
      "7 46 loss: 0.009251510724425316\n",
      "7 47 loss: 0.02189207635819912\n",
      "7 48 loss: 0.037283316254615784\n",
      "7 49 loss: 0.01843789964914322\n",
      "7 50 loss: 0.010823667049407959\n",
      "7 51 loss: 0.004148959647864103\n",
      "7 52 loss: 0.0028332816436886787\n",
      "7 53 loss: 0.018101738765835762\n",
      "7 54 loss: 0.011186614632606506\n",
      "7 55 loss: 0.016188200563192368\n",
      "7 56 loss: 0.003998327534645796\n",
      "7 57 loss: 0.10481353104114532\n",
      "7 58 loss: 0.059267643839120865\n",
      "7 59 loss: 0.006372217554599047\n",
      "7 60 loss: 0.049479223787784576\n",
      "7 61 loss: 0.04006429761648178\n",
      "7 62 loss: 0.017526913434267044\n",
      "7 63 loss: 0.011067758314311504\n",
      "7 64 loss: 0.026928327977657318\n",
      "7 65 loss: 0.049468688666820526\n",
      "7 66 loss: 0.003290316555649042\n",
      "7 67 loss: 0.01774539053440094\n",
      "7 68 loss: 0.025681421160697937\n",
      "7 69 loss: 0.0572059191763401\n",
      "7 70 loss: 0.017194170504808426\n",
      "7 71 loss: 0.015140363946557045\n",
      "7 72 loss: 0.003982111345976591\n",
      "7 73 loss: 0.052372295409440994\n",
      "7 74 loss: 0.016524869948625565\n",
      "7 75 loss: 0.025890368968248367\n",
      "7 76 loss: 0.01542220264673233\n",
      "7 77 loss: 0.013174996711313725\n",
      "7 78 loss: 0.025272591039538383\n",
      "7 79 loss: 0.016773736104369164\n",
      "7 80 loss: 0.024345865473151207\n",
      "7 81 loss: 0.01673019491136074\n",
      "7 82 loss: 0.06842031329870224\n",
      "7 83 loss: 0.013800082728266716\n",
      "7 84 loss: 0.008691944181919098\n",
      "7 85 loss: 0.009514865465462208\n",
      "7 86 loss: 0.02054135501384735\n",
      "7 87 loss: 0.06205639988183975\n",
      "7 88 loss: 0.0235927514731884\n",
      "7 89 loss: 0.10335609316825867\n",
      "7 90 loss: 0.017424654215574265\n",
      "7 91 loss: 0.004144000355154276\n",
      "7 92 loss: 0.03046623058617115\n",
      "7 93 loss: 0.016570815816521645\n",
      "7 94 loss: 0.055317848920822144\n",
      "7 95 loss: 0.02943207323551178\n",
      "7 96 loss: 0.02548353001475334\n",
      "7 97 loss: 0.009630932472646236\n",
      "7 98 loss: 0.0051972814835608006\n",
      "7 99 loss: 0.049384042620658875\n",
      "7 100 loss: 0.08428076654672623\n",
      "7 101 loss: 0.021864958107471466\n",
      "7 102 loss: 0.04732600599527359\n",
      "7 103 loss: 0.012510751374065876\n",
      "7 104 loss: 0.014457851648330688\n",
      "7 105 loss: 0.06646432727575302\n",
      "7 106 loss: 0.022420497611165047\n",
      "7 107 loss: 0.00291635119356215\n",
      "7 108 loss: 0.01447167806327343\n",
      "7 109 loss: 0.014893503859639168\n",
      "7 110 loss: 0.030746936798095703\n",
      "7 111 loss: 0.008054450154304504\n",
      "7 112 loss: 0.04191888868808746\n",
      "7 113 loss: 0.04908323287963867\n",
      "7 114 loss: 0.03743559867143631\n",
      "7 115 loss: 0.03626415506005287\n",
      "7 116 loss: 0.03789167478680611\n",
      "7 117 loss: 0.004373411647975445\n",
      "7 118 loss: 0.037967100739479065\n",
      "7 119 loss: 0.06388015300035477\n",
      "7 120 loss: 0.013451049104332924\n",
      "7 121 loss: 0.025547247380018234\n",
      "7 122 loss: 0.014932360500097275\n",
      "7 123 loss: 0.10907317698001862\n",
      "7 124 loss: 0.008939153514802456\n",
      "7 125 loss: 0.01687178947031498\n",
      "7 126 loss: 0.04342549666762352\n",
      "7 127 loss: 0.06253201514482498\n",
      "7 128 loss: 0.011301340535283089\n",
      "7 129 loss: 0.007058759685605764\n",
      "7 130 loss: 0.01093843299895525\n",
      "7 131 loss: 0.012400299310684204\n",
      "7 132 loss: 0.012406091205775738\n",
      "7 133 loss: 0.026926472783088684\n",
      "7 134 loss: 0.018957458436489105\n",
      "7 135 loss: 0.02199535444378853\n",
      "7 136 loss: 0.02401614561676979\n",
      "7 137 loss: 0.004703465849161148\n",
      "7 138 loss: 0.03530555218458176\n",
      "7 139 loss: 0.02066987380385399\n",
      "7 140 loss: 0.04218490794301033\n",
      "7 141 loss: 0.016541866585612297\n",
      "7 142 loss: 0.012754571624100208\n",
      "7 143 loss: 0.0688672885298729\n",
      "7 144 loss: 0.07518833875656128\n",
      "7 145 loss: 0.030823202803730965\n",
      "7 146 loss: 0.033737968653440475\n",
      "7 147 loss: 0.015389688313007355\n",
      "7 148 loss: 0.008786759339272976\n",
      "7 149 loss: 0.006603245623409748\n",
      "7 150 loss: 0.03112301230430603\n",
      "7 151 loss: 0.05021272227168083\n",
      "7 152 loss: 0.01135034766048193\n",
      "7 153 loss: 0.024885214865207672\n",
      "7 154 loss: 0.004521126858890057\n",
      "7 155 loss: 0.0026514960918575525\n",
      "7 156 loss: 0.0036630122922360897\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e36c2e16184b42ae81e09703519f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0 loss: 0.02144470438361168\n",
      "8 1 loss: 0.07216739654541016\n",
      "8 2 loss: 0.0057629793882369995\n",
      "8 3 loss: 0.07932303845882416\n",
      "8 4 loss: 0.033478036522865295\n",
      "8 5 loss: 0.02224298194050789\n",
      "8 6 loss: 0.025828303769230843\n",
      "8 7 loss: 0.005449064075946808\n",
      "8 8 loss: 0.007782090455293655\n",
      "8 9 loss: 0.003643997944891453\n",
      "8 10 loss: 0.005071112886071205\n",
      "8 11 loss: 0.03946717455983162\n",
      "8 12 loss: 0.024295583367347717\n",
      "8 13 loss: 0.050501205027103424\n",
      "8 14 loss: 0.006321938708424568\n",
      "8 15 loss: 0.016362713649868965\n",
      "8 16 loss: 0.013266470283269882\n",
      "8 17 loss: 0.02678837813436985\n",
      "8 18 loss: 0.048419442027807236\n",
      "8 19 loss: 0.028891511261463165\n",
      "8 20 loss: 0.002887868555262685\n",
      "8 21 loss: 0.030661212280392647\n",
      "8 22 loss: 0.01936224475502968\n",
      "8 23 loss: 0.06457434594631195\n",
      "8 24 loss: 0.027379533275961876\n",
      "8 25 loss: 0.008723167702555656\n",
      "8 26 loss: 0.06380639970302582\n",
      "8 27 loss: 0.03695426136255264\n",
      "8 28 loss: 0.09473828226327896\n",
      "8 29 loss: 0.03623484820127487\n",
      "8 30 loss: 0.008058286271989346\n",
      "8 31 loss: 0.042584460228681564\n",
      "8 32 loss: 0.0028000101447105408\n",
      "8 33 loss: 0.04204300791025162\n",
      "8 34 loss: 0.10026158392429352\n",
      "8 35 loss: 0.03547799214720726\n",
      "8 36 loss: 0.006978373043239117\n",
      "8 37 loss: 0.005660719238221645\n",
      "8 38 loss: 0.059357888996601105\n",
      "8 39 loss: 0.009587015956640244\n",
      "8 40 loss: 0.005263119004666805\n",
      "8 41 loss: 0.004816144704818726\n",
      "8 42 loss: 0.03425401449203491\n",
      "8 43 loss: 0.0390208438038826\n",
      "8 44 loss: 0.03745579719543457\n",
      "8 45 loss: 0.04211163520812988\n",
      "8 46 loss: 0.023691417649388313\n",
      "8 47 loss: 0.014744122512638569\n",
      "8 48 loss: 0.013619554229080677\n",
      "8 49 loss: 0.012019127607345581\n",
      "8 50 loss: 0.0167118888348341\n",
      "8 51 loss: 0.025805719196796417\n",
      "8 52 loss: 0.018017977476119995\n",
      "8 53 loss: 0.013152381405234337\n",
      "8 54 loss: 0.008979551494121552\n",
      "8 55 loss: 0.026281103491783142\n",
      "8 56 loss: 0.04708009958267212\n",
      "8 57 loss: 0.02189023792743683\n",
      "8 58 loss: 0.04024432599544525\n",
      "8 59 loss: 0.019562186673283577\n",
      "8 60 loss: 0.006386107299476862\n",
      "8 61 loss: 0.00834532082080841\n",
      "8 62 loss: 0.09096886962652206\n",
      "8 63 loss: 0.007103703450411558\n",
      "8 64 loss: 0.013347668573260307\n",
      "8 65 loss: 0.046752385795116425\n",
      "8 66 loss: 0.028354860842227936\n",
      "8 67 loss: 0.028659094125032425\n",
      "8 68 loss: 0.01024351455271244\n",
      "8 69 loss: 0.00797376036643982\n",
      "8 70 loss: 0.04078521952033043\n",
      "8 71 loss: 0.050901442766189575\n",
      "8 72 loss: 0.042224250733852386\n",
      "8 73 loss: 0.03151801973581314\n",
      "8 74 loss: 0.03955477848649025\n",
      "8 75 loss: 0.069337397813797\n",
      "8 76 loss: 0.012507997453212738\n",
      "8 77 loss: 0.013580964878201485\n",
      "8 78 loss: 0.03258349001407623\n",
      "8 79 loss: 0.009725205600261688\n",
      "8 80 loss: 0.03733760118484497\n",
      "8 81 loss: 0.027706019580364227\n",
      "8 82 loss: 0.010611525736749172\n",
      "8 83 loss: 0.011049221269786358\n",
      "8 84 loss: 0.039584413170814514\n",
      "8 85 loss: 0.011574013158679008\n",
      "8 86 loss: 0.04217621684074402\n",
      "8 87 loss: 0.0061012860387563705\n",
      "8 88 loss: 0.019260436296463013\n",
      "8 89 loss: 0.05869714543223381\n",
      "8 90 loss: 0.03689926117658615\n",
      "8 91 loss: 0.040273282676935196\n",
      "8 92 loss: 0.03932096064090729\n",
      "8 93 loss: 0.008114644326269627\n",
      "8 94 loss: 0.0403069444000721\n",
      "8 95 loss: 0.0030558749567717314\n",
      "8 96 loss: 0.018772710114717484\n",
      "8 97 loss: 0.045145921409130096\n",
      "8 98 loss: 0.03584979102015495\n",
      "8 99 loss: 0.017084799706935883\n",
      "8 100 loss: 0.056333526968955994\n",
      "8 101 loss: 0.04430852085351944\n",
      "8 102 loss: 0.05333856865763664\n",
      "8 103 loss: 0.00867799948900938\n",
      "8 104 loss: 0.01823914609849453\n",
      "8 105 loss: 0.009907625615596771\n",
      "8 106 loss: 0.008317154832184315\n",
      "8 107 loss: 0.01993117481470108\n",
      "8 108 loss: 0.005409095901995897\n",
      "8 109 loss: 0.009086376056075096\n",
      "8 110 loss: 0.04431596025824547\n",
      "8 111 loss: 0.037554189562797546\n",
      "8 112 loss: 0.06659550964832306\n",
      "8 113 loss: 0.045167822390794754\n",
      "8 114 loss: 0.012004079297184944\n",
      "8 115 loss: 0.007724515628069639\n",
      "8 116 loss: 0.04048620164394379\n",
      "8 117 loss: 0.02096831053495407\n",
      "8 118 loss: 0.03716835007071495\n",
      "8 119 loss: 0.015402796678245068\n",
      "8 120 loss: 0.019093800336122513\n",
      "8 121 loss: 0.03314121812582016\n",
      "8 122 loss: 0.030412709340453148\n",
      "8 123 loss: 0.027024976909160614\n",
      "8 124 loss: 0.04365018010139465\n",
      "8 125 loss: 0.026647869497537613\n",
      "8 126 loss: 0.06801937520503998\n",
      "8 127 loss: 0.027246639132499695\n",
      "8 128 loss: 0.014168902300298214\n",
      "8 129 loss: 0.06949647516012192\n",
      "8 130 loss: 0.03621327131986618\n",
      "8 131 loss: 0.056843265891075134\n",
      "8 132 loss: 0.0064455559477210045\n",
      "8 133 loss: 0.028402581810951233\n",
      "8 134 loss: 0.010516269132494926\n",
      "8 135 loss: 0.008450434543192387\n",
      "8 136 loss: 0.006234572734683752\n",
      "8 137 loss: 0.017771612852811813\n",
      "8 138 loss: 0.008040457032620907\n",
      "8 139 loss: 0.023549750447273254\n",
      "8 140 loss: 0.03022925928235054\n",
      "8 141 loss: 0.014249211177229881\n",
      "8 142 loss: 0.0072316695004701614\n",
      "8 143 loss: 0.014171155169606209\n",
      "8 144 loss: 0.0833880826830864\n",
      "8 145 loss: 0.011716373264789581\n",
      "8 146 loss: 0.0035124015994369984\n",
      "8 147 loss: 0.01137391198426485\n",
      "8 148 loss: 0.02898792177438736\n",
      "8 149 loss: 0.04563300684094429\n",
      "8 150 loss: 0.019485190510749817\n",
      "8 151 loss: 0.022739477455615997\n",
      "8 152 loss: 0.02213260531425476\n",
      "8 153 loss: 0.041316062211990356\n",
      "8 154 loss: 0.03123992308974266\n",
      "8 155 loss: 0.015907732769846916\n",
      "8 156 loss: 0.008146162144839764\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf78f2b9fe4146099ce62b0b5722df83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0 loss: 0.015641657635569572\n",
      "9 1 loss: 0.018580203875899315\n",
      "9 2 loss: 0.04527736455202103\n",
      "9 3 loss: 0.00900248158723116\n",
      "9 4 loss: 0.01071199867874384\n",
      "9 5 loss: 0.030514823272824287\n",
      "9 6 loss: 0.018510641530156136\n",
      "9 7 loss: 0.0724603682756424\n",
      "9 8 loss: 0.025579120963811874\n",
      "9 9 loss: 0.008796739391982555\n",
      "9 10 loss: 0.03784678131341934\n",
      "9 11 loss: 0.01347735058516264\n",
      "9 12 loss: 0.009421597234904766\n",
      "9 13 loss: 0.02401738241314888\n",
      "9 14 loss: 0.02195076271891594\n",
      "9 15 loss: 0.004292578902095556\n",
      "9 16 loss: 0.018615178763866425\n",
      "9 17 loss: 0.015640605241060257\n",
      "9 18 loss: 0.03174034506082535\n",
      "9 19 loss: 0.019513379782438278\n",
      "9 20 loss: 0.005936020519584417\n",
      "9 21 loss: 0.04572781175374985\n",
      "9 22 loss: 0.05187871679663658\n",
      "9 23 loss: 0.02828012965619564\n",
      "9 24 loss: 0.003640844952315092\n",
      "9 25 loss: 0.010391537100076675\n",
      "9 26 loss: 0.004677949007600546\n",
      "9 27 loss: 0.01219181902706623\n",
      "9 28 loss: 0.013629352673888206\n",
      "9 29 loss: 0.07061603665351868\n",
      "9 30 loss: 0.0016109944554045796\n",
      "9 31 loss: 0.02449294738471508\n",
      "9 32 loss: 0.009225794114172459\n",
      "9 33 loss: 0.0018665038514882326\n",
      "9 34 loss: 0.0332002229988575\n",
      "9 35 loss: 0.013486490584909916\n",
      "9 36 loss: 0.010411310940980911\n",
      "9 37 loss: 0.05342382192611694\n",
      "9 38 loss: 0.07057195901870728\n",
      "9 39 loss: 0.02030489221215248\n",
      "9 40 loss: 0.0232984758913517\n",
      "9 41 loss: 0.007095280569046736\n",
      "9 42 loss: 0.003551811445504427\n",
      "9 43 loss: 0.040260836482048035\n",
      "9 44 loss: 0.0201324000954628\n",
      "9 45 loss: 0.03290686383843422\n",
      "9 46 loss: 0.04816669970750809\n",
      "9 47 loss: 0.009116014465689659\n",
      "9 48 loss: 0.06642290949821472\n",
      "9 49 loss: 0.009215474128723145\n",
      "9 50 loss: 0.052699826657772064\n",
      "9 51 loss: 0.01777072250843048\n",
      "9 52 loss: 0.010659902356564999\n",
      "9 53 loss: 0.01113241259008646\n",
      "9 54 loss: 0.04885698854923248\n",
      "9 55 loss: 0.027528516948223114\n",
      "9 56 loss: 0.013220340944826603\n",
      "9 57 loss: 0.035258132964372635\n",
      "9 58 loss: 0.008489356376230717\n",
      "9 59 loss: 0.021055612713098526\n",
      "9 60 loss: 0.008123116567730904\n",
      "9 61 loss: 0.028713416308164597\n",
      "9 62 loss: 0.03472672775387764\n",
      "9 63 loss: 0.01554357074201107\n",
      "9 64 loss: 0.00417311629280448\n",
      "9 65 loss: 0.034544218331575394\n",
      "9 66 loss: 0.026041630655527115\n",
      "9 67 loss: 0.031186122447252274\n",
      "9 68 loss: 0.012874477542936802\n",
      "9 69 loss: 0.025407154113054276\n",
      "9 70 loss: 0.03486590459942818\n",
      "9 71 loss: 0.0038203205913305283\n",
      "9 72 loss: 0.009176157414913177\n",
      "9 73 loss: 0.029621195048093796\n",
      "9 74 loss: 0.02000485174357891\n",
      "9 75 loss: 0.0275691207498312\n",
      "9 76 loss: 0.02103257179260254\n",
      "9 77 loss: 0.032134346663951874\n",
      "9 78 loss: 0.043429914861917496\n",
      "9 79 loss: 0.004530823789536953\n",
      "9 80 loss: 0.004690331406891346\n",
      "9 81 loss: 0.007605122402310371\n",
      "9 82 loss: 0.007793990895152092\n",
      "9 83 loss: 0.017755810171365738\n",
      "9 84 loss: 0.013935849070549011\n",
      "9 85 loss: 0.014037275686860085\n",
      "9 86 loss: 0.01690577156841755\n",
      "9 87 loss: 0.03700731694698334\n",
      "9 88 loss: 0.043151214718818665\n",
      "9 89 loss: 0.04371718317270279\n",
      "9 90 loss: 0.013798383064568043\n",
      "9 91 loss: 0.031378429383039474\n",
      "9 92 loss: 0.041191183030605316\n",
      "9 93 loss: 0.061864301562309265\n",
      "9 94 loss: 0.031713537871837616\n",
      "9 95 loss: 0.023540237918496132\n",
      "9 96 loss: 0.007749767508357763\n",
      "9 97 loss: 0.036819204688072205\n",
      "9 98 loss: 0.011615876108407974\n",
      "9 99 loss: 0.02516130730509758\n",
      "9 100 loss: 0.03597811609506607\n",
      "9 101 loss: 0.024715442210435867\n",
      "9 102 loss: 0.0044325534254312515\n",
      "9 103 loss: 0.016872623935341835\n",
      "9 104 loss: 0.0214930959045887\n",
      "9 105 loss: 0.04740525037050247\n",
      "9 106 loss: 0.011210218071937561\n",
      "9 107 loss: 0.006665972992777824\n",
      "9 108 loss: 0.031359631568193436\n",
      "9 109 loss: 0.021326160058379173\n",
      "9 110 loss: 0.00751221738755703\n",
      "9 111 loss: 0.008379630744457245\n",
      "9 112 loss: 0.0030662273056805134\n",
      "9 113 loss: 0.003426558105275035\n",
      "9 114 loss: 0.013974275439977646\n",
      "9 115 loss: 0.027900034561753273\n",
      "9 116 loss: 0.005175705999135971\n",
      "9 117 loss: 0.00464689452201128\n",
      "9 118 loss: 0.010621726512908936\n",
      "9 119 loss: 0.012599282898008823\n",
      "9 120 loss: 0.0505671501159668\n",
      "9 121 loss: 0.005003293044865131\n",
      "9 122 loss: 0.061356402933597565\n",
      "9 123 loss: 0.053150758147239685\n",
      "9 124 loss: 0.06910240650177002\n",
      "9 125 loss: 0.04180707782506943\n",
      "9 126 loss: 0.00565682165324688\n",
      "9 127 loss: 0.004026160575449467\n",
      "9 128 loss: 0.037585631012916565\n",
      "9 129 loss: 0.04757857322692871\n",
      "9 130 loss: 0.014653576537966728\n",
      "9 131 loss: 0.019942715764045715\n",
      "9 132 loss: 0.0065713124349713326\n",
      "9 133 loss: 0.051444970071315765\n",
      "9 134 loss: 0.013509009033441544\n",
      "9 135 loss: 0.05860966444015503\n",
      "9 136 loss: 0.055767789483070374\n",
      "9 137 loss: 0.010589527897536755\n",
      "9 138 loss: 0.05929841846227646\n",
      "9 139 loss: 0.030356021597981453\n",
      "9 140 loss: 0.0563352033495903\n",
      "9 141 loss: 0.011007186025381088\n",
      "9 142 loss: 0.015463916584849358\n",
      "9 143 loss: 0.06411990523338318\n",
      "9 144 loss: 0.05994519591331482\n",
      "9 145 loss: 0.066009521484375\n",
      "9 146 loss: 0.023099901154637337\n",
      "9 147 loss: 0.01505344733595848\n",
      "9 148 loss: 0.09470825642347336\n",
      "9 149 loss: 0.016634367406368256\n",
      "9 150 loss: 0.023245908319950104\n",
      "9 151 loss: 0.04084867238998413\n",
      "9 152 loss: 0.03840440511703491\n",
      "9 153 loss: 0.005344985984265804\n",
      "9 154 loss: 0.00683223269879818\n",
      "9 155 loss: 0.02227015234529972\n",
      "9 156 loss: 0.002495132852345705\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809330a0e86748869bc843558e783347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 loss: 0.035138558596372604\n",
      "10 1 loss: 0.051990754902362823\n",
      "10 2 loss: 0.02894214540719986\n",
      "10 3 loss: 0.017590206116437912\n",
      "10 4 loss: 0.0037469679955393076\n",
      "10 5 loss: 0.013648798689246178\n",
      "10 6 loss: 0.032484833151102066\n",
      "10 7 loss: 0.014801103621721268\n",
      "10 8 loss: 0.0033804751001298428\n",
      "10 9 loss: 0.056799065321683884\n",
      "10 10 loss: 0.05947345495223999\n",
      "10 11 loss: 0.015315991826355457\n",
      "10 12 loss: 0.043985068798065186\n",
      "10 13 loss: 0.03471572324633598\n",
      "10 14 loss: 0.015242074616253376\n",
      "10 15 loss: 0.009122407995164394\n",
      "10 16 loss: 0.024746716022491455\n",
      "10 17 loss: 0.05109414458274841\n",
      "10 18 loss: 0.008661724627017975\n",
      "10 19 loss: 0.04747643321752548\n",
      "10 20 loss: 0.017612742260098457\n",
      "10 21 loss: 0.01128321047872305\n",
      "10 22 loss: 0.008673269301652908\n",
      "10 23 loss: 0.02673226036131382\n",
      "10 24 loss: 0.016882535070180893\n",
      "10 25 loss: 0.01733594387769699\n",
      "10 26 loss: 0.011006593704223633\n",
      "10 27 loss: 0.037795573472976685\n",
      "10 28 loss: 0.018900137394666672\n",
      "10 29 loss: 0.030082225799560547\n",
      "10 30 loss: 0.0686444416642189\n",
      "10 31 loss: 0.031502265483140945\n",
      "10 32 loss: 0.010381357744336128\n",
      "10 33 loss: 0.04066165164113045\n",
      "10 34 loss: 0.014907139353454113\n",
      "10 35 loss: 0.018823198974132538\n",
      "10 36 loss: 0.03266417235136032\n",
      "10 37 loss: 0.017901290208101273\n",
      "10 38 loss: 0.03750733286142349\n",
      "10 39 loss: 0.022992895916104317\n",
      "10 40 loss: 0.023563910275697708\n",
      "10 41 loss: 0.02462594583630562\n",
      "10 42 loss: 0.04720454290509224\n",
      "10 43 loss: 0.01941084675490856\n",
      "10 44 loss: 0.045980148017406464\n",
      "10 45 loss: 0.016477273777127266\n",
      "10 46 loss: 0.010217862203717232\n",
      "10 47 loss: 0.018387271091341972\n",
      "10 48 loss: 0.07184673845767975\n",
      "10 49 loss: 0.020031463354825974\n",
      "10 50 loss: 0.009493902325630188\n",
      "10 51 loss: 0.02523362636566162\n",
      "10 52 loss: 0.05069616436958313\n",
      "10 53 loss: 0.03741329163312912\n",
      "10 54 loss: 0.012315427884459496\n",
      "10 55 loss: 0.005729626398533583\n",
      "10 56 loss: 0.014568940736353397\n",
      "10 57 loss: 0.004462067969143391\n",
      "10 58 loss: 0.03498268127441406\n",
      "10 59 loss: 0.02790006995201111\n",
      "10 60 loss: 0.004764222074300051\n",
      "10 61 loss: 0.01582624763250351\n",
      "10 62 loss: 0.011719885282218456\n",
      "10 63 loss: 0.011838419362902641\n",
      "10 64 loss: 0.006604453083127737\n",
      "10 65 loss: 0.004388268105685711\n",
      "10 66 loss: 0.059326451271772385\n",
      "10 67 loss: 0.024112820625305176\n",
      "10 68 loss: 0.039359115064144135\n",
      "10 69 loss: 0.019157782196998596\n",
      "10 70 loss: 0.0035935365594923496\n",
      "10 71 loss: 0.01358578260987997\n",
      "10 72 loss: 0.024843404069542885\n",
      "10 73 loss: 0.00268374802544713\n",
      "10 74 loss: 0.060951441526412964\n",
      "10 75 loss: 0.024767816066741943\n",
      "10 76 loss: 0.05416521430015564\n",
      "10 77 loss: 0.009232224896550179\n",
      "10 78 loss: 0.024824485182762146\n",
      "10 79 loss: 0.03565920889377594\n",
      "10 80 loss: 0.018656238913536072\n",
      "10 81 loss: 0.006864053197205067\n",
      "10 82 loss: 0.008814869448542595\n",
      "10 83 loss: 0.00980677641928196\n",
      "10 84 loss: 0.009847237728536129\n",
      "10 85 loss: 0.03541506826877594\n",
      "10 86 loss: 0.02131510153412819\n",
      "10 87 loss: 0.008375542238354683\n",
      "10 88 loss: 0.013166042976081371\n",
      "10 89 loss: 0.03837520256638527\n",
      "10 90 loss: 0.009579017758369446\n",
      "10 91 loss: 0.01830408349633217\n",
      "10 92 loss: 0.0186208076775074\n",
      "10 93 loss: 0.03238459303975105\n",
      "10 94 loss: 0.00553415110334754\n",
      "10 95 loss: 0.00556828361004591\n",
      "10 96 loss: 0.006194153800606728\n",
      "10 97 loss: 0.0037745654117316008\n",
      "10 98 loss: 0.014666307717561722\n",
      "10 99 loss: 0.004709708504378796\n",
      "10 100 loss: 0.007636640220880508\n",
      "10 101 loss: 0.02502218633890152\n",
      "10 102 loss: 0.0031545336823910475\n",
      "10 103 loss: 0.0019247420132160187\n",
      "10 104 loss: 0.02414844185113907\n",
      "10 105 loss: 0.0006314482307061553\n",
      "10 106 loss: 0.02707265503704548\n",
      "10 107 loss: 0.04173686355352402\n",
      "10 108 loss: 0.005267005413770676\n",
      "10 109 loss: 0.010330474004149437\n",
      "10 110 loss: 0.05412055924534798\n",
      "10 111 loss: 0.011674348264932632\n",
      "10 112 loss: 0.05301184579730034\n",
      "10 113 loss: 0.013159060850739479\n",
      "10 114 loss: 0.015277029946446419\n",
      "10 115 loss: 0.0073749590665102005\n",
      "10 116 loss: 0.01104032900184393\n",
      "10 117 loss: 0.009833292104303837\n",
      "10 118 loss: 0.0435781255364418\n",
      "10 119 loss: 0.005965568590909243\n",
      "10 120 loss: 0.003758338512852788\n",
      "10 121 loss: 0.003872200148180127\n",
      "10 122 loss: 0.008606523275375366\n",
      "10 123 loss: 0.013431469909846783\n",
      "10 124 loss: 0.004220029339194298\n",
      "10 125 loss: 0.0013596871867775917\n",
      "10 126 loss: 0.00995208416134119\n",
      "10 127 loss: 0.03395736590027809\n",
      "10 128 loss: 0.018881509080529213\n",
      "10 129 loss: 0.006337229162454605\n",
      "10 130 loss: 0.005955378990620375\n",
      "10 131 loss: 0.009783917106688023\n",
      "10 132 loss: 0.03282687067985535\n",
      "10 133 loss: 0.0019904589280486107\n",
      "10 134 loss: 0.03761080652475357\n",
      "10 135 loss: 0.005073759704828262\n",
      "10 136 loss: 0.003479565493762493\n",
      "10 137 loss: 0.022128650918602943\n",
      "10 138 loss: 0.004027637653052807\n",
      "10 139 loss: 0.007200765423476696\n",
      "10 140 loss: 0.014947030693292618\n",
      "10 141 loss: 0.003175969235599041\n",
      "10 142 loss: 0.008886687457561493\n",
      "10 143 loss: 0.002952689304947853\n",
      "10 144 loss: 0.019103756174445152\n",
      "10 145 loss: 0.004960304591804743\n",
      "10 146 loss: 0.005631444975733757\n",
      "10 147 loss: 0.01039627380669117\n",
      "10 148 loss: 0.03668530285358429\n",
      "10 149 loss: 0.009180343709886074\n",
      "10 150 loss: 0.030843127518892288\n",
      "10 151 loss: 0.00731420423835516\n",
      "10 152 loss: 0.008604663424193859\n",
      "10 153 loss: 0.08441565930843353\n",
      "10 154 loss: 0.002716648392379284\n",
      "10 155 loss: 0.0068877944722771645\n",
      "10 156 loss: 0.0002373610041104257\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e980aff72149119e8b231afe72154f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0 loss: 0.036504343152046204\n",
      "11 1 loss: 0.020171185955405235\n",
      "11 2 loss: 0.0037856868002563715\n",
      "11 3 loss: 0.0034622817765921354\n",
      "11 4 loss: 0.003603495890274644\n",
      "11 5 loss: 0.013378966599702835\n",
      "11 6 loss: 0.006903894245624542\n",
      "11 7 loss: 0.006249637342989445\n",
      "11 8 loss: 0.057385433465242386\n",
      "11 9 loss: 0.0015373688656836748\n",
      "11 10 loss: 0.011623654514551163\n",
      "11 11 loss: 0.11494387686252594\n",
      "11 12 loss: 0.04081733152270317\n",
      "11 13 loss: 0.011746963486075401\n",
      "11 14 loss: 0.021942317485809326\n",
      "11 15 loss: 0.002574451733380556\n",
      "11 16 loss: 0.03917594999074936\n",
      "11 17 loss: 0.050501301884651184\n",
      "11 18 loss: 0.01664755865931511\n",
      "11 19 loss: 0.015167304314672947\n",
      "11 20 loss: 0.03823854774236679\n",
      "11 21 loss: 0.004437677096575499\n",
      "11 22 loss: 0.06870429217815399\n",
      "11 23 loss: 0.006624156609177589\n",
      "11 24 loss: 0.021169116720557213\n",
      "11 25 loss: 0.04813789576292038\n",
      "11 26 loss: 0.07045366615056992\n",
      "11 27 loss: 0.014912407845258713\n",
      "11 28 loss: 0.03688544034957886\n",
      "11 29 loss: 0.00709141418337822\n",
      "11 30 loss: 0.05249512568116188\n",
      "11 31 loss: 0.03760726749897003\n",
      "11 32 loss: 0.029729854315519333\n",
      "11 33 loss: 0.030131695792078972\n",
      "11 34 loss: 0.00485668471083045\n",
      "11 35 loss: 0.003762262174859643\n",
      "11 36 loss: 0.005894077941775322\n",
      "11 37 loss: 0.00796547532081604\n",
      "11 38 loss: 0.02933388575911522\n",
      "11 39 loss: 0.027911189943552017\n",
      "11 40 loss: 0.012735080905258656\n",
      "11 41 loss: 0.03982941433787346\n",
      "11 42 loss: 0.01762808859348297\n",
      "11 43 loss: 0.004078146070241928\n",
      "11 44 loss: 0.014419874176383018\n",
      "11 45 loss: 0.07652442902326584\n",
      "11 46 loss: 0.02413579821586609\n",
      "11 47 loss: 0.06495534628629684\n",
      "11 48 loss: 0.004005424678325653\n",
      "11 49 loss: 0.0038856095634400845\n",
      "11 50 loss: 0.030261382460594177\n",
      "11 51 loss: 0.0065646665170788765\n",
      "11 52 loss: 0.006260490044951439\n",
      "11 53 loss: 0.031609803438186646\n",
      "11 54 loss: 0.013478435575962067\n",
      "11 55 loss: 0.006673603784292936\n",
      "11 56 loss: 0.01508580893278122\n",
      "11 57 loss: 0.038746267557144165\n",
      "11 58 loss: 0.0414748415350914\n",
      "11 59 loss: 0.0193341001868248\n",
      "11 60 loss: 0.044531065970659256\n",
      "11 61 loss: 0.012152155861258507\n",
      "11 62 loss: 0.01080242544412613\n",
      "11 63 loss: 0.022934332489967346\n",
      "11 64 loss: 0.03908540681004524\n",
      "11 65 loss: 0.008748577907681465\n",
      "11 66 loss: 0.014143291860818863\n",
      "11 67 loss: 0.02588598057627678\n",
      "11 68 loss: 0.008617869578301907\n",
      "11 69 loss: 0.02100127376616001\n",
      "11 70 loss: 0.00533039728179574\n",
      "11 71 loss: 0.009911229833960533\n",
      "11 72 loss: 0.022945933043956757\n",
      "11 73 loss: 0.009570649825036526\n",
      "11 74 loss: 0.08367714285850525\n",
      "11 75 loss: 0.006326745264232159\n",
      "11 76 loss: 0.04989301785826683\n",
      "11 77 loss: 0.020818427205085754\n",
      "11 78 loss: 0.045906201004981995\n",
      "11 79 loss: 0.009343107230961323\n",
      "11 80 loss: 0.016928937286138535\n",
      "11 81 loss: 0.02953648567199707\n",
      "11 82 loss: 0.0034665237180888653\n",
      "11 83 loss: 0.012232393026351929\n",
      "11 84 loss: 0.010547224432229996\n",
      "11 85 loss: 0.034230172634124756\n",
      "11 86 loss: 0.016924742609262466\n",
      "11 87 loss: 0.04526163637638092\n",
      "11 88 loss: 0.0025916185695677996\n",
      "11 89 loss: 0.010189207270741463\n",
      "11 90 loss: 0.028356341645121574\n",
      "11 91 loss: 0.006855308078229427\n",
      "11 92 loss: 0.003974609076976776\n",
      "11 93 loss: 0.04708678275346756\n",
      "11 94 loss: 0.02495650015771389\n",
      "11 95 loss: 0.01961124688386917\n",
      "11 96 loss: 0.017013706266880035\n",
      "11 97 loss: 0.003224520478397608\n",
      "11 98 loss: 0.006502347532659769\n",
      "11 99 loss: 0.03364482522010803\n",
      "11 100 loss: 0.004891031887382269\n",
      "11 101 loss: 0.01827075332403183\n",
      "11 102 loss: 0.0060013169422745705\n",
      "11 103 loss: 0.007581367157399654\n",
      "11 104 loss: 0.024190908297896385\n",
      "11 105 loss: 0.038587331771850586\n",
      "11 106 loss: 0.018061218783259392\n",
      "11 107 loss: 0.006045474670827389\n",
      "11 108 loss: 0.013994477689266205\n",
      "11 109 loss: 0.011844002641737461\n",
      "11 110 loss: 0.028240825980901718\n",
      "11 111 loss: 0.031813543289899826\n",
      "11 112 loss: 0.006935642100870609\n",
      "11 113 loss: 0.004602301865816116\n",
      "11 114 loss: 0.016791686415672302\n",
      "11 115 loss: 0.012363153509795666\n",
      "11 116 loss: 0.006219510920345783\n",
      "11 117 loss: 0.004737647250294685\n",
      "11 118 loss: 0.004307104274630547\n",
      "11 119 loss: 0.020009314641356468\n",
      "11 120 loss: 0.007099272683262825\n",
      "11 121 loss: 0.011656885966658592\n",
      "11 122 loss: 0.013322588987648487\n",
      "11 123 loss: 0.008483749814331532\n",
      "11 124 loss: 0.018728844821453094\n",
      "11 125 loss: 0.02065967582166195\n",
      "11 126 loss: 0.018976334482431412\n",
      "11 127 loss: 0.007044043857604265\n",
      "11 128 loss: 0.007240036502480507\n",
      "11 129 loss: 0.03374642878770828\n",
      "11 130 loss: 0.0033973464742302895\n",
      "11 131 loss: 0.00281613995321095\n",
      "11 132 loss: 0.006546560674905777\n",
      "11 133 loss: 0.0030557038262486458\n",
      "11 134 loss: 0.009125035256147385\n",
      "11 135 loss: 0.029467754065990448\n",
      "11 136 loss: 0.17351263761520386\n",
      "11 137 loss: 0.0070534637197852135\n",
      "11 138 loss: 0.024414870887994766\n",
      "11 139 loss: 0.0012135043507441878\n",
      "11 140 loss: 0.041477832943201065\n",
      "11 141 loss: 0.020787758752703667\n",
      "11 142 loss: 0.004428473301231861\n",
      "11 143 loss: 0.015306062996387482\n",
      "11 144 loss: 0.026772983372211456\n",
      "11 145 loss: 0.006108926143497229\n",
      "11 146 loss: 0.011392924934625626\n",
      "11 147 loss: 0.08049380034208298\n",
      "11 148 loss: 0.01822139322757721\n",
      "11 149 loss: 0.05360957607626915\n",
      "11 150 loss: 0.02981339767575264\n",
      "11 151 loss: 0.019895590841770172\n",
      "11 152 loss: 0.013058800250291824\n",
      "11 153 loss: 0.00821925699710846\n",
      "11 154 loss: 0.007824238389730453\n",
      "11 155 loss: 0.005729976110160351\n",
      "11 156 loss: 0.0025169469881802797\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac38c525feeb4fd09a68480abb8e5f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0 loss: 0.029916351661086082\n",
      "12 1 loss: 0.04883028194308281\n",
      "12 2 loss: 0.042883120477199554\n",
      "12 3 loss: 0.005244694650173187\n",
      "12 4 loss: 0.07145491242408752\n",
      "12 5 loss: 0.016139550134539604\n",
      "12 6 loss: 0.0037259955424815416\n",
      "12 7 loss: 0.011702166870236397\n",
      "12 8 loss: 0.029932299628853798\n",
      "12 9 loss: 0.011456155218183994\n",
      "12 10 loss: 0.04082847759127617\n",
      "12 11 loss: 0.04799315333366394\n",
      "12 12 loss: 0.0036187623627483845\n",
      "12 13 loss: 0.06162184476852417\n",
      "12 14 loss: 0.06015429645776749\n",
      "12 15 loss: 0.01085415855050087\n",
      "12 16 loss: 0.014089291915297508\n",
      "12 17 loss: 0.011352263391017914\n",
      "12 18 loss: 0.02066255733370781\n",
      "12 19 loss: 0.029193632304668427\n",
      "12 20 loss: 0.010386954993009567\n",
      "12 21 loss: 0.01796681061387062\n",
      "12 22 loss: 0.016188036650419235\n",
      "12 23 loss: 0.015294644050300121\n",
      "12 24 loss: 0.020839612931013107\n",
      "12 25 loss: 0.00658945320174098\n",
      "12 26 loss: 0.007588638924062252\n",
      "12 27 loss: 0.007846562191843987\n",
      "12 28 loss: 0.0615554004907608\n",
      "12 29 loss: 0.009978009387850761\n",
      "12 30 loss: 0.03654640167951584\n",
      "12 31 loss: 0.011759727261960506\n",
      "12 32 loss: 0.04065769910812378\n",
      "12 33 loss: 0.05564527213573456\n",
      "12 34 loss: 0.006250227801501751\n",
      "12 35 loss: 0.009167554788291454\n",
      "12 36 loss: 0.010371260344982147\n",
      "12 37 loss: 0.005584515631198883\n",
      "12 38 loss: 0.03782229125499725\n",
      "12 39 loss: 0.024710385128855705\n",
      "12 40 loss: 0.013791022822260857\n",
      "12 41 loss: 0.03375856578350067\n",
      "12 42 loss: 0.046992115676403046\n",
      "12 43 loss: 0.004096997901797295\n",
      "12 44 loss: 0.035383038222789764\n",
      "12 45 loss: 0.009097980335354805\n",
      "12 46 loss: 0.01739072985947132\n",
      "12 47 loss: 0.037993066012859344\n",
      "12 48 loss: 0.007379238959401846\n",
      "12 49 loss: 0.02963896468281746\n",
      "12 50 loss: 0.007205776404589415\n",
      "12 51 loss: 0.02440771833062172\n",
      "12 52 loss: 0.0023412900045514107\n",
      "12 53 loss: 0.004398196004331112\n",
      "12 54 loss: 0.008406565524637699\n",
      "12 55 loss: 0.016159245744347572\n",
      "12 56 loss: 0.0036710966378450394\n",
      "12 57 loss: 0.008785681799054146\n",
      "12 58 loss: 0.00892113521695137\n",
      "12 59 loss: 0.0578249953687191\n",
      "12 60 loss: 0.013602592051029205\n",
      "12 61 loss: 0.02983149327337742\n",
      "12 62 loss: 0.016367558389902115\n",
      "12 63 loss: 0.06265443563461304\n",
      "12 64 loss: 0.0048704491928219795\n",
      "12 65 loss: 0.005265271756798029\n",
      "12 66 loss: 0.02228568308055401\n",
      "12 67 loss: 0.023798689246177673\n",
      "12 68 loss: 0.025411203503608704\n",
      "12 69 loss: 0.06043355539441109\n",
      "12 70 loss: 0.020483214408159256\n",
      "12 71 loss: 0.03135395422577858\n",
      "12 72 loss: 0.050585221499204636\n",
      "12 73 loss: 0.04935487359762192\n",
      "12 74 loss: 0.027579009532928467\n",
      "12 75 loss: 0.03067645989358425\n",
      "12 76 loss: 0.004423930309712887\n",
      "12 77 loss: 0.030024226754903793\n",
      "12 78 loss: 0.026734061539173126\n",
      "12 79 loss: 0.02220028266310692\n",
      "12 80 loss: 0.009275398217141628\n",
      "12 81 loss: 0.0019409984815865755\n",
      "12 82 loss: 0.003510955721139908\n",
      "12 83 loss: 0.004535153042525053\n",
      "12 84 loss: 0.013760194182395935\n",
      "12 85 loss: 0.004203233867883682\n",
      "12 86 loss: 0.014311613515019417\n",
      "12 87 loss: 0.08157409727573395\n",
      "12 88 loss: 0.012887850403785706\n",
      "12 89 loss: 0.002915184712037444\n",
      "12 90 loss: 0.02579658105969429\n",
      "12 91 loss: 0.07796621322631836\n",
      "12 92 loss: 0.013220202177762985\n",
      "12 93 loss: 0.02114671654999256\n",
      "12 94 loss: 0.024358712136745453\n",
      "12 95 loss: 0.004423888400197029\n",
      "12 96 loss: 0.043314799666404724\n",
      "12 97 loss: 0.0126836271956563\n",
      "12 98 loss: 0.006302729249000549\n",
      "12 99 loss: 0.02951209433376789\n",
      "12 100 loss: 0.010196983814239502\n",
      "12 101 loss: 0.009332604706287384\n",
      "12 102 loss: 0.012980276718735695\n",
      "12 103 loss: 0.06252297759056091\n",
      "12 104 loss: 0.009350361302495003\n",
      "12 105 loss: 0.021738486364483833\n",
      "12 106 loss: 0.006456857081502676\n",
      "12 107 loss: 0.02633313089609146\n",
      "12 108 loss: 0.009087772108614445\n",
      "12 109 loss: 0.009008264169096947\n",
      "12 110 loss: 0.03309551626443863\n",
      "12 111 loss: 0.010494335554540157\n",
      "12 112 loss: 0.0051526715978980064\n",
      "12 113 loss: 0.005139785818755627\n",
      "12 114 loss: 0.05016007274389267\n",
      "12 115 loss: 0.003384496085345745\n",
      "12 116 loss: 0.015147787518799305\n",
      "12 117 loss: 0.009455865249037743\n",
      "12 118 loss: 0.003954310901463032\n",
      "12 119 loss: 0.006882575806230307\n",
      "12 120 loss: 0.02349507436156273\n",
      "12 121 loss: 0.01971549727022648\n",
      "12 122 loss: 0.005553956143558025\n",
      "12 123 loss: 0.004713341593742371\n",
      "12 124 loss: 0.010192026384174824\n",
      "12 125 loss: 0.008643855340778828\n",
      "12 126 loss: 0.007211457006633282\n",
      "12 127 loss: 0.0035675494000315666\n",
      "12 128 loss: 0.017719866707921028\n",
      "12 129 loss: 0.010476542636752129\n",
      "12 130 loss: 0.05337943509221077\n",
      "12 131 loss: 0.004365180619060993\n",
      "12 132 loss: 0.004182889591902494\n",
      "12 133 loss: 0.023827267810702324\n",
      "12 134 loss: 0.026706023141741753\n",
      "12 135 loss: 0.09616512060165405\n",
      "12 136 loss: 0.010891713201999664\n",
      "12 137 loss: 0.0292330551892519\n",
      "12 138 loss: 0.010517619550228119\n",
      "12 139 loss: 0.006333606317639351\n",
      "12 140 loss: 0.009445618838071823\n",
      "12 141 loss: 0.05612762272357941\n",
      "12 142 loss: 0.01848546229302883\n",
      "12 143 loss: 0.009599137119948864\n",
      "12 144 loss: 0.014595785178244114\n",
      "12 145 loss: 0.0418037548661232\n",
      "12 146 loss: 0.006311958655714989\n",
      "12 147 loss: 0.009110990911722183\n",
      "12 148 loss: 0.03388385847210884\n",
      "12 149 loss: 0.005753458011895418\n",
      "12 150 loss: 0.01180056668817997\n",
      "12 151 loss: 0.012468742206692696\n",
      "12 152 loss: 0.1499515026807785\n",
      "12 153 loss: 0.04600892215967178\n",
      "12 154 loss: 0.003090775106102228\n",
      "12 155 loss: 0.02120620384812355\n",
      "12 156 loss: 0.02751871943473816\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5fca7bc60c442d8919911b274e472a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0 loss: 0.04760999605059624\n",
      "13 1 loss: 0.0170699842274189\n",
      "13 2 loss: 0.004491719417273998\n",
      "13 3 loss: 0.012677524238824844\n",
      "13 4 loss: 0.02276463806629181\n",
      "13 5 loss: 0.033223871141672134\n",
      "13 6 loss: 0.023541584610939026\n",
      "13 7 loss: 0.029930109158158302\n",
      "13 8 loss: 0.025038618594408035\n",
      "13 9 loss: 0.058064065873622894\n",
      "13 10 loss: 0.033287111669778824\n",
      "13 11 loss: 0.01282153744250536\n",
      "13 12 loss: 0.005177818704396486\n",
      "13 13 loss: 0.02468588948249817\n",
      "13 14 loss: 0.005226475652307272\n",
      "13 15 loss: 0.007574885617941618\n",
      "13 16 loss: 0.010692753829061985\n",
      "13 17 loss: 0.027250099927186966\n",
      "13 18 loss: 0.026820186525583267\n",
      "13 19 loss: 0.004754466470330954\n",
      "13 20 loss: 0.004282950423657894\n",
      "13 21 loss: 0.05210544914007187\n",
      "13 22 loss: 0.02256068028509617\n",
      "13 23 loss: 0.07147667557001114\n",
      "13 24 loss: 0.002902928739786148\n",
      "13 25 loss: 0.020792335271835327\n",
      "13 26 loss: 0.03495807945728302\n",
      "13 27 loss: 0.06698931753635406\n",
      "13 28 loss: 0.0033412992488592863\n",
      "13 29 loss: 0.004540720954537392\n",
      "13 30 loss: 0.003286936553195119\n",
      "13 31 loss: 0.003204528009518981\n",
      "13 32 loss: 0.008802607655525208\n",
      "13 33 loss: 0.001892618602141738\n",
      "13 34 loss: 0.006252061575651169\n",
      "13 35 loss: 0.0038683887105435133\n",
      "13 36 loss: 0.025065330788493156\n",
      "13 37 loss: 0.0021260420326143503\n",
      "13 38 loss: 0.02933507412672043\n",
      "13 39 loss: 0.038746025413274765\n",
      "13 40 loss: 0.0029672374948859215\n",
      "13 41 loss: 0.007333613932132721\n",
      "13 42 loss: 0.02654343657195568\n",
      "13 43 loss: 0.0038914168253540993\n",
      "13 44 loss: 0.006133462302386761\n",
      "13 45 loss: 0.009739983826875687\n",
      "13 46 loss: 0.0127878338098526\n",
      "13 47 loss: 0.005010948516428471\n",
      "13 48 loss: 0.0036197248846292496\n",
      "13 49 loss: 0.02597784996032715\n",
      "13 50 loss: 0.057213932275772095\n",
      "13 51 loss: 0.010392606258392334\n",
      "13 52 loss: 0.0009483619360253215\n",
      "13 53 loss: 0.02618645690381527\n",
      "13 54 loss: 0.02245035581290722\n",
      "13 55 loss: 0.012534679844975471\n",
      "13 56 loss: 0.004860386718064547\n",
      "13 57 loss: 0.05000673234462738\n",
      "13 58 loss: 0.005074105225503445\n",
      "13 59 loss: 0.004499831702560186\n",
      "13 60 loss: 0.01203574426472187\n",
      "13 61 loss: 0.009651503525674343\n",
      "13 62 loss: 0.03513187915086746\n",
      "13 63 loss: 0.032936885952949524\n",
      "13 64 loss: 0.0021293489262461662\n",
      "13 65 loss: 0.011355718597769737\n",
      "13 66 loss: 0.043657027184963226\n",
      "13 67 loss: 0.04681519418954849\n",
      "13 68 loss: 0.0040227328427135944\n",
      "13 69 loss: 0.028218301013112068\n",
      "13 70 loss: 0.014843879267573357\n",
      "13 71 loss: 0.005314357578754425\n",
      "13 72 loss: 0.039337337017059326\n",
      "13 73 loss: 0.002169362735003233\n",
      "13 74 loss: 0.0024763247929513454\n",
      "13 75 loss: 0.0023516598157584667\n",
      "13 76 loss: 0.05260462313890457\n",
      "13 77 loss: 0.014284341596066952\n",
      "13 78 loss: 0.003619341179728508\n",
      "13 79 loss: 0.04256567731499672\n",
      "13 80 loss: 0.017992336302995682\n",
      "13 81 loss: 0.05830147862434387\n",
      "13 82 loss: 0.02772844210267067\n",
      "13 83 loss: 0.005396388471126556\n",
      "13 84 loss: 0.044756751507520676\n",
      "13 85 loss: 0.03244529664516449\n",
      "13 86 loss: 0.06748078763484955\n",
      "13 87 loss: 0.063802570104599\n",
      "13 88 loss: 0.016310010105371475\n",
      "13 89 loss: 0.03224696218967438\n",
      "13 90 loss: 0.025875724852085114\n",
      "13 91 loss: 0.019310256466269493\n",
      "13 92 loss: 0.015110066160559654\n",
      "13 93 loss: 0.03159959614276886\n",
      "13 94 loss: 0.020452100783586502\n",
      "13 95 loss: 0.00505667133256793\n",
      "13 96 loss: 0.00832574162632227\n",
      "13 97 loss: 0.014856122434139252\n",
      "13 98 loss: 0.003366264281794429\n",
      "13 99 loss: 0.006367535330355167\n",
      "13 100 loss: 0.08505423367023468\n",
      "13 101 loss: 0.01577381044626236\n",
      "13 102 loss: 0.012895568273961544\n",
      "13 103 loss: 0.011482106521725655\n",
      "13 104 loss: 0.015604650601744652\n",
      "13 105 loss: 0.010075986385345459\n",
      "13 106 loss: 0.05270279198884964\n",
      "13 107 loss: 0.04905188828706741\n",
      "13 108 loss: 0.028731735423207283\n",
      "13 109 loss: 0.05571281909942627\n",
      "13 110 loss: 0.07401403039693832\n",
      "13 111 loss: 0.029281623661518097\n",
      "13 112 loss: 0.00402720645070076\n",
      "13 113 loss: 0.007562924176454544\n",
      "13 114 loss: 0.008351157419383526\n",
      "13 115 loss: 0.007084516808390617\n",
      "13 116 loss: 0.03394201397895813\n",
      "13 117 loss: 0.007382978685200214\n",
      "13 118 loss: 0.026993772014975548\n",
      "13 119 loss: 0.010283544659614563\n",
      "13 120 loss: 0.01865135133266449\n",
      "13 121 loss: 0.008505399338901043\n",
      "13 122 loss: 0.02173604443669319\n",
      "13 123 loss: 0.018620019778609276\n",
      "13 124 loss: 0.06809918582439423\n",
      "13 125 loss: 0.007216852158308029\n",
      "13 126 loss: 0.049815885722637177\n",
      "13 127 loss: 0.011843729764223099\n",
      "13 128 loss: 0.01742800883948803\n",
      "13 129 loss: 0.019186433404684067\n",
      "13 130 loss: 0.0034273338969796896\n",
      "13 131 loss: 0.043306127190589905\n",
      "13 132 loss: 0.02053837850689888\n",
      "13 133 loss: 0.025178372859954834\n",
      "13 134 loss: 0.006567132193595171\n",
      "13 135 loss: 0.005823192186653614\n",
      "13 136 loss: 0.01382293552160263\n",
      "13 137 loss: 0.014281029812991619\n",
      "13 138 loss: 0.005308008752763271\n",
      "13 139 loss: 0.02184503711760044\n",
      "13 140 loss: 0.005513682495802641\n",
      "13 141 loss: 0.027146516367793083\n",
      "13 142 loss: 0.049411188811063766\n",
      "13 143 loss: 0.0026399772614240646\n",
      "13 144 loss: 0.08673013746738434\n",
      "13 145 loss: 0.030532091856002808\n",
      "13 146 loss: 0.01842447929084301\n",
      "13 147 loss: 0.03443247824907303\n",
      "13 148 loss: 0.011695814318954945\n",
      "13 149 loss: 0.0034643737599253654\n",
      "13 150 loss: 0.0429355762898922\n",
      "13 151 loss: 0.017810868099331856\n",
      "13 152 loss: 0.03633292019367218\n",
      "13 153 loss: 0.06283745914697647\n",
      "13 154 loss: 0.01144473161548376\n",
      "13 155 loss: 0.02638598531484604\n",
      "13 156 loss: 0.019288012757897377\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31d8791032e492282f71eaafdc07e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0 loss: 0.0359623059630394\n",
      "14 1 loss: 0.016492486000061035\n",
      "14 2 loss: 0.010748440399765968\n",
      "14 3 loss: 0.008042202331125736\n",
      "14 4 loss: 0.029127484187483788\n",
      "14 5 loss: 0.004990881308913231\n",
      "14 6 loss: 0.0030853913631290197\n",
      "14 7 loss: 0.03264922276139259\n",
      "14 8 loss: 0.021675433963537216\n",
      "14 9 loss: 0.01169782504439354\n",
      "14 10 loss: 0.01554439589381218\n",
      "14 11 loss: 0.00428187008947134\n",
      "14 12 loss: 0.05127329006791115\n",
      "14 13 loss: 0.005650169216096401\n",
      "14 14 loss: 0.016932273283600807\n",
      "14 15 loss: 0.004895716439932585\n",
      "14 16 loss: 0.020112039521336555\n",
      "14 17 loss: 0.006318350788205862\n",
      "14 18 loss: 0.06385671347379684\n",
      "14 19 loss: 0.004705274011939764\n",
      "14 20 loss: 0.014875989407300949\n",
      "14 21 loss: 0.006163470447063446\n",
      "14 22 loss: 0.017313098534941673\n",
      "14 23 loss: 0.00583972642198205\n",
      "14 24 loss: 0.030625788494944572\n",
      "14 25 loss: 0.0017341577913612127\n",
      "14 26 loss: 0.039740413427352905\n",
      "14 27 loss: 0.03272214159369469\n",
      "14 28 loss: 0.023510653525590897\n",
      "14 29 loss: 0.06718029826879501\n",
      "14 30 loss: 0.005185908637940884\n",
      "14 31 loss: 0.009438655339181423\n",
      "14 32 loss: 0.008822258561849594\n",
      "14 33 loss: 0.046193014830350876\n",
      "14 34 loss: 0.02124318853020668\n",
      "14 35 loss: 0.015207789838314056\n",
      "14 36 loss: 0.007450539618730545\n",
      "14 37 loss: 0.00903034396469593\n",
      "14 38 loss: 0.017695682123303413\n",
      "14 39 loss: 0.006770094856619835\n",
      "14 40 loss: 0.01705925539135933\n",
      "14 41 loss: 0.053032707422971725\n",
      "14 42 loss: 0.007871193811297417\n",
      "14 43 loss: 0.009278554469347\n",
      "14 44 loss: 0.0986480861902237\n",
      "14 45 loss: 0.03326999768614769\n",
      "14 46 loss: 0.019092971459031105\n",
      "14 47 loss: 0.019229520112276077\n",
      "14 48 loss: 0.007768428418785334\n",
      "14 49 loss: 0.023729193955659866\n",
      "14 50 loss: 0.019648445770144463\n",
      "14 51 loss: 0.003918138798326254\n",
      "14 52 loss: 0.03038257732987404\n",
      "14 53 loss: 0.011563979089260101\n",
      "14 54 loss: 0.01052046101540327\n",
      "14 55 loss: 0.020581671968102455\n",
      "14 56 loss: 0.031202560290694237\n",
      "14 57 loss: 0.009339719079434872\n",
      "14 58 loss: 0.04105524718761444\n",
      "14 59 loss: 0.005566634237766266\n",
      "14 60 loss: 0.013097680173814297\n",
      "14 61 loss: 0.0013954442692920566\n",
      "14 62 loss: 0.014111869037151337\n",
      "14 63 loss: 0.0034915513824671507\n",
      "14 64 loss: 0.002428554929792881\n",
      "14 65 loss: 0.05323507636785507\n",
      "14 66 loss: 0.0028463408816605806\n",
      "14 67 loss: 0.05044582486152649\n",
      "14 68 loss: 0.030048422515392303\n",
      "14 69 loss: 0.002614707686007023\n",
      "14 70 loss: 0.014576959423720837\n",
      "14 71 loss: 0.00587155856192112\n",
      "14 72 loss: 0.005157021805644035\n",
      "14 73 loss: 0.04641922563314438\n",
      "14 74 loss: 0.015903998166322708\n",
      "14 75 loss: 0.019375648349523544\n",
      "14 76 loss: 0.004148462787270546\n",
      "14 77 loss: 0.004533825442194939\n",
      "14 78 loss: 0.040282417088747025\n",
      "14 79 loss: 0.025417136028409004\n",
      "14 80 loss: 0.011204720474779606\n",
      "14 81 loss: 0.0046903290785849094\n",
      "14 82 loss: 0.00560738006606698\n",
      "14 83 loss: 0.013268798589706421\n",
      "14 84 loss: 0.03138440102338791\n",
      "14 85 loss: 0.03448512777686119\n",
      "14 86 loss: 0.009306970983743668\n",
      "14 87 loss: 0.02933880314230919\n",
      "14 88 loss: 0.011962131597101688\n",
      "14 89 loss: 0.025773100554943085\n",
      "14 90 loss: 0.024891749024391174\n",
      "14 91 loss: 0.012397090904414654\n",
      "14 92 loss: 0.006029549054801464\n",
      "14 93 loss: 0.08469709753990173\n",
      "14 94 loss: 0.04028172791004181\n",
      "14 95 loss: 0.007935957983136177\n",
      "14 96 loss: 0.040894296020269394\n",
      "14 97 loss: 0.019764665514230728\n",
      "14 98 loss: 0.019718119874596596\n",
      "14 99 loss: 0.030326060950756073\n",
      "14 100 loss: 0.005751827731728554\n",
      "14 101 loss: 0.005566145293414593\n",
      "14 102 loss: 0.007819595746695995\n",
      "14 103 loss: 0.01031519379466772\n",
      "14 104 loss: 0.013120041228830814\n",
      "14 105 loss: 0.03462674841284752\n",
      "14 106 loss: 0.05725157633423805\n",
      "14 107 loss: 0.005750834941864014\n",
      "14 108 loss: 0.03346496447920799\n",
      "14 109 loss: 0.04976210370659828\n",
      "14 110 loss: 0.07957077026367188\n",
      "14 111 loss: 0.031575676053762436\n",
      "14 112 loss: 0.019640281796455383\n",
      "14 113 loss: 0.02256012335419655\n",
      "14 114 loss: 0.009778321720659733\n",
      "14 115 loss: 0.00848638080060482\n",
      "14 116 loss: 0.008816768415272236\n",
      "14 117 loss: 0.06195387244224548\n",
      "14 118 loss: 0.042248278856277466\n",
      "14 119 loss: 0.011419753544032574\n",
      "14 120 loss: 0.021717671304941177\n",
      "14 121 loss: 0.03486868366599083\n",
      "14 122 loss: 0.04393400996923447\n",
      "14 123 loss: 0.02654457464814186\n",
      "14 124 loss: 0.0024229143746197224\n",
      "14 125 loss: 0.052937932312488556\n",
      "14 126 loss: 0.016768112778663635\n",
      "14 127 loss: 0.0035495359916239977\n",
      "14 128 loss: 0.010891200043261051\n",
      "14 129 loss: 0.03733447194099426\n",
      "14 130 loss: 0.01465316116809845\n",
      "14 131 loss: 0.013701154850423336\n",
      "14 132 loss: 0.008031078614294529\n",
      "14 133 loss: 0.04349435493350029\n",
      "14 134 loss: 0.011669952422380447\n",
      "14 135 loss: 0.03749499469995499\n",
      "14 136 loss: 0.02647458016872406\n",
      "14 137 loss: 0.016971543431282043\n",
      "14 138 loss: 0.0456475168466568\n",
      "14 139 loss: 0.00610409677028656\n",
      "14 140 loss: 0.05210879445075989\n",
      "14 141 loss: 0.009092967957258224\n",
      "14 142 loss: 0.03492215275764465\n",
      "14 143 loss: 0.009009966626763344\n",
      "14 144 loss: 0.01793292909860611\n",
      "14 145 loss: 0.016571180894970894\n",
      "14 146 loss: 0.01369734387844801\n",
      "14 147 loss: 0.004884019028395414\n",
      "14 148 loss: 0.026066666468977928\n",
      "14 149 loss: 0.02477356046438217\n",
      "14 150 loss: 0.002547132782638073\n",
      "14 151 loss: 0.025949306786060333\n",
      "14 152 loss: 0.06620457768440247\n",
      "14 153 loss: 0.022666042670607567\n",
      "14 154 loss: 0.001301838201470673\n",
      "14 155 loss: 0.006038526073098183\n",
      "14 156 loss: 0.021663600578904152\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05810f622c70400abeeb8d746cf68883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0 loss: 0.016132349148392677\n",
      "15 1 loss: 0.019633624702692032\n",
      "15 2 loss: 0.009956777095794678\n",
      "15 3 loss: 0.06264014542102814\n",
      "15 4 loss: 0.01763732358813286\n",
      "15 5 loss: 0.04868914186954498\n",
      "15 6 loss: 0.04718106985092163\n",
      "15 7 loss: 0.00451330840587616\n",
      "15 8 loss: 0.016913289204239845\n",
      "15 9 loss: 0.0211776215583086\n",
      "15 10 loss: 0.0073265815153717995\n",
      "15 11 loss: 0.03949533402919769\n",
      "15 12 loss: 0.00746883125975728\n",
      "15 13 loss: 0.006620741914957762\n",
      "15 14 loss: 0.06566458940505981\n",
      "15 15 loss: 0.019524075090885162\n",
      "15 16 loss: 0.046373240649700165\n",
      "15 17 loss: 0.007143630646169186\n",
      "15 18 loss: 0.014811450615525246\n",
      "15 19 loss: 0.030913684517145157\n",
      "15 20 loss: 0.05016893893480301\n",
      "15 21 loss: 0.04424656182527542\n",
      "15 22 loss: 0.045241087675094604\n",
      "15 23 loss: 0.008667456917464733\n",
      "15 24 loss: 0.01180030032992363\n",
      "15 25 loss: 0.0041078487411141396\n",
      "15 26 loss: 0.012967105954885483\n",
      "15 27 loss: 0.022789618000388145\n",
      "15 28 loss: 0.026702117174863815\n",
      "15 29 loss: 0.010751083493232727\n",
      "15 30 loss: 0.026256419718265533\n",
      "15 31 loss: 0.008296719752252102\n",
      "15 32 loss: 0.04792135953903198\n",
      "15 33 loss: 0.0037446029018610716\n",
      "15 34 loss: 0.020309705287218094\n",
      "15 35 loss: 0.0039614057168364525\n",
      "15 36 loss: 0.10155175626277924\n",
      "15 37 loss: 0.01353052444756031\n",
      "15 38 loss: 0.005917114205658436\n",
      "15 39 loss: 0.02641035057604313\n",
      "15 40 loss: 0.0039091394282877445\n",
      "15 41 loss: 0.05071765184402466\n",
      "15 42 loss: 0.0011766424868255854\n",
      "15 43 loss: 0.061295539140701294\n",
      "15 44 loss: 0.00741588743403554\n",
      "15 45 loss: 0.009809293784201145\n",
      "15 46 loss: 0.005834916606545448\n",
      "15 47 loss: 0.03184427320957184\n",
      "15 48 loss: 0.033396556973457336\n",
      "15 49 loss: 0.008935829624533653\n",
      "15 50 loss: 0.032637517899274826\n",
      "15 51 loss: 0.05241180956363678\n",
      "15 52 loss: 0.01737380214035511\n",
      "15 53 loss: 0.012954301200807095\n",
      "15 54 loss: 0.004190963692963123\n",
      "15 55 loss: 0.0033921939320862293\n",
      "15 56 loss: 0.04179534316062927\n",
      "15 57 loss: 0.05195252224802971\n",
      "15 58 loss: 0.01746630296111107\n",
      "15 59 loss: 0.01989244669675827\n",
      "15 60 loss: 0.012383718974888325\n",
      "15 61 loss: 0.009456786327064037\n",
      "15 62 loss: 0.06771786510944366\n",
      "15 63 loss: 0.03782157227396965\n",
      "15 64 loss: 0.016309764236211777\n",
      "15 65 loss: 0.028002848848700523\n",
      "15 66 loss: 0.02397768199443817\n",
      "15 67 loss: 0.025914810597896576\n",
      "15 68 loss: 0.012049886398017406\n",
      "15 69 loss: 0.03648867830634117\n",
      "15 70 loss: 0.05515189468860626\n",
      "15 71 loss: 0.014204530045390129\n",
      "15 72 loss: 0.01768188364803791\n",
      "15 73 loss: 0.023714404553174973\n",
      "15 74 loss: 0.03024599701166153\n",
      "15 75 loss: 0.06795134395360947\n",
      "15 76 loss: 0.02856474369764328\n",
      "15 77 loss: 0.047034598886966705\n",
      "15 78 loss: 0.006581106223165989\n",
      "15 79 loss: 0.014367268420755863\n",
      "15 80 loss: 0.010628433898091316\n",
      "15 81 loss: 0.0041128299199044704\n",
      "15 82 loss: 0.025724442675709724\n",
      "15 83 loss: 0.0451110303401947\n",
      "15 84 loss: 0.028031254187226295\n",
      "15 85 loss: 0.02242697775363922\n",
      "15 86 loss: 0.0373220294713974\n",
      "15 87 loss: 0.029880616813898087\n",
      "15 88 loss: 0.0018021591240540147\n",
      "15 89 loss: 0.021518032997846603\n",
      "15 90 loss: 0.011077008210122585\n",
      "15 91 loss: 0.010781407356262207\n",
      "15 92 loss: 0.021991334855556488\n",
      "15 93 loss: 0.011252820491790771\n",
      "15 94 loss: 0.013134615495800972\n",
      "15 95 loss: 0.016993556171655655\n",
      "15 96 loss: 0.04681643843650818\n",
      "15 97 loss: 0.003183117602020502\n",
      "15 98 loss: 0.02066064067184925\n",
      "15 99 loss: 0.03573567420244217\n",
      "15 100 loss: 0.002175537869334221\n",
      "15 101 loss: 0.006982570979744196\n",
      "15 102 loss: 0.04924565181136131\n",
      "15 103 loss: 0.022259419783949852\n",
      "15 104 loss: 0.001255146460607648\n",
      "15 105 loss: 0.013730009086430073\n",
      "15 106 loss: 0.062068626284599304\n",
      "15 107 loss: 0.004134196788072586\n",
      "15 108 loss: 0.02243623323738575\n",
      "15 109 loss: 0.01378406397998333\n",
      "15 110 loss: 0.032955750823020935\n",
      "15 111 loss: 0.008547119796276093\n",
      "15 112 loss: 0.029702771455049515\n",
      "15 113 loss: 0.10976893454790115\n",
      "15 114 loss: 0.03321593254804611\n",
      "15 115 loss: 0.04381056874990463\n",
      "15 116 loss: 0.014711916446685791\n",
      "15 117 loss: 0.026289571076631546\n",
      "15 118 loss: 0.06179053708910942\n",
      "15 119 loss: 0.015624893829226494\n",
      "15 120 loss: 0.024252161383628845\n",
      "15 121 loss: 0.06017012521624565\n",
      "15 122 loss: 0.011171303689479828\n",
      "15 123 loss: 0.0075308782979846\n",
      "15 124 loss: 0.00644521601498127\n",
      "15 125 loss: 0.007572818081825972\n",
      "15 126 loss: 0.03848429396748543\n",
      "15 127 loss: 0.07214397192001343\n",
      "15 128 loss: 0.0055935196578502655\n",
      "15 129 loss: 0.00971207581460476\n",
      "15 130 loss: 0.019282877445220947\n",
      "15 131 loss: 0.008011255413293839\n",
      "15 132 loss: 0.00780558492988348\n",
      "15 133 loss: 0.009789707139134407\n",
      "15 134 loss: 0.03384974226355553\n",
      "15 135 loss: 0.005800645798444748\n",
      "15 136 loss: 0.025899555534124374\n",
      "15 137 loss: 0.03573242202401161\n",
      "15 138 loss: 0.006206085905432701\n",
      "15 139 loss: 0.025166615843772888\n",
      "15 140 loss: 0.014202754013240337\n",
      "15 141 loss: 0.006048801355063915\n",
      "15 142 loss: 0.011385515332221985\n",
      "15 143 loss: 0.009840583428740501\n",
      "15 144 loss: 0.016306212171912193\n",
      "15 145 loss: 0.035762663930654526\n",
      "15 146 loss: 0.00639510340988636\n",
      "15 147 loss: 0.060218989849090576\n",
      "15 148 loss: 0.018147636204957962\n",
      "15 149 loss: 0.08967659622430801\n",
      "15 150 loss: 0.008366110734641552\n",
      "15 151 loss: 0.03159753978252411\n",
      "15 152 loss: 0.0011243617627769709\n",
      "15 153 loss: 0.014256585389375687\n",
      "15 154 loss: 0.01079484075307846\n",
      "15 155 loss: 0.006500956602394581\n",
      "15 156 loss: 0.004628439899533987\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a8a16e1cce43c2a55e0fe351a767a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0 loss: 0.04864274710416794\n",
      "16 1 loss: 0.027984417974948883\n",
      "16 2 loss: 0.016227353364229202\n",
      "16 3 loss: 0.010042005218565464\n",
      "16 4 loss: 0.03797171264886856\n",
      "16 5 loss: 0.011492272838950157\n",
      "16 6 loss: 0.037179309874773026\n",
      "16 7 loss: 0.01614748314023018\n",
      "16 8 loss: 0.021946489810943604\n",
      "16 9 loss: 0.003846596460789442\n",
      "16 10 loss: 0.0464341938495636\n",
      "16 11 loss: 0.003937932662665844\n",
      "16 12 loss: 0.05256015434861183\n",
      "16 13 loss: 0.0029495744965970516\n",
      "16 14 loss: 0.19120439887046814\n",
      "16 15 loss: 0.005038367118686438\n",
      "16 16 loss: 0.01264746394008398\n",
      "16 17 loss: 0.010814584791660309\n",
      "16 18 loss: 0.025668958202004433\n",
      "16 19 loss: 0.01106431894004345\n",
      "16 20 loss: 0.005725773051381111\n",
      "16 21 loss: 0.0254109725356102\n",
      "16 22 loss: 0.00818356592208147\n",
      "16 23 loss: 0.05114708095788956\n",
      "16 24 loss: 0.006027440074831247\n",
      "16 25 loss: 0.018530581146478653\n",
      "16 26 loss: 0.017004642635583878\n",
      "16 27 loss: 0.012177307158708572\n",
      "16 28 loss: 0.011637142859399319\n",
      "16 29 loss: 0.045955926179885864\n",
      "16 30 loss: 0.02625936269760132\n",
      "16 31 loss: 0.023857001215219498\n",
      "16 32 loss: 0.01694619283080101\n",
      "16 33 loss: 0.04783051833510399\n",
      "16 34 loss: 0.03717619925737381\n",
      "16 35 loss: 0.0070615606382489204\n",
      "16 36 loss: 0.0035675768740475178\n",
      "16 37 loss: 0.01579887419939041\n",
      "16 38 loss: 0.004795743152499199\n",
      "16 39 loss: 0.013627296313643456\n",
      "16 40 loss: 0.006902678869664669\n",
      "16 41 loss: 0.004791677463799715\n",
      "16 42 loss: 0.06543617695569992\n",
      "16 43 loss: 0.002749310340732336\n",
      "16 44 loss: 0.02140873111784458\n",
      "16 45 loss: 0.04022578150033951\n",
      "16 46 loss: 0.0056260861456394196\n",
      "16 47 loss: 0.004481355659663677\n",
      "16 48 loss: 0.008343489840626717\n",
      "16 49 loss: 0.015895627439022064\n",
      "16 50 loss: 0.005481022410094738\n",
      "16 51 loss: 0.014924025163054466\n",
      "16 52 loss: 0.04452134296298027\n",
      "16 53 loss: 0.004332621581852436\n",
      "16 54 loss: 0.08652593195438385\n",
      "16 55 loss: 0.005946367979049683\n",
      "16 56 loss: 0.008662295527756214\n",
      "16 57 loss: 0.015546140260994434\n",
      "16 58 loss: 0.03576253354549408\n",
      "16 59 loss: 0.0687037855386734\n",
      "16 60 loss: 0.04696236923336983\n",
      "16 61 loss: 0.004444983787834644\n",
      "16 62 loss: 0.0021324767731130123\n",
      "16 63 loss: 0.01434086263179779\n",
      "16 64 loss: 0.03233309090137482\n",
      "16 65 loss: 0.0254349485039711\n",
      "16 66 loss: 0.02097320184111595\n",
      "16 67 loss: 0.00867337267845869\n",
      "16 68 loss: 0.03349912911653519\n",
      "16 69 loss: 0.04446682333946228\n",
      "16 70 loss: 0.060437530279159546\n",
      "16 71 loss: 0.00798709411174059\n",
      "16 72 loss: 0.08344854414463043\n",
      "16 73 loss: 0.0021249051205813885\n",
      "16 74 loss: 0.015221438370645046\n",
      "16 75 loss: 0.002083228435367346\n",
      "16 76 loss: 0.012945455498993397\n",
      "16 77 loss: 0.03509904071688652\n",
      "16 78 loss: 0.006524275988340378\n",
      "16 79 loss: 0.19105756282806396\n",
      "16 80 loss: 0.003379218280315399\n",
      "16 81 loss: 0.01201553177088499\n",
      "16 82 loss: 0.03393986448645592\n",
      "16 83 loss: 0.02485823817551136\n",
      "16 84 loss: 0.03027624636888504\n",
      "16 85 loss: 0.039449505507946014\n",
      "16 86 loss: 0.06348878145217896\n",
      "16 87 loss: 0.07512083649635315\n",
      "16 88 loss: 0.009026669897139072\n",
      "16 89 loss: 0.010641643777489662\n",
      "16 90 loss: 0.023409631103277206\n",
      "16 91 loss: 0.017376601696014404\n",
      "16 92 loss: 0.025335155427455902\n",
      "16 93 loss: 0.045323628932237625\n",
      "16 94 loss: 0.017663005739450455\n",
      "16 95 loss: 0.04267202317714691\n",
      "16 96 loss: 0.03814844414591789\n",
      "16 97 loss: 0.013379637151956558\n",
      "16 98 loss: 0.02335745096206665\n",
      "16 99 loss: 0.008614923804998398\n",
      "16 100 loss: 0.0070978449657559395\n",
      "16 101 loss: 0.041074253618717194\n",
      "16 102 loss: 0.03634492680430412\n",
      "16 103 loss: 0.012432446703314781\n",
      "16 104 loss: 0.06100329011678696\n",
      "16 105 loss: 0.014587922021746635\n",
      "16 106 loss: 0.004065884277224541\n",
      "16 107 loss: 0.015111424028873444\n",
      "16 108 loss: 0.04954366013407707\n",
      "16 109 loss: 0.03953488916158676\n",
      "16 110 loss: 0.08060980588197708\n",
      "16 111 loss: 0.0066570984199643135\n",
      "16 112 loss: 0.00493668531998992\n",
      "16 113 loss: 0.03098585084080696\n",
      "16 114 loss: 0.00478010717779398\n",
      "16 115 loss: 0.029851285740733147\n",
      "16 116 loss: 0.06369386613368988\n",
      "16 117 loss: 0.07022485136985779\n",
      "16 118 loss: 0.01989584043622017\n",
      "16 119 loss: 0.05896078422665596\n",
      "16 120 loss: 0.10228164494037628\n",
      "16 121 loss: 0.010953383520245552\n",
      "16 122 loss: 0.03765108808875084\n",
      "16 123 loss: 0.023759324103593826\n",
      "16 124 loss: 0.031054574996232986\n",
      "16 125 loss: 0.03595799580216408\n",
      "16 126 loss: 0.033947933465242386\n",
      "16 127 loss: 0.010463072918355465\n",
      "16 128 loss: 0.007674547843635082\n",
      "16 129 loss: 0.027749603614211082\n",
      "16 130 loss: 0.03880245238542557\n",
      "16 131 loss: 0.04710827022790909\n",
      "16 132 loss: 0.014442749321460724\n",
      "16 133 loss: 0.08703364431858063\n",
      "16 134 loss: 0.011227134615182877\n",
      "16 135 loss: 0.011221766471862793\n",
      "16 136 loss: 0.012457836419343948\n",
      "16 137 loss: 0.032022684812545776\n",
      "16 138 loss: 0.024815980345010757\n",
      "16 139 loss: 0.00561548164114356\n",
      "16 140 loss: 0.06949738413095474\n",
      "16 141 loss: 0.003910345956683159\n",
      "16 142 loss: 0.0075445156544446945\n",
      "16 143 loss: 0.03597729653120041\n",
      "16 144 loss: 0.0049689412117004395\n",
      "16 145 loss: 0.005838990677148104\n",
      "16 146 loss: 0.009804711677134037\n",
      "16 147 loss: 0.0063691893592476845\n",
      "16 148 loss: 0.01331569254398346\n",
      "16 149 loss: 0.02486279606819153\n",
      "16 150 loss: 0.04925981163978577\n",
      "16 151 loss: 0.059895604848861694\n",
      "16 152 loss: 0.015478543937206268\n",
      "16 153 loss: 0.0036416102666407824\n",
      "16 154 loss: 0.022322112694382668\n",
      "16 155 loss: 0.008701076731085777\n",
      "16 156 loss: 0.012649929150938988\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db565035843b4eae91eafe5e9f716e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0 loss: 0.015241820365190506\n",
      "17 1 loss: 0.015142681077122688\n",
      "17 2 loss: 0.010532173328101635\n",
      "17 3 loss: 0.036985814571380615\n",
      "17 4 loss: 0.01339565496891737\n",
      "17 5 loss: 0.034761544317007065\n",
      "17 6 loss: 0.01149984821677208\n",
      "17 7 loss: 0.006217334885150194\n",
      "17 8 loss: 0.00898992270231247\n",
      "17 9 loss: 0.00696769542992115\n",
      "17 10 loss: 0.03205512836575508\n",
      "17 11 loss: 0.021624116227030754\n",
      "17 12 loss: 0.0034385903272777796\n",
      "17 13 loss: 0.009097479283809662\n",
      "17 14 loss: 0.034697361290454865\n",
      "17 15 loss: 0.028831245377659798\n",
      "17 16 loss: 0.04404667764902115\n",
      "17 17 loss: 0.0055981166660785675\n",
      "17 18 loss: 0.0023018454667180777\n",
      "17 19 loss: 0.026863744482398033\n",
      "17 20 loss: 0.004976431839168072\n",
      "17 21 loss: 0.010576024651527405\n",
      "17 22 loss: 0.055258218199014664\n",
      "17 23 loss: 0.02374935708940029\n",
      "17 24 loss: 0.016422569751739502\n",
      "17 25 loss: 0.07402121275663376\n",
      "17 26 loss: 0.008702246472239494\n",
      "17 27 loss: 0.019264088943600655\n",
      "17 28 loss: 0.005383354611694813\n",
      "17 29 loss: 0.008256454020738602\n",
      "17 30 loss: 0.01921330764889717\n",
      "17 31 loss: 0.005893354304134846\n",
      "17 32 loss: 0.01710347831249237\n",
      "17 33 loss: 0.030906839296221733\n",
      "17 34 loss: 0.005625522695481777\n",
      "17 35 loss: 0.014296965673565865\n",
      "17 36 loss: 0.0036701341159641743\n",
      "17 37 loss: 0.005394833628088236\n",
      "17 38 loss: 0.003800894832238555\n",
      "17 39 loss: 0.001292937551625073\n",
      "17 40 loss: 0.015991313382983208\n",
      "17 41 loss: 0.000949814566411078\n",
      "17 42 loss: 0.033277496695518494\n",
      "17 43 loss: 0.04174003377556801\n",
      "17 44 loss: 0.0016798689030110836\n",
      "17 45 loss: 0.03334156423807144\n",
      "17 46 loss: 0.0017489329911768436\n",
      "17 47 loss: 0.0014523613499477506\n",
      "17 48 loss: 0.005151201039552689\n",
      "17 49 loss: 0.046868883073329926\n",
      "17 50 loss: 0.01250201091170311\n",
      "17 51 loss: 0.03937675803899765\n",
      "17 52 loss: 0.010319381020963192\n",
      "17 53 loss: 0.004313869867473841\n",
      "17 54 loss: 0.032784704118967056\n",
      "17 55 loss: 0.003233309369534254\n",
      "17 56 loss: 0.0056050606071949005\n",
      "17 57 loss: 0.005133706144988537\n",
      "17 58 loss: 0.012109633535146713\n",
      "17 59 loss: 0.003479673760011792\n",
      "17 60 loss: 0.0393734946846962\n",
      "17 61 loss: 0.016651447862386703\n",
      "17 62 loss: 0.044273220002651215\n",
      "17 63 loss: 0.008606614544987679\n",
      "17 64 loss: 0.031674377620220184\n",
      "17 65 loss: 0.03826307877898216\n",
      "17 66 loss: 0.005067654885351658\n",
      "17 67 loss: 0.008526677265763283\n",
      "17 68 loss: 0.011622192338109016\n",
      "17 69 loss: 0.008013271726667881\n",
      "17 70 loss: 0.005001257639378309\n",
      "17 71 loss: 0.008604945614933968\n",
      "17 72 loss: 0.006769728846848011\n",
      "17 73 loss: 0.026996709406375885\n",
      "17 74 loss: 0.05327915400266647\n",
      "17 75 loss: 0.006636311300098896\n",
      "17 76 loss: 0.00692087784409523\n",
      "17 77 loss: 0.066911481320858\n",
      "17 78 loss: 0.036717627197504044\n",
      "17 79 loss: 0.004888102412223816\n",
      "17 80 loss: 0.001577315153554082\n",
      "17 81 loss: 0.03963422402739525\n",
      "17 82 loss: 0.0011642492609098554\n",
      "17 83 loss: 0.011240819469094276\n",
      "17 84 loss: 0.02972063608467579\n",
      "17 85 loss: 0.03865021467208862\n",
      "17 86 loss: 0.009974999353289604\n",
      "17 87 loss: 0.011356232687830925\n",
      "17 88 loss: 0.01925189606845379\n",
      "17 89 loss: 0.014554695226252079\n",
      "17 90 loss: 0.005932467058300972\n",
      "17 91 loss: 0.030499109998345375\n",
      "17 92 loss: 0.005900145508348942\n",
      "17 93 loss: 0.02067040652036667\n",
      "17 94 loss: 0.004936493467539549\n",
      "17 95 loss: 0.02180209569633007\n",
      "17 96 loss: 0.0072182901203632355\n",
      "17 97 loss: 0.010198161005973816\n",
      "17 98 loss: 0.09796719253063202\n",
      "17 99 loss: 0.021684935316443443\n",
      "17 100 loss: 0.01645728573203087\n",
      "17 101 loss: 0.00668784324079752\n",
      "17 102 loss: 0.040959298610687256\n",
      "17 103 loss: 0.005363969132304192\n",
      "17 104 loss: 0.020262857899069786\n",
      "17 105 loss: 0.02266208454966545\n",
      "17 106 loss: 0.05513752996921539\n",
      "17 107 loss: 0.0033264118246734142\n",
      "17 108 loss: 0.016343969851732254\n",
      "17 109 loss: 0.004418022930622101\n",
      "17 110 loss: 0.02633521892130375\n",
      "17 111 loss: 0.015911202877759933\n",
      "17 112 loss: 0.009458230808377266\n",
      "17 113 loss: 0.010142048820853233\n",
      "17 114 loss: 0.008818911388516426\n",
      "17 115 loss: 0.0028108032420277596\n",
      "17 116 loss: 0.004434463568031788\n",
      "17 117 loss: 0.004731971770524979\n",
      "17 118 loss: 0.04192648455500603\n",
      "17 119 loss: 0.00908204447478056\n",
      "17 120 loss: 0.0025025568902492523\n",
      "17 121 loss: 0.05645234137773514\n",
      "17 122 loss: 0.06044546142220497\n",
      "17 123 loss: 0.027676662430167198\n",
      "17 124 loss: 0.013659949414432049\n",
      "17 125 loss: 0.0015299615915864706\n",
      "17 126 loss: 0.00704758008942008\n",
      "17 127 loss: 0.008323583751916885\n",
      "17 128 loss: 0.012345973402261734\n",
      "17 129 loss: 0.014851792715489864\n",
      "17 130 loss: 0.014239625073969364\n",
      "17 131 loss: 0.008599511347711086\n",
      "17 132 loss: 0.0034858323633670807\n",
      "17 133 loss: 0.005710524041205645\n",
      "17 134 loss: 0.008027653209865093\n",
      "17 135 loss: 0.047384168952703476\n",
      "17 136 loss: 0.007556570693850517\n",
      "17 137 loss: 0.003906974568963051\n",
      "17 138 loss: 0.024836890399456024\n",
      "17 139 loss: 0.02566676214337349\n",
      "17 140 loss: 0.004562108777463436\n",
      "17 141 loss: 0.008208224549889565\n",
      "17 142 loss: 0.015095297247171402\n",
      "17 143 loss: 0.01396222598850727\n",
      "17 144 loss: 0.005014474503695965\n",
      "17 145 loss: 0.004057917278259993\n",
      "17 146 loss: 0.03385473042726517\n",
      "17 147 loss: 0.024210702627897263\n",
      "17 148 loss: 0.008076616562902927\n",
      "17 149 loss: 0.00612665293738246\n",
      "17 150 loss: 0.03179866075515747\n",
      "17 151 loss: 0.0030158953741192818\n",
      "17 152 loss: 0.018679020926356316\n",
      "17 153 loss: 0.057960394769907\n",
      "17 154 loss: 0.013396243564784527\n",
      "17 155 loss: 0.00655942689627409\n",
      "17 156 loss: 0.011983513832092285\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f07c75950e4f6ea43385a1f31f6eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0 loss: 0.026230037212371826\n",
      "18 1 loss: 0.024569228291511536\n",
      "18 2 loss: 0.025706490501761436\n",
      "18 3 loss: 0.005360372830182314\n",
      "18 4 loss: 0.027585787698626518\n",
      "18 5 loss: 0.00579645112156868\n",
      "18 6 loss: 0.024708328768610954\n",
      "18 7 loss: 0.024444537237286568\n",
      "18 8 loss: 0.005937675945460796\n",
      "18 9 loss: 0.006264766678214073\n",
      "18 10 loss: 0.006347771733999252\n",
      "18 11 loss: 0.017264889553189278\n",
      "18 12 loss: 0.007547798100858927\n",
      "18 13 loss: 0.006429760251194239\n",
      "18 14 loss: 0.02468436025083065\n",
      "18 15 loss: 0.0027236598543822765\n",
      "18 16 loss: 0.013015251606702805\n",
      "18 17 loss: 0.010268284939229488\n",
      "18 18 loss: 0.07282587140798569\n",
      "18 19 loss: 0.036649055778980255\n",
      "18 20 loss: 0.009589926339685917\n",
      "18 21 loss: 0.03994908183813095\n",
      "18 22 loss: 0.002739772666245699\n",
      "18 23 loss: 0.00969009380787611\n",
      "18 24 loss: 0.004798023495823145\n",
      "18 25 loss: 0.010519354604184628\n",
      "18 26 loss: 0.01682165637612343\n",
      "18 27 loss: 0.005340117961168289\n",
      "18 28 loss: 0.020184597000479698\n",
      "18 29 loss: 0.020036984235048294\n",
      "18 30 loss: 0.03313644975423813\n",
      "18 31 loss: 0.00469841156154871\n",
      "18 32 loss: 0.02855715900659561\n",
      "18 33 loss: 0.01255895011126995\n",
      "18 34 loss: 0.003450514981523156\n",
      "18 35 loss: 0.0030733179301023483\n",
      "18 36 loss: 0.047519501298666\n",
      "18 37 loss: 0.036835718899965286\n",
      "18 38 loss: 0.0021755555644631386\n",
      "18 39 loss: 0.027410080656409264\n",
      "18 40 loss: 0.046785302460193634\n",
      "18 41 loss: 0.01360873319208622\n",
      "18 42 loss: 0.042594972997903824\n",
      "18 43 loss: 0.019333690404891968\n",
      "18 44 loss: 0.018337329849600792\n",
      "18 45 loss: 0.007600112818181515\n",
      "18 46 loss: 0.03479927033185959\n",
      "18 47 loss: 0.04178491607308388\n",
      "18 48 loss: 0.003934399224817753\n",
      "18 49 loss: 0.04226923733949661\n",
      "18 50 loss: 0.0010009619873017073\n",
      "18 51 loss: 0.08156628906726837\n",
      "18 52 loss: 0.0032351468689739704\n",
      "18 53 loss: 0.004274995997548103\n",
      "18 54 loss: 0.1411685347557068\n",
      "18 55 loss: 0.12095117568969727\n",
      "18 56 loss: 0.030248360708355904\n",
      "18 57 loss: 0.031515855342149734\n",
      "18 58 loss: 0.0026660102885216475\n",
      "18 59 loss: 0.004248069599270821\n",
      "18 60 loss: 0.013360047712922096\n",
      "18 61 loss: 0.018166182562708855\n",
      "18 62 loss: 0.012014349922537804\n",
      "18 63 loss: 0.03926600515842438\n",
      "18 64 loss: 0.006869925186038017\n",
      "18 65 loss: 0.0538567379117012\n",
      "18 66 loss: 0.01018573809415102\n",
      "18 67 loss: 0.014207795262336731\n",
      "18 68 loss: 0.018182411789894104\n",
      "18 69 loss: 0.0031171697191894054\n",
      "18 70 loss: 0.03256718069314957\n",
      "18 71 loss: 0.00430690310895443\n",
      "18 72 loss: 0.0028710816986858845\n",
      "18 73 loss: 0.005731936544179916\n",
      "18 74 loss: 0.004534965846687555\n",
      "18 75 loss: 0.00879568513482809\n",
      "18 76 loss: 0.021956391632556915\n",
      "18 77 loss: 0.004527384415268898\n",
      "18 78 loss: 0.015762144699692726\n",
      "18 79 loss: 0.017727196216583252\n",
      "18 80 loss: 0.0020123752765357494\n",
      "18 81 loss: 0.0058337850496172905\n",
      "18 82 loss: 0.048641953617334366\n",
      "18 83 loss: 0.043353281915187836\n",
      "18 84 loss: 0.020991362631320953\n",
      "18 85 loss: 0.03193303570151329\n",
      "18 86 loss: 0.01504279114305973\n",
      "18 87 loss: 0.01117468811571598\n",
      "18 88 loss: 0.007382942363619804\n",
      "18 89 loss: 0.0743396133184433\n",
      "18 90 loss: 0.0091688958927989\n",
      "18 91 loss: 0.013871962204575539\n",
      "18 92 loss: 0.02063138037919998\n",
      "18 93 loss: 0.0039038441609591246\n",
      "18 94 loss: 0.004476947709918022\n",
      "18 95 loss: 0.014320943504571915\n",
      "18 96 loss: 0.0065605370327830315\n",
      "18 97 loss: 0.07947775721549988\n",
      "18 98 loss: 0.04911484569311142\n",
      "18 99 loss: 0.05412648990750313\n",
      "18 100 loss: 0.007976268418133259\n",
      "18 101 loss: 0.025505919009447098\n",
      "18 102 loss: 0.04421037808060646\n",
      "18 103 loss: 0.03284445032477379\n",
      "18 104 loss: 0.013819411396980286\n",
      "18 105 loss: 0.005163048394024372\n",
      "18 106 loss: 0.014194829389452934\n",
      "18 107 loss: 0.019625477492809296\n",
      "18 108 loss: 0.001858697272837162\n",
      "18 109 loss: 0.027144726365804672\n",
      "18 110 loss: 0.0036942013539373875\n",
      "18 111 loss: 0.036539748311042786\n",
      "18 112 loss: 0.016107048839330673\n",
      "18 113 loss: 0.005690952762961388\n",
      "18 114 loss: 0.023628292605280876\n",
      "18 115 loss: 0.01655004173517227\n",
      "18 116 loss: 0.008335321210324764\n",
      "18 117 loss: 0.004617669619619846\n",
      "18 118 loss: 0.03928452357649803\n",
      "18 119 loss: 0.008313655853271484\n",
      "18 120 loss: 0.00781963113695383\n",
      "18 121 loss: 0.008303215727210045\n",
      "18 122 loss: 0.010029880329966545\n",
      "18 123 loss: 0.007068539038300514\n",
      "18 124 loss: 0.06882468611001968\n",
      "18 125 loss: 0.026620835065841675\n",
      "18 126 loss: 0.008529942482709885\n",
      "18 127 loss: 0.0052846441976726055\n",
      "18 128 loss: 0.014443508349359035\n",
      "18 129 loss: 0.009993257001042366\n",
      "18 130 loss: 0.0019878235179930925\n",
      "18 131 loss: 0.012437291443347931\n",
      "18 132 loss: 0.0018507929053157568\n",
      "18 133 loss: 0.007048346102237701\n",
      "18 134 loss: 0.008301926776766777\n",
      "18 135 loss: 0.015768583863973618\n",
      "18 136 loss: 0.0025170922745019197\n",
      "18 137 loss: 0.030948886647820473\n",
      "18 138 loss: 0.013517823070287704\n",
      "18 139 loss: 0.029344435781240463\n",
      "18 140 loss: 0.045668117702007294\n",
      "18 141 loss: 0.0016110256547108293\n",
      "18 142 loss: 0.0077196755446493626\n",
      "18 143 loss: 0.004702859558165073\n",
      "18 144 loss: 0.008214867673814297\n",
      "18 145 loss: 0.009874407202005386\n",
      "18 146 loss: 0.020470861345529556\n",
      "18 147 loss: 0.021416865289211273\n",
      "18 148 loss: 0.026197196915745735\n",
      "18 149 loss: 0.0031729163601994514\n",
      "18 150 loss: 0.0017638130811974406\n",
      "18 151 loss: 0.014491958543658257\n",
      "18 152 loss: 0.02104281634092331\n",
      "18 153 loss: 0.04687395691871643\n",
      "18 154 loss: 0.034219853579998016\n",
      "18 155 loss: 0.010539117269217968\n",
      "18 156 loss: 0.0020707552321255207\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfa8667eac4410e9293b47106d5863e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0 loss: 0.023577304556965828\n",
      "19 1 loss: 0.008637606166303158\n",
      "19 2 loss: 0.06696614623069763\n",
      "19 3 loss: 0.01329309307038784\n",
      "19 4 loss: 0.01816335693001747\n",
      "19 5 loss: 0.003809225745499134\n",
      "19 6 loss: 0.013226762413978577\n",
      "19 7 loss: 0.0025871829129755497\n",
      "19 8 loss: 0.0015083430334925652\n",
      "19 9 loss: 0.028387850150465965\n",
      "19 10 loss: 0.003857971169054508\n",
      "19 11 loss: 0.008703280240297318\n",
      "19 12 loss: 0.0036534005776047707\n",
      "19 13 loss: 0.003037170972675085\n",
      "19 14 loss: 0.004886014387011528\n",
      "19 15 loss: 0.013590900227427483\n",
      "19 16 loss: 0.09368045628070831\n",
      "19 17 loss: 0.03627787530422211\n",
      "19 18 loss: 0.0112192053347826\n",
      "19 19 loss: 0.006306883879005909\n",
      "19 20 loss: 0.023074917495250702\n",
      "19 21 loss: 0.008618351072072983\n",
      "19 22 loss: 0.012180586345493793\n",
      "19 23 loss: 0.005033382214605808\n",
      "19 24 loss: 0.01378837414085865\n",
      "19 25 loss: 0.0871017575263977\n",
      "19 26 loss: 0.005331628955900669\n",
      "19 27 loss: 0.007789752446115017\n",
      "19 28 loss: 0.002079169964417815\n",
      "19 29 loss: 0.04067326337099075\n",
      "19 30 loss: 0.0218913946300745\n",
      "19 31 loss: 0.009241300635039806\n",
      "19 32 loss: 0.047533631324768066\n",
      "19 33 loss: 0.005963677540421486\n",
      "19 34 loss: 0.00965895876288414\n",
      "19 35 loss: 0.03774367272853851\n",
      "19 36 loss: 0.011517209932208061\n",
      "19 37 loss: 0.03279895707964897\n",
      "19 38 loss: 0.0018479994032531977\n",
      "19 39 loss: 0.006952815689146519\n",
      "19 40 loss: 0.012802928686141968\n",
      "19 41 loss: 0.02448953315615654\n",
      "19 42 loss: 0.011796043254435062\n",
      "19 43 loss: 0.007348346523940563\n",
      "19 44 loss: 0.037829890847206116\n",
      "19 45 loss: 0.017615923658013344\n",
      "19 46 loss: 0.01021217554807663\n",
      "19 47 loss: 0.007626775652170181\n",
      "19 48 loss: 0.009223942644894123\n",
      "19 49 loss: 0.005273055285215378\n",
      "19 50 loss: 0.003914741333574057\n",
      "19 51 loss: 0.014174051582813263\n",
      "19 52 loss: 0.0029424112290143967\n",
      "19 53 loss: 0.011717873625457287\n",
      "19 54 loss: 0.04195296764373779\n",
      "19 55 loss: 0.003239696379750967\n",
      "19 56 loss: 0.014523055404424667\n",
      "19 57 loss: 0.018573975190520287\n",
      "19 58 loss: 0.013247404247522354\n",
      "19 59 loss: 0.04566733539104462\n",
      "19 60 loss: 0.023069165647029877\n",
      "19 61 loss: 0.05018197000026703\n",
      "19 62 loss: 0.008444881066679955\n",
      "19 63 loss: 0.013073353096842766\n",
      "19 64 loss: 0.006021308246999979\n",
      "19 65 loss: 0.0345628559589386\n",
      "19 66 loss: 0.004521469119936228\n",
      "19 67 loss: 0.015518944710493088\n",
      "19 68 loss: 0.02245549112558365\n",
      "19 69 loss: 0.0008918661624193192\n",
      "19 70 loss: 0.005193567369133234\n",
      "19 71 loss: 0.005988082382827997\n",
      "19 72 loss: 0.04870045930147171\n",
      "19 73 loss: 0.004828047938644886\n",
      "19 74 loss: 0.001268685911782086\n",
      "19 75 loss: 0.0382256805896759\n",
      "19 76 loss: 0.007444984745234251\n",
      "19 77 loss: 0.006626296788454056\n",
      "19 78 loss: 0.010346384719014168\n",
      "19 79 loss: 0.02351258136332035\n",
      "19 80 loss: 0.0029295561835169792\n",
      "19 81 loss: 0.0026220446452498436\n",
      "19 82 loss: 0.005834580864757299\n",
      "19 83 loss: 0.0077635920606553555\n",
      "19 84 loss: 0.0035802910570055246\n",
      "19 85 loss: 0.0074219428934156895\n",
      "19 86 loss: 0.024466754868626595\n",
      "19 87 loss: 0.11070380359888077\n",
      "19 88 loss: 0.005486990325152874\n",
      "19 89 loss: 0.00931528303772211\n",
      "19 90 loss: 0.01833534613251686\n",
      "19 91 loss: 0.00861280970275402\n",
      "19 92 loss: 0.023674290627241135\n",
      "19 93 loss: 0.01175627764314413\n",
      "19 94 loss: 0.008308213204145432\n",
      "19 95 loss: 0.024024516344070435\n",
      "19 96 loss: 0.0015398020623251796\n",
      "19 97 loss: 0.0033383395057171583\n",
      "19 98 loss: 0.02981497161090374\n",
      "19 99 loss: 0.05475541949272156\n",
      "19 100 loss: 0.013246679678559303\n",
      "19 101 loss: 0.011896216310560703\n",
      "19 102 loss: 0.02228126861155033\n",
      "19 103 loss: 0.0749199241399765\n",
      "19 104 loss: 0.00842457078397274\n",
      "19 105 loss: 0.01106172613799572\n",
      "19 106 loss: 0.004201266448944807\n",
      "19 107 loss: 0.008663871325552464\n",
      "19 108 loss: 0.02471809834241867\n",
      "19 109 loss: 0.010749207809567451\n",
      "19 110 loss: 0.041785143315792084\n",
      "19 111 loss: 0.002933363663032651\n",
      "19 112 loss: 0.007573546841740608\n",
      "19 113 loss: 0.05250931903719902\n",
      "19 114 loss: 0.006419524550437927\n",
      "19 115 loss: 0.001073536928743124\n",
      "19 116 loss: 0.003066078992560506\n",
      "19 117 loss: 0.004559990484267473\n",
      "19 118 loss: 0.013541590422391891\n",
      "19 119 loss: 0.022815033793449402\n",
      "19 120 loss: 0.0077476538717746735\n",
      "19 121 loss: 0.005900287535041571\n",
      "19 122 loss: 0.015545107424259186\n",
      "19 123 loss: 0.01013829093426466\n",
      "19 124 loss: 0.008564791642129421\n",
      "19 125 loss: 0.009723011404275894\n",
      "19 126 loss: 0.045164018869400024\n",
      "19 127 loss: 0.005952939391136169\n",
      "19 128 loss: 0.014439689926803112\n",
      "19 129 loss: 0.025634337216615677\n",
      "19 130 loss: 0.013361211866140366\n",
      "19 131 loss: 0.02043025568127632\n",
      "19 132 loss: 0.003022850025445223\n",
      "19 133 loss: 0.04628422111272812\n",
      "19 134 loss: 0.023102909326553345\n",
      "19 135 loss: 0.005672512575984001\n",
      "19 136 loss: 0.0024260878562927246\n",
      "19 137 loss: 0.0035960457753390074\n",
      "19 138 loss: 0.022009706124663353\n",
      "19 139 loss: 0.008813401684165001\n",
      "19 140 loss: 0.0019233433995395899\n",
      "19 141 loss: 0.006868661381304264\n",
      "19 142 loss: 0.006375923287123442\n",
      "19 143 loss: 0.0027284242678433657\n",
      "19 144 loss: 0.006027275696396828\n",
      "19 145 loss: 0.01749124564230442\n",
      "19 146 loss: 0.012760994024574757\n",
      "19 147 loss: 0.016751565039157867\n",
      "19 148 loss: 0.0020080029498785734\n",
      "19 149 loss: 0.012965251691639423\n",
      "19 150 loss: 0.0026162960566580296\n",
      "19 151 loss: 0.006654372438788414\n",
      "19 152 loss: 0.0011782916262745857\n",
      "19 153 loss: 0.010611394420266151\n",
      "19 154 loss: 0.0035019484348595142\n",
      "19 155 loss: 0.0030216509476304054\n",
      "19 156 loss: 0.0016559388022869825\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8a2b0e0c934e6baa824a62a7d402d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0 loss: 0.00239849416539073\n",
      "20 1 loss: 0.008023064583539963\n",
      "20 2 loss: 0.005428778938949108\n",
      "20 3 loss: 0.003410207573324442\n",
      "20 4 loss: 0.008532959967851639\n",
      "20 5 loss: 0.030866457149386406\n",
      "20 6 loss: 0.042183682322502136\n",
      "20 7 loss: 0.016173722222447395\n",
      "20 8 loss: 0.009210141375660896\n",
      "20 9 loss: 0.0030521261505782604\n",
      "20 10 loss: 0.001588486018590629\n",
      "20 11 loss: 0.004953524097800255\n",
      "20 12 loss: 0.002977249212563038\n",
      "20 13 loss: 0.0016464710934087634\n",
      "20 14 loss: 0.01118495687842369\n",
      "20 15 loss: 0.0019617900252342224\n",
      "20 16 loss: 0.010419969446957111\n",
      "20 17 loss: 0.0025224220007658005\n",
      "20 18 loss: 0.005783203523606062\n",
      "20 19 loss: 0.008616487495601177\n",
      "20 20 loss: 0.002474133623763919\n",
      "20 21 loss: 0.03501918911933899\n",
      "20 22 loss: 0.002445655409246683\n",
      "20 23 loss: 0.003837680909782648\n",
      "20 24 loss: 0.00393245043233037\n",
      "20 25 loss: 0.0032983259297907352\n",
      "20 26 loss: 0.000572929042391479\n",
      "20 27 loss: 0.000819331151433289\n",
      "20 28 loss: 0.014373961836099625\n",
      "20 29 loss: 0.0011227254290133715\n",
      "20 30 loss: 0.002920352853834629\n",
      "20 31 loss: 0.0012779126409441233\n",
      "20 32 loss: 0.014341909438371658\n",
      "20 33 loss: 0.00039658317109569907\n",
      "20 34 loss: 0.00177739467471838\n",
      "20 35 loss: 0.007227625697851181\n",
      "20 36 loss: 0.028826028108596802\n",
      "20 37 loss: 0.0032878746278584003\n",
      "20 38 loss: 0.01846158690750599\n",
      "20 39 loss: 0.011002189479768276\n",
      "20 40 loss: 0.03606186807155609\n",
      "20 41 loss: 0.014448861591517925\n",
      "20 42 loss: 0.015201300382614136\n",
      "20 43 loss: 0.007486695423722267\n",
      "20 44 loss: 0.01996656507253647\n",
      "20 45 loss: 0.04520160332322121\n",
      "20 46 loss: 0.0016960378270596266\n",
      "20 47 loss: 0.018585730344057083\n",
      "20 48 loss: 0.009075452573597431\n",
      "20 49 loss: 0.017158322036266327\n",
      "20 50 loss: 0.003283522091805935\n",
      "20 51 loss: 0.0005463594570755959\n",
      "20 52 loss: 0.0012555841822177172\n",
      "20 53 loss: 0.02097400650382042\n",
      "20 54 loss: 0.003934383857995272\n",
      "20 55 loss: 0.003166443668305874\n",
      "20 56 loss: 0.01631123386323452\n",
      "20 57 loss: 0.0012854008236899972\n",
      "20 58 loss: 0.01320901419967413\n",
      "20 59 loss: 0.009669925086200237\n",
      "20 60 loss: 0.0013517081970348954\n",
      "20 61 loss: 0.007203454617410898\n",
      "20 62 loss: 0.00111352966632694\n",
      "20 63 loss: 0.0029052672907710075\n",
      "20 64 loss: 0.016602888703346252\n",
      "20 65 loss: 0.02115199901163578\n",
      "20 66 loss: 0.005925050936639309\n",
      "20 67 loss: 0.0036385939456522465\n",
      "20 68 loss: 0.006854587234556675\n",
      "20 69 loss: 0.00163703050930053\n",
      "20 70 loss: 0.007100743241608143\n",
      "20 71 loss: 0.01618083007633686\n",
      "20 72 loss: 0.012911507859826088\n",
      "20 73 loss: 0.013702976517379284\n",
      "20 74 loss: 0.0409407913684845\n",
      "20 75 loss: 0.023339878767728806\n",
      "20 76 loss: 0.003488413291051984\n",
      "20 77 loss: 0.02185741439461708\n",
      "20 78 loss: 0.002822746755555272\n",
      "20 79 loss: 0.0023254752159118652\n",
      "20 80 loss: 0.0023156742099672556\n",
      "20 81 loss: 0.10020938515663147\n",
      "20 82 loss: 0.024968000128865242\n",
      "20 83 loss: 0.053976234048604965\n",
      "20 84 loss: 0.0022585587576031685\n",
      "20 85 loss: 0.017824169248342514\n",
      "20 86 loss: 0.004051500931382179\n",
      "20 87 loss: 0.0036154717672616243\n",
      "20 88 loss: 0.010590695776045322\n",
      "20 89 loss: 0.005392702296376228\n",
      "20 90 loss: 0.003366706660017371\n",
      "20 91 loss: 0.0513770654797554\n",
      "20 92 loss: 0.024323031306266785\n",
      "20 93 loss: 0.0025574075989425182\n",
      "20 94 loss: 0.03915415704250336\n",
      "20 95 loss: 0.051930081099271774\n",
      "20 96 loss: 0.007939288392663002\n",
      "20 97 loss: 0.005162459798157215\n",
      "20 98 loss: 0.006611263379454613\n",
      "20 99 loss: 0.007860728539526463\n",
      "20 100 loss: 0.003359974594786763\n",
      "20 101 loss: 0.0024802929256111383\n",
      "20 102 loss: 0.003979160916060209\n",
      "20 103 loss: 0.0052316151559352875\n",
      "20 104 loss: 0.0005342171061784029\n",
      "20 105 loss: 0.030331255868077278\n",
      "20 106 loss: 0.0160356592386961\n",
      "20 107 loss: 0.010075774043798447\n",
      "20 108 loss: 0.08818709850311279\n",
      "20 109 loss: 0.0011043281992897391\n",
      "20 110 loss: 0.00951771717518568\n",
      "20 111 loss: 0.012117531150579453\n",
      "20 112 loss: 0.08216322213411331\n",
      "20 113 loss: 0.025057094171643257\n",
      "20 114 loss: 0.04508252814412117\n",
      "20 115 loss: 0.041388873010873795\n",
      "20 116 loss: 0.023689810186624527\n",
      "20 117 loss: 0.005821180064231157\n",
      "20 118 loss: 0.028339283540844917\n",
      "20 119 loss: 0.00802074745297432\n",
      "20 120 loss: 0.00564181711524725\n",
      "20 121 loss: 0.03910253196954727\n",
      "20 122 loss: 0.007915426045656204\n",
      "20 123 loss: 0.002082156017422676\n",
      "20 124 loss: 0.0110018290579319\n",
      "20 125 loss: 0.013026117347180843\n",
      "20 126 loss: 0.014517624862492085\n",
      "20 127 loss: 0.012306071817874908\n",
      "20 128 loss: 0.018007589504122734\n",
      "20 129 loss: 0.034569304436445236\n",
      "20 130 loss: 0.012728329747915268\n",
      "20 131 loss: 0.12436196208000183\n",
      "20 132 loss: 0.038044147193431854\n",
      "20 133 loss: 0.0369969941675663\n",
      "20 134 loss: 0.001143855624832213\n",
      "20 135 loss: 0.0012477273121476173\n",
      "20 136 loss: 0.0016929889097809792\n",
      "20 137 loss: 0.011897395364940166\n",
      "20 138 loss: 0.05775807052850723\n",
      "20 139 loss: 0.03981173038482666\n",
      "20 140 loss: 0.0025409916415810585\n",
      "20 141 loss: 0.0549696683883667\n",
      "20 142 loss: 0.025384953245520592\n",
      "20 143 loss: 0.03876803070306778\n",
      "20 144 loss: 0.011081291362643242\n",
      "20 145 loss: 0.0021095084957778454\n",
      "20 146 loss: 0.0059473151341080666\n",
      "20 147 loss: 0.007179290987551212\n",
      "20 148 loss: 0.021542061120271683\n",
      "20 149 loss: 0.014215633273124695\n",
      "20 150 loss: 0.09840409457683563\n",
      "20 151 loss: 0.008704863488674164\n",
      "20 152 loss: 0.011782499961555004\n",
      "20 153 loss: 0.005636201705783606\n",
      "20 154 loss: 0.0653839111328125\n",
      "20 155 loss: 0.09144090116024017\n",
      "20 156 loss: 0.026617545634508133\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f2fae4615744acb047f6103e147a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0 loss: 0.05131592974066734\n",
      "21 1 loss: 0.010295039042830467\n",
      "21 2 loss: 0.005649400409311056\n",
      "21 3 loss: 0.003756676334887743\n",
      "21 4 loss: 0.01217515580356121\n",
      "21 5 loss: 0.011268082074820995\n",
      "21 6 loss: 0.049276210367679596\n",
      "21 7 loss: 0.028308264911174774\n",
      "21 8 loss: 0.03027154505252838\n",
      "21 9 loss: 0.03142857179045677\n",
      "21 10 loss: 0.03163786232471466\n",
      "21 11 loss: 0.020474201068282127\n",
      "21 12 loss: 0.03890667110681534\n",
      "21 13 loss: 0.007138418965041637\n",
      "21 14 loss: 0.07292036712169647\n",
      "21 15 loss: 0.019206717610359192\n",
      "21 16 loss: 0.015488038770854473\n",
      "21 17 loss: 0.013858169317245483\n",
      "21 18 loss: 0.011351775377988815\n",
      "21 19 loss: 0.025888165459036827\n",
      "21 20 loss: 0.01732604391872883\n",
      "21 21 loss: 0.08330470323562622\n",
      "21 22 loss: 0.007792520336806774\n",
      "21 23 loss: 0.06498373299837112\n",
      "21 24 loss: 0.006752863526344299\n",
      "21 25 loss: 0.018454916775226593\n",
      "21 26 loss: 0.03753302991390228\n",
      "21 27 loss: 0.014498552307486534\n",
      "21 28 loss: 0.0067293099127709866\n",
      "21 29 loss: 0.04824400693178177\n",
      "21 30 loss: 0.010018902830779552\n",
      "21 31 loss: 0.006917157210409641\n",
      "21 32 loss: 0.028354862704873085\n",
      "21 33 loss: 0.01878662407398224\n",
      "21 34 loss: 0.0024749126750975847\n",
      "21 35 loss: 0.00807737372815609\n",
      "21 36 loss: 0.055267974734306335\n",
      "21 37 loss: 0.033950962126255035\n",
      "21 38 loss: 0.011862375773489475\n",
      "21 39 loss: 0.00348648545332253\n",
      "21 40 loss: 0.03194402903318405\n",
      "21 41 loss: 0.04394975304603577\n",
      "21 42 loss: 0.0032194433733820915\n",
      "21 43 loss: 0.031696829944849014\n",
      "21 44 loss: 0.005365179385989904\n",
      "21 45 loss: 0.013763630762696266\n",
      "21 46 loss: 0.015531463548541069\n",
      "21 47 loss: 0.01200176402926445\n",
      "21 48 loss: 0.008928781375288963\n",
      "21 49 loss: 0.0026079374365508556\n",
      "21 50 loss: 0.005881128367036581\n",
      "21 51 loss: 0.042065709829330444\n",
      "21 52 loss: 0.025544695556163788\n",
      "21 53 loss: 0.012421377003192902\n",
      "21 54 loss: 0.018295977264642715\n",
      "21 55 loss: 0.02208479680120945\n",
      "21 56 loss: 0.058733899146318436\n",
      "21 57 loss: 0.0651048868894577\n",
      "21 58 loss: 0.023706331849098206\n",
      "21 59 loss: 0.00511202635243535\n",
      "21 60 loss: 0.007807761896401644\n",
      "21 61 loss: 0.0061952825635671616\n",
      "21 62 loss: 0.007373482920229435\n",
      "21 63 loss: 0.005570092238485813\n",
      "21 64 loss: 0.027008431032299995\n",
      "21 65 loss: 0.02176506631076336\n",
      "21 66 loss: 0.03330289199948311\n",
      "21 67 loss: 0.002374306321144104\n",
      "21 68 loss: 0.0021698903292417526\n",
      "21 69 loss: 0.003956904634833336\n",
      "21 70 loss: 0.007889322005212307\n",
      "21 71 loss: 0.009026472456753254\n",
      "21 72 loss: 0.015123831108212471\n",
      "21 73 loss: 0.017740942537784576\n",
      "21 74 loss: 0.005086954217404127\n",
      "21 75 loss: 0.0038374578580260277\n",
      "21 76 loss: 0.06242290139198303\n",
      "21 77 loss: 0.03474210575222969\n",
      "21 78 loss: 0.0028817723505198956\n",
      "21 79 loss: 0.04562380909919739\n",
      "21 80 loss: 0.015619625337421894\n",
      "21 81 loss: 0.015782764181494713\n",
      "21 82 loss: 0.05185669660568237\n",
      "21 83 loss: 0.007267309352755547\n",
      "21 84 loss: 0.053037188947200775\n",
      "21 85 loss: 0.006792443338781595\n",
      "21 86 loss: 0.008996587246656418\n",
      "21 87 loss: 0.01298992708325386\n",
      "21 88 loss: 0.008918557316064835\n",
      "21 89 loss: 0.006812026258558035\n",
      "21 90 loss: 0.020600944757461548\n",
      "21 91 loss: 0.044588230550289154\n",
      "21 92 loss: 0.01285644993185997\n",
      "21 93 loss: 0.0035476612392812967\n",
      "21 94 loss: 0.00204742350615561\n",
      "21 95 loss: 0.028285767883062363\n",
      "21 96 loss: 0.005357257556170225\n",
      "21 97 loss: 0.014817792922258377\n",
      "21 98 loss: 0.04940657317638397\n",
      "21 99 loss: 0.0023289918899536133\n",
      "21 100 loss: 0.06107013300061226\n",
      "21 101 loss: 0.002839612076058984\n",
      "21 102 loss: 0.03258639574050903\n",
      "21 103 loss: 0.0038321525789797306\n",
      "21 104 loss: 0.00441268365830183\n",
      "21 105 loss: 0.016681475564837456\n",
      "21 106 loss: 0.011862920597195625\n",
      "21 107 loss: 0.009888768196105957\n",
      "21 108 loss: 0.011076683178544044\n",
      "21 109 loss: 0.0022810306400060654\n",
      "21 110 loss: 0.00780646875500679\n",
      "21 111 loss: 0.010886313393712044\n",
      "21 112 loss: 0.014767730608582497\n",
      "21 113 loss: 0.02711542695760727\n",
      "21 114 loss: 0.02167520299553871\n",
      "21 115 loss: 0.00623659510165453\n",
      "21 116 loss: 0.009488856419920921\n",
      "21 117 loss: 0.017675375565886497\n",
      "21 118 loss: 0.008047369308769703\n",
      "21 119 loss: 0.0013743988238275051\n",
      "21 120 loss: 0.021812841296195984\n",
      "21 121 loss: 0.023646943271160126\n",
      "21 122 loss: 0.004763767588883638\n",
      "21 123 loss: 0.0270416010171175\n",
      "21 124 loss: 0.008740875869989395\n",
      "21 125 loss: 0.00529647758230567\n",
      "21 126 loss: 0.0034898067824542522\n",
      "21 127 loss: 0.0020185899920761585\n",
      "21 128 loss: 0.0012953451368957758\n",
      "21 129 loss: 0.023549381643533707\n",
      "21 130 loss: 0.020382270216941833\n",
      "21 131 loss: 0.010151605121791363\n",
      "21 132 loss: 0.02715853787958622\n",
      "21 133 loss: 0.008459136821329594\n",
      "21 134 loss: 0.007883363403379917\n",
      "21 135 loss: 0.004351195879280567\n",
      "21 136 loss: 0.003016609698534012\n",
      "21 137 loss: 0.004932089243084192\n",
      "21 138 loss: 0.009215538389980793\n",
      "21 139 loss: 0.009907502681016922\n",
      "21 140 loss: 0.0018687641713768244\n",
      "21 141 loss: 0.020759135484695435\n",
      "21 142 loss: 0.023563498631119728\n",
      "21 143 loss: 0.001714912592433393\n",
      "21 144 loss: 0.007126718293875456\n",
      "21 145 loss: 0.007650601677596569\n",
      "21 146 loss: 0.015962891280651093\n",
      "21 147 loss: 0.004594095051288605\n",
      "21 148 loss: 0.02115044556558132\n",
      "21 149 loss: 0.02219189889729023\n",
      "21 150 loss: 0.0007908325060270727\n",
      "21 151 loss: 0.006436731666326523\n",
      "21 152 loss: 0.004293623846024275\n",
      "21 153 loss: 0.007067904807627201\n",
      "21 154 loss: 0.003053240245208144\n",
      "21 155 loss: 0.06945161521434784\n",
      "21 156 loss: 0.00210059667006135\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c8affbff76491492edaf2df4169f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0 loss: 0.0019662906415760517\n",
      "22 1 loss: 0.0031620666850358248\n",
      "22 2 loss: 0.0033000498078763485\n",
      "22 3 loss: 0.0023579623084515333\n",
      "22 4 loss: 0.013363411650061607\n",
      "22 5 loss: 0.0069181304425001144\n",
      "22 6 loss: 0.042158905416727066\n",
      "22 7 loss: 0.016092389822006226\n",
      "22 8 loss: 0.0067900968715548515\n",
      "22 9 loss: 0.010573549196124077\n",
      "22 10 loss: 0.004017275292426348\n",
      "22 11 loss: 0.0022841659374535084\n",
      "22 12 loss: 0.0021297093480825424\n",
      "22 13 loss: 0.0032523106783628464\n",
      "22 14 loss: 0.002688963431864977\n",
      "22 15 loss: 0.021226150915026665\n",
      "22 16 loss: 0.011748267337679863\n",
      "22 17 loss: 0.0036231137346476316\n",
      "22 18 loss: 0.015362363308668137\n",
      "22 19 loss: 0.004292414989322424\n",
      "22 20 loss: 0.0036052691284567118\n",
      "22 21 loss: 0.0007873350405134261\n",
      "22 22 loss: 0.0014355718158185482\n",
      "22 23 loss: 0.060426827520132065\n",
      "22 24 loss: 0.0008709616959095001\n",
      "22 25 loss: 0.002504283096641302\n",
      "22 26 loss: 0.004735796712338924\n",
      "22 27 loss: 0.03541190177202225\n",
      "22 28 loss: 0.007807863876223564\n",
      "22 29 loss: 0.013933454640209675\n",
      "22 30 loss: 0.004570492543280125\n",
      "22 31 loss: 0.03254329785704613\n",
      "22 32 loss: 0.04116935655474663\n",
      "22 33 loss: 0.0011568729532882571\n",
      "22 34 loss: 0.03773879632353783\n",
      "22 35 loss: 0.06897076964378357\n",
      "22 36 loss: 0.005146580282598734\n",
      "22 37 loss: 0.012321369722485542\n",
      "22 38 loss: 0.014506991021335125\n",
      "22 39 loss: 0.006615182384848595\n",
      "22 40 loss: 0.0031952369026839733\n",
      "22 41 loss: 0.014660902321338654\n",
      "22 42 loss: 0.07205437123775482\n",
      "22 43 loss: 0.002651822054758668\n",
      "22 44 loss: 0.0027573155239224434\n",
      "22 45 loss: 0.0055167656391859055\n",
      "22 46 loss: 0.0015142831252887845\n",
      "22 47 loss: 0.034946542233228683\n",
      "22 48 loss: 0.003233781084418297\n",
      "22 49 loss: 0.0006155711598694324\n",
      "22 50 loss: 0.00031564131495542824\n",
      "22 51 loss: 0.03347982466220856\n",
      "22 52 loss: 0.002085817279294133\n",
      "22 53 loss: 0.004663972649723291\n",
      "22 54 loss: 0.0012937909923493862\n",
      "22 55 loss: 0.04336388036608696\n",
      "22 56 loss: 0.0140659399330616\n",
      "22 57 loss: 0.0012226051185280085\n",
      "22 58 loss: 0.003574114292860031\n",
      "22 59 loss: 0.00297140097245574\n",
      "22 60 loss: 0.0019595064222812653\n",
      "22 61 loss: 0.002694688970223069\n",
      "22 62 loss: 0.0008119069971144199\n",
      "22 63 loss: 0.005959176458418369\n",
      "22 64 loss: 0.00547834113240242\n",
      "22 65 loss: 0.009592007845640182\n",
      "22 66 loss: 0.002404227154329419\n",
      "22 67 loss: 0.08462562412023544\n",
      "22 68 loss: 0.010079881176352501\n",
      "22 69 loss: 0.0033500618301331997\n",
      "22 70 loss: 0.010375157929956913\n",
      "22 71 loss: 0.006164132617413998\n",
      "22 72 loss: 0.02796465903520584\n",
      "22 73 loss: 0.016928020864725113\n",
      "22 74 loss: 0.008423937484622002\n",
      "22 75 loss: 0.005599889438599348\n",
      "22 76 loss: 0.018427599221467972\n",
      "22 77 loss: 0.00290150148794055\n",
      "22 78 loss: 0.01069894339889288\n",
      "22 79 loss: 0.005443421192467213\n",
      "22 80 loss: 0.012634470127522945\n",
      "22 81 loss: 0.005861541256308556\n",
      "22 82 loss: 0.005061862990260124\n",
      "22 83 loss: 0.004561142064630985\n",
      "22 84 loss: 0.006921143736690283\n",
      "22 85 loss: 0.0070553068071603775\n",
      "22 86 loss: 0.026749756187200546\n",
      "22 87 loss: 0.007909751497209072\n",
      "22 88 loss: 0.04286640137434006\n",
      "22 89 loss: 0.021535539999604225\n",
      "22 90 loss: 0.007340771146118641\n",
      "22 91 loss: 0.036358170211315155\n",
      "22 92 loss: 0.0285235196352005\n",
      "22 93 loss: 0.025072304531931877\n",
      "22 94 loss: 0.022168468683958054\n",
      "22 95 loss: 0.0074447207152843475\n",
      "22 96 loss: 0.0011056801304221153\n",
      "22 97 loss: 0.004104078747332096\n",
      "22 98 loss: 0.029795680195093155\n",
      "22 99 loss: 0.010999945923686028\n",
      "22 100 loss: 0.04288645461201668\n",
      "22 101 loss: 0.014245830476284027\n",
      "22 102 loss: 0.027392154559493065\n",
      "22 103 loss: 0.00293326610699296\n",
      "22 104 loss: 0.00925649143755436\n",
      "22 105 loss: 0.005596409551799297\n",
      "22 106 loss: 0.0011572143994271755\n",
      "22 107 loss: 0.020478302612900734\n",
      "22 108 loss: 0.0016390718519687653\n",
      "22 109 loss: 0.0009331434266641736\n",
      "22 110 loss: 0.004895584192126989\n",
      "22 111 loss: 0.004477367736399174\n",
      "22 112 loss: 0.0017181853763759136\n",
      "22 113 loss: 0.0018490361981093884\n",
      "22 114 loss: 0.001316827954724431\n",
      "22 115 loss: 0.0007644949946552515\n",
      "22 116 loss: 0.02259330451488495\n",
      "22 117 loss: 0.005360505543649197\n",
      "22 118 loss: 0.00046897048014216125\n",
      "22 119 loss: 0.03519883379340172\n",
      "22 120 loss: 0.0015843703877180815\n",
      "22 121 loss: 0.008181443437933922\n",
      "22 122 loss: 0.009182000532746315\n",
      "22 123 loss: 0.0008632951066829264\n",
      "22 124 loss: 0.0018308936851099133\n",
      "22 125 loss: 0.020543955266475677\n",
      "22 126 loss: 0.017763957381248474\n",
      "22 127 loss: 0.026680706068873405\n",
      "22 128 loss: 0.0062513998709619045\n",
      "22 129 loss: 0.001646687276661396\n",
      "22 130 loss: 0.006463401950895786\n",
      "22 131 loss: 0.0022955555468797684\n",
      "22 132 loss: 0.001000591553747654\n",
      "22 133 loss: 0.0023855320177972317\n",
      "22 134 loss: 0.0027738558128476143\n",
      "22 135 loss: 0.006929150316864252\n",
      "22 136 loss: 0.002798907458782196\n",
      "22 137 loss: 0.009238590486347675\n",
      "22 138 loss: 0.02149122953414917\n",
      "22 139 loss: 0.00516862329095602\n",
      "22 140 loss: 0.010847708210349083\n",
      "22 141 loss: 0.0022864416241645813\n",
      "22 142 loss: 0.013466703705489635\n",
      "22 143 loss: 0.007427258417010307\n",
      "22 144 loss: 0.004911383613944054\n",
      "22 145 loss: 0.0010531669249758124\n",
      "22 146 loss: 0.006097171455621719\n",
      "22 147 loss: 0.0031987177208065987\n",
      "22 148 loss: 0.007921308279037476\n",
      "22 149 loss: 0.002578229643404484\n",
      "22 150 loss: 0.027118030935525894\n",
      "22 151 loss: 0.007664096541702747\n",
      "22 152 loss: 0.002211296232417226\n",
      "22 153 loss: 0.0016253726789727807\n",
      "22 154 loss: 0.0016497010365128517\n",
      "22 155 loss: 0.036898333579301834\n",
      "22 156 loss: 0.0004364053893368691\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a439b63ab04331a8992d822f7dcbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0 loss: 0.001402726280502975\n",
      "23 1 loss: 0.003832981688901782\n",
      "23 2 loss: 0.04647339507937431\n",
      "23 3 loss: 0.003031711559742689\n",
      "23 4 loss: 0.03359263017773628\n",
      "23 5 loss: 0.008744241669774055\n",
      "23 6 loss: 0.0114512350410223\n",
      "23 7 loss: 0.0823848620057106\n",
      "23 8 loss: 0.006420777179300785\n",
      "23 9 loss: 0.0031800572760403156\n",
      "23 10 loss: 0.0012725198175758123\n",
      "23 11 loss: 0.0010156930657103658\n",
      "23 12 loss: 0.0007832772680558264\n",
      "23 13 loss: 0.003984599374234676\n",
      "23 14 loss: 0.023090258240699768\n",
      "23 15 loss: 0.00284277880564332\n",
      "23 16 loss: 0.005990636069327593\n",
      "23 17 loss: 0.015226499177515507\n",
      "23 18 loss: 0.0054269395768642426\n",
      "23 19 loss: 0.004358984995633364\n",
      "23 20 loss: 0.0056821727193892\n",
      "23 21 loss: 0.007277336902916431\n",
      "23 22 loss: 0.05399434268474579\n",
      "23 23 loss: 0.005888705141842365\n",
      "23 24 loss: 0.003016290720552206\n",
      "23 25 loss: 0.012588595040142536\n",
      "23 26 loss: 0.001570837339386344\n",
      "23 27 loss: 0.0007961945375427604\n",
      "23 28 loss: 0.03338320553302765\n",
      "23 29 loss: 0.004775248467922211\n",
      "23 30 loss: 0.006522896233946085\n",
      "23 31 loss: 0.00624445965513587\n",
      "23 32 loss: 0.006173231638967991\n",
      "23 33 loss: 0.004161468707025051\n",
      "23 34 loss: 0.005717141088098288\n",
      "23 35 loss: 0.001240314682945609\n",
      "23 36 loss: 0.05463521182537079\n",
      "23 37 loss: 0.02039521373808384\n",
      "23 38 loss: 0.0012244321405887604\n",
      "23 39 loss: 0.006453532725572586\n",
      "23 40 loss: 0.0011181127047166228\n",
      "23 41 loss: 0.008893178775906563\n",
      "23 42 loss: 0.03791942447423935\n",
      "23 43 loss: 0.010468708351254463\n",
      "23 44 loss: 0.001503298874013126\n",
      "23 45 loss: 0.005789651535451412\n",
      "23 46 loss: 0.014342846348881721\n",
      "23 47 loss: 0.003157172119244933\n",
      "23 48 loss: 0.012144344858825207\n",
      "23 49 loss: 0.011154251173138618\n",
      "23 50 loss: 0.006566825322806835\n",
      "23 51 loss: 0.005564461927860975\n",
      "23 52 loss: 0.001308739185333252\n",
      "23 53 loss: 0.005632251966744661\n",
      "23 54 loss: 0.07957231998443604\n",
      "23 55 loss: 0.0330338217318058\n",
      "23 56 loss: 0.001831244328059256\n",
      "23 57 loss: 0.02065563201904297\n",
      "23 58 loss: 0.003020769450813532\n",
      "23 59 loss: 0.004150712862610817\n",
      "23 60 loss: 0.002504652598872781\n",
      "23 61 loss: 0.008443916216492653\n",
      "23 62 loss: 0.0029126377776265144\n",
      "23 63 loss: 0.0011051290202885866\n",
      "23 64 loss: 0.01761571690440178\n",
      "23 65 loss: 0.0024536228738725185\n",
      "23 66 loss: 0.005582666955888271\n",
      "23 67 loss: 0.015715984627604485\n",
      "23 68 loss: 0.009682727046310902\n",
      "23 69 loss: 0.020345179364085197\n",
      "23 70 loss: 0.0017056195065379143\n",
      "23 71 loss: 0.0030904440209269524\n",
      "23 72 loss: 0.002979462966322899\n",
      "23 73 loss: 0.002370501635596156\n",
      "23 74 loss: 0.017061486840248108\n",
      "23 75 loss: 0.004307195078581572\n",
      "23 76 loss: 0.04716457054018974\n",
      "23 77 loss: 0.006415152456611395\n",
      "23 78 loss: 0.004623641259968281\n",
      "23 79 loss: 0.0026286570355296135\n",
      "23 80 loss: 0.0038255269173532724\n",
      "23 81 loss: 0.0018788673914968967\n",
      "23 82 loss: 0.06236447021365166\n",
      "23 83 loss: 0.002762941876426339\n",
      "23 84 loss: 0.004276633262634277\n",
      "23 85 loss: 0.0035020802170038223\n",
      "23 86 loss: 0.0022341255098581314\n",
      "23 87 loss: 0.002650070935487747\n",
      "23 88 loss: 0.00318750343285501\n",
      "23 89 loss: 0.031945936381816864\n",
      "23 90 loss: 0.03335801884531975\n",
      "23 91 loss: 0.0016606232384219766\n",
      "23 92 loss: 0.001993784448131919\n",
      "23 93 loss: 0.0031992769800126553\n",
      "23 94 loss: 0.08066738396883011\n",
      "23 95 loss: 0.0018259815406054258\n",
      "23 96 loss: 0.004410236608237028\n",
      "23 97 loss: 0.008902030065655708\n",
      "23 98 loss: 0.005076764151453972\n",
      "23 99 loss: 0.011455993168056011\n",
      "23 100 loss: 0.016658248379826546\n",
      "23 101 loss: 0.0032090945169329643\n",
      "23 102 loss: 0.0018393851350992918\n",
      "23 103 loss: 0.004077363293617964\n",
      "23 104 loss: 0.004018477164208889\n",
      "23 105 loss: 0.009738474152982235\n",
      "23 106 loss: 0.007790092378854752\n",
      "23 107 loss: 0.0009258012287318707\n",
      "23 108 loss: 0.0058450098149478436\n",
      "23 109 loss: 0.01012053620070219\n",
      "23 110 loss: 0.013167095370590687\n",
      "23 111 loss: 0.011060855351388454\n",
      "23 112 loss: 0.01684975065290928\n",
      "23 113 loss: 0.003451927565038204\n",
      "23 114 loss: 0.030208498239517212\n",
      "23 115 loss: 0.001939987065270543\n",
      "23 116 loss: 0.0019923709332942963\n",
      "23 117 loss: 0.0006393473595380783\n",
      "23 118 loss: 0.03044811263680458\n",
      "23 119 loss: 0.016977615654468536\n",
      "23 120 loss: 0.03395954146981239\n",
      "23 121 loss: 0.029373904690146446\n",
      "23 122 loss: 0.00930825062096119\n",
      "23 123 loss: 0.048517610877752304\n",
      "23 124 loss: 0.0031209313310682774\n",
      "23 125 loss: 0.01622420735657215\n",
      "23 126 loss: 0.0034682671539485455\n",
      "23 127 loss: 0.0023182560689747334\n",
      "23 128 loss: 0.004262097179889679\n",
      "23 129 loss: 0.004120966419577599\n",
      "23 130 loss: 0.038083020597696304\n",
      "23 131 loss: 0.013635234907269478\n",
      "23 132 loss: 0.0009325729333795607\n",
      "23 133 loss: 0.005901141092181206\n",
      "23 134 loss: 0.008023465052247047\n",
      "23 135 loss: 0.015241382643580437\n",
      "23 136 loss: 0.00871608778834343\n",
      "23 137 loss: 0.11895013600587845\n",
      "23 138 loss: 0.029446564614772797\n",
      "23 139 loss: 0.0026149030309170485\n",
      "23 140 loss: 0.0059736319817602634\n",
      "23 141 loss: 0.05127529799938202\n",
      "23 142 loss: 0.02400975115597248\n",
      "23 143 loss: 0.00250808778218925\n",
      "23 144 loss: 0.008436520583927631\n",
      "23 145 loss: 0.0036141020245850086\n",
      "23 146 loss: 0.0321994386613369\n",
      "23 147 loss: 0.011884236708283424\n",
      "23 148 loss: 0.015532214194536209\n",
      "23 149 loss: 0.0023500588722527027\n",
      "23 150 loss: 0.0005924607976339757\n",
      "23 151 loss: 0.029667846858501434\n",
      "23 152 loss: 0.007151415571570396\n",
      "23 153 loss: 0.0004991189925931394\n",
      "23 154 loss: 0.024541612714529037\n",
      "23 155 loss: 0.06199127435684204\n",
      "23 156 loss: 0.0005176792619749904\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3b4974c6d1421eb23a2ea828192dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0 loss: 0.0005412478931248188\n",
      "24 1 loss: 0.015017172321677208\n",
      "24 2 loss: 0.0025460212491452694\n",
      "24 3 loss: 0.05299527198076248\n",
      "24 4 loss: 0.007198544219136238\n",
      "24 5 loss: 0.049940817058086395\n",
      "24 6 loss: 0.003084616968408227\n",
      "24 7 loss: 0.0038135081995278597\n",
      "24 8 loss: 0.02188664861023426\n",
      "24 9 loss: 0.00241023488342762\n",
      "24 10 loss: 0.014471759088337421\n",
      "24 11 loss: 0.052826445549726486\n",
      "24 12 loss: 0.047682441771030426\n",
      "24 13 loss: 0.009153757244348526\n",
      "24 14 loss: 0.02507774345576763\n",
      "24 15 loss: 0.0029702745378017426\n",
      "24 16 loss: 0.009190184995532036\n",
      "24 17 loss: 0.06384792178869247\n",
      "24 18 loss: 0.002030553761869669\n",
      "24 19 loss: 0.012304536998271942\n",
      "24 20 loss: 0.005681414157152176\n",
      "24 21 loss: 0.03742164373397827\n",
      "24 22 loss: 0.0006633981829509139\n",
      "24 23 loss: 0.0394161082804203\n",
      "24 24 loss: 0.005528570152819157\n",
      "24 25 loss: 0.001519134035333991\n",
      "24 26 loss: 0.02020266465842724\n",
      "24 27 loss: 0.0038104357663542032\n",
      "24 28 loss: 0.04078013077378273\n",
      "24 29 loss: 0.00291082332842052\n",
      "24 30 loss: 0.04476071521639824\n",
      "24 31 loss: 0.015420648269355297\n",
      "24 32 loss: 0.0207908246666193\n",
      "24 33 loss: 0.04652776941657066\n",
      "24 34 loss: 0.005975155159831047\n",
      "24 35 loss: 0.0031245057471096516\n",
      "24 36 loss: 0.056286394596099854\n",
      "24 37 loss: 0.0039018348325043917\n",
      "24 38 loss: 0.009037023410201073\n",
      "24 39 loss: 0.036172471940517426\n",
      "24 40 loss: 0.029149498790502548\n",
      "24 41 loss: 0.01072083879262209\n",
      "24 42 loss: 0.005392051301896572\n",
      "24 43 loss: 0.006072910502552986\n",
      "24 44 loss: 0.01320765819400549\n",
      "24 45 loss: 0.016502082347869873\n",
      "24 46 loss: 0.0029587664175778627\n",
      "24 47 loss: 0.0016464103246107697\n",
      "24 48 loss: 0.0016113824676722288\n",
      "24 49 loss: 0.008503553457558155\n",
      "24 50 loss: 0.015653660520911217\n",
      "24 51 loss: 0.00648021325469017\n",
      "24 52 loss: 0.01658175140619278\n",
      "24 53 loss: 0.004502419847995043\n",
      "24 54 loss: 0.002394227311015129\n",
      "24 55 loss: 0.004495065659284592\n",
      "24 56 loss: 0.03762305900454521\n",
      "24 57 loss: 0.03248884528875351\n",
      "24 58 loss: 0.002044989727437496\n",
      "24 59 loss: 0.004394854418933392\n",
      "24 60 loss: 0.009342486038804054\n",
      "24 61 loss: 0.008871398866176605\n",
      "24 62 loss: 0.003998715430498123\n",
      "24 63 loss: 0.002134025329723954\n",
      "24 64 loss: 0.007994546554982662\n",
      "24 65 loss: 0.0019712336361408234\n",
      "24 66 loss: 0.010632622055709362\n",
      "24 67 loss: 0.023765897378325462\n",
      "24 68 loss: 0.011175693944096565\n",
      "24 69 loss: 0.024807937443256378\n",
      "24 70 loss: 0.003786630928516388\n",
      "24 71 loss: 0.001468866947107017\n",
      "24 72 loss: 0.0013359204167500138\n",
      "24 73 loss: 0.0026139935944229364\n",
      "24 74 loss: 0.0016720080748200417\n",
      "24 75 loss: 0.010620941407978535\n",
      "24 76 loss: 0.001991303637623787\n",
      "24 77 loss: 0.0018232944421470165\n",
      "24 78 loss: 0.016698237508535385\n",
      "24 79 loss: 0.015079881995916367\n",
      "24 80 loss: 0.0024840296246111393\n",
      "24 81 loss: 0.0009484486654400826\n",
      "24 82 loss: 0.0057282596826553345\n",
      "24 83 loss: 0.014865539036691189\n",
      "24 84 loss: 0.0277243759483099\n",
      "24 85 loss: 0.012145512737333775\n",
      "24 86 loss: 0.026422729715704918\n",
      "24 87 loss: 0.01119525358080864\n",
      "24 88 loss: 0.0027422113344073296\n",
      "24 89 loss: 0.002049257978796959\n",
      "24 90 loss: 0.044375523924827576\n",
      "24 91 loss: 0.010720957070589066\n",
      "24 92 loss: 0.012872881256043911\n",
      "24 93 loss: 0.006998964585363865\n",
      "24 94 loss: 0.003271831665188074\n",
      "24 95 loss: 0.004950371570885181\n",
      "24 96 loss: 0.005607109051197767\n",
      "24 97 loss: 0.03106217086315155\n",
      "24 98 loss: 0.012318078428506851\n",
      "24 99 loss: 0.0017944260034710169\n",
      "24 100 loss: 0.008327118121087551\n",
      "24 101 loss: 0.0584859699010849\n",
      "24 102 loss: 0.011026676744222641\n",
      "24 103 loss: 0.0047687930054962635\n",
      "24 104 loss: 0.003510888200253248\n",
      "24 105 loss: 0.017990468069911003\n",
      "24 106 loss: 0.0013634318020194769\n",
      "24 107 loss: 0.011185485869646072\n",
      "24 108 loss: 0.0039433566853404045\n",
      "24 109 loss: 0.009277439676225185\n",
      "24 110 loss: 0.011607280001044273\n",
      "24 111 loss: 0.001242197584360838\n",
      "24 112 loss: 0.002382268663495779\n",
      "24 113 loss: 0.006304167211055756\n",
      "24 114 loss: 0.001063717296347022\n",
      "24 115 loss: 0.006181681994348764\n",
      "24 116 loss: 0.0029099490493535995\n",
      "24 117 loss: 0.01959400065243244\n",
      "24 118 loss: 0.017582204192876816\n",
      "24 119 loss: 0.005041519179940224\n",
      "24 120 loss: 0.007288265973329544\n",
      "24 121 loss: 0.000738808186724782\n",
      "24 122 loss: 0.027571462094783783\n",
      "24 123 loss: 0.0010820581810548902\n",
      "24 124 loss: 0.025695763528347015\n",
      "24 125 loss: 0.0015523114707320929\n",
      "24 126 loss: 0.002485212404280901\n",
      "24 127 loss: 0.036640360951423645\n",
      "24 128 loss: 0.0033812092151492834\n",
      "24 129 loss: 0.013712607324123383\n",
      "24 130 loss: 0.01431429386138916\n",
      "24 131 loss: 0.002770625753328204\n",
      "24 132 loss: 0.022722655907273293\n",
      "24 133 loss: 0.13971084356307983\n",
      "24 134 loss: 0.0010999288642778993\n",
      "24 135 loss: 0.0005908125312998891\n",
      "24 136 loss: 0.0007732860976830125\n",
      "24 137 loss: 0.029805850237607956\n",
      "24 138 loss: 0.0009553380077704787\n",
      "24 139 loss: 0.022684190422296524\n",
      "24 140 loss: 0.013827962800860405\n",
      "24 141 loss: 0.0019007389200851321\n",
      "24 142 loss: 0.0010365269845351577\n",
      "24 143 loss: 0.05430537834763527\n",
      "24 144 loss: 8.154050738085061e-05\n",
      "24 145 loss: 0.01709587126970291\n",
      "24 146 loss: 0.011446070857346058\n",
      "24 147 loss: 0.002844998612999916\n",
      "24 148 loss: 0.04007498919963837\n",
      "24 149 loss: 0.014844629913568497\n",
      "24 150 loss: 0.028459671884775162\n",
      "24 151 loss: 0.015275679528713226\n",
      "24 152 loss: 0.0030366978608071804\n",
      "24 153 loss: 0.008387338370084763\n",
      "24 154 loss: 0.025013545528054237\n",
      "24 155 loss: 0.019189946353435516\n",
      "24 156 loss: 0.00023105487343855202\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcd17b8a54c41d38becea18a12c0664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0 loss: 0.015768764540553093\n",
      "25 1 loss: 0.009296617470681667\n",
      "25 2 loss: 0.006306028924882412\n",
      "25 3 loss: 0.035890232771635056\n",
      "25 4 loss: 0.0018484813626855612\n",
      "25 5 loss: 0.03577030450105667\n",
      "25 6 loss: 0.04990822449326515\n",
      "25 7 loss: 0.0028009742964059114\n",
      "25 8 loss: 0.04000174254179001\n",
      "25 9 loss: 0.0014314097352325916\n",
      "25 10 loss: 0.01972801610827446\n",
      "25 11 loss: 0.012370692566037178\n",
      "25 12 loss: 0.015868136659264565\n",
      "25 13 loss: 0.017072563990950584\n",
      "25 14 loss: 0.0033693108707666397\n",
      "25 15 loss: 0.02531854622066021\n",
      "25 16 loss: 0.011670855805277824\n",
      "25 17 loss: 0.01954147033393383\n",
      "25 18 loss: 0.014137756079435349\n",
      "25 19 loss: 0.008665557950735092\n",
      "25 20 loss: 0.03190819174051285\n",
      "25 21 loss: 0.005096071399748325\n",
      "25 22 loss: 0.025864945724606514\n",
      "25 23 loss: 0.005282578524202108\n",
      "25 24 loss: 0.004640216939151287\n",
      "25 25 loss: 0.0238692257553339\n",
      "25 26 loss: 0.00222986564040184\n",
      "25 27 loss: 0.00910118967294693\n",
      "25 28 loss: 0.002657786011695862\n",
      "25 29 loss: 0.024310868233442307\n",
      "25 30 loss: 0.00736389122903347\n",
      "25 31 loss: 0.008528107777237892\n",
      "25 32 loss: 0.011539687402546406\n",
      "25 33 loss: 0.004764567594975233\n",
      "25 34 loss: 0.011003517545759678\n",
      "25 35 loss: 0.008414550684392452\n",
      "25 36 loss: 0.0011669733794406056\n",
      "25 37 loss: 0.02942730486392975\n",
      "25 38 loss: 0.019121160730719566\n",
      "25 39 loss: 0.009858444333076477\n",
      "25 40 loss: 0.0010225819423794746\n",
      "25 41 loss: 0.0025695632211863995\n",
      "25 42 loss: 0.0015608018729835749\n",
      "25 43 loss: 0.009696612134575844\n",
      "25 44 loss: 0.0017530238255858421\n",
      "25 45 loss: 0.001321866875514388\n",
      "25 46 loss: 0.00748518155887723\n",
      "25 47 loss: 0.0132373608648777\n",
      "25 48 loss: 0.004044284112751484\n",
      "25 49 loss: 0.041513461619615555\n",
      "25 50 loss: 0.028603876009583473\n",
      "25 51 loss: 0.02199801616370678\n",
      "25 52 loss: 0.007263941690325737\n",
      "25 53 loss: 0.002108644926920533\n",
      "25 54 loss: 0.0029565594159066677\n",
      "25 55 loss: 0.0033560111187398434\n",
      "25 56 loss: 0.03491142392158508\n",
      "25 57 loss: 0.003530960762873292\n",
      "25 58 loss: 0.006157443858683109\n",
      "25 59 loss: 0.010634317062795162\n",
      "25 60 loss: 0.007415590807795525\n",
      "25 61 loss: 0.004193684086203575\n",
      "25 62 loss: 0.0145749906077981\n",
      "25 63 loss: 0.006693486589938402\n",
      "25 64 loss: 0.006983422674238682\n",
      "25 65 loss: 0.03498781472444534\n",
      "25 66 loss: 0.0053162481635808945\n",
      "25 67 loss: 0.006080120801925659\n",
      "25 68 loss: 0.03917969763278961\n",
      "25 69 loss: 0.010632282122969627\n",
      "25 70 loss: 0.008419254794716835\n",
      "25 71 loss: 0.006192022934556007\n",
      "25 72 loss: 0.002762232441455126\n",
      "25 73 loss: 0.008824119344353676\n",
      "25 74 loss: 0.04820648580789566\n",
      "25 75 loss: 0.0035563549026846886\n",
      "25 76 loss: 0.0005342428339645267\n",
      "25 77 loss: 0.029499555006623268\n",
      "25 78 loss: 0.011423831805586815\n",
      "25 79 loss: 0.0033527922350913286\n",
      "25 80 loss: 0.020061803981661797\n",
      "25 81 loss: 0.0024551230017095804\n",
      "25 82 loss: 0.00922347605228424\n",
      "25 83 loss: 0.004064004402607679\n",
      "25 84 loss: 0.004384690895676613\n",
      "25 85 loss: 0.006702692247927189\n",
      "25 86 loss: 0.0014426682610064745\n",
      "25 87 loss: 0.005005245096981525\n",
      "25 88 loss: 0.002599193947389722\n",
      "25 89 loss: 0.012608055025339127\n",
      "25 90 loss: 0.04444015398621559\n",
      "25 91 loss: 0.011358307674527168\n",
      "25 92 loss: 0.005641797557473183\n",
      "25 93 loss: 0.0030495733954012394\n",
      "25 94 loss: 0.01041646022349596\n",
      "25 95 loss: 0.009368808008730412\n",
      "25 96 loss: 0.007293213624507189\n",
      "25 97 loss: 0.002542865462601185\n",
      "25 98 loss: 0.004570122808218002\n",
      "25 99 loss: 0.005376453511416912\n",
      "25 100 loss: 0.003354359418153763\n",
      "25 101 loss: 0.005754582118242979\n",
      "25 102 loss: 0.023174474015831947\n",
      "25 103 loss: 0.004920073319226503\n",
      "25 104 loss: 0.001984961563721299\n",
      "25 105 loss: 0.024720076471567154\n",
      "25 106 loss: 0.0056847878731787205\n",
      "25 107 loss: 0.003569031832739711\n",
      "25 108 loss: 0.0075970240868628025\n",
      "25 109 loss: 0.0005152842495590448\n",
      "25 110 loss: 0.001545142731629312\n",
      "25 111 loss: 0.0010070194257423282\n",
      "25 112 loss: 0.0028323212172836065\n",
      "25 113 loss: 0.0003723119734786451\n",
      "25 114 loss: 0.0196226853877306\n",
      "25 115 loss: 0.0019647141452878714\n",
      "25 116 loss: 0.0007521383231505752\n",
      "25 117 loss: 0.001256048446521163\n",
      "25 118 loss: 0.0010376886930316687\n",
      "25 119 loss: 0.08114296942949295\n",
      "25 120 loss: 0.0010494596790522337\n",
      "25 121 loss: 0.0012716902419924736\n",
      "25 122 loss: 0.004498791415244341\n",
      "25 123 loss: 0.05793657898902893\n",
      "25 124 loss: 0.004446257837116718\n",
      "25 125 loss: 0.0017918189987540245\n",
      "25 126 loss: 0.001650865189731121\n",
      "25 127 loss: 0.006115875206887722\n",
      "25 128 loss: 0.007196604274213314\n",
      "25 129 loss: 0.0029900167137384415\n",
      "25 130 loss: 0.010397961363196373\n",
      "25 131 loss: 0.01427430473268032\n",
      "25 132 loss: 0.003010725136846304\n",
      "25 133 loss: 0.0036645897198468447\n",
      "25 134 loss: 0.004180897027254105\n",
      "25 135 loss: 0.004832371138036251\n",
      "25 136 loss: 0.000717454997356981\n",
      "25 137 loss: 0.001250389264896512\n",
      "25 138 loss: 0.001023066695779562\n",
      "25 139 loss: 0.0031870617531239986\n",
      "25 140 loss: 0.006236270535737276\n",
      "25 141 loss: 0.0013461739290505648\n",
      "25 142 loss: 0.025345589965581894\n",
      "25 143 loss: 0.0020404665265232325\n",
      "25 144 loss: 0.02036301977932453\n",
      "25 145 loss: 0.0009254153119400144\n",
      "25 146 loss: 0.006768125109374523\n",
      "25 147 loss: 0.0008227790240198374\n",
      "25 148 loss: 0.008574697189033031\n",
      "25 149 loss: 0.004138104617595673\n",
      "25 150 loss: 0.005506055895239115\n",
      "25 151 loss: 0.0061884550377726555\n",
      "25 152 loss: 0.0019610298331826925\n",
      "25 153 loss: 0.0008709118701517582\n",
      "25 154 loss: 0.0014509096508845687\n",
      "25 155 loss: 0.014318905770778656\n",
      "25 156 loss: 0.0057798950001597404\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5568de7a00fd4ecf92ca0a02229c0f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 0 loss: 0.001681862398982048\n",
      "26 1 loss: 0.018175892531871796\n",
      "26 2 loss: 0.01941854879260063\n",
      "26 3 loss: 0.005104214884340763\n",
      "26 4 loss: 0.0009003154700621963\n",
      "26 5 loss: 0.010968882590532303\n",
      "26 6 loss: 0.03721066936850548\n",
      "26 7 loss: 0.000357800570782274\n",
      "26 8 loss: 0.012464558705687523\n",
      "26 9 loss: 0.0011652623070403934\n",
      "26 10 loss: 0.0014790953136980534\n",
      "26 11 loss: 0.0014256280846893787\n",
      "26 12 loss: 0.017662057653069496\n",
      "26 13 loss: 0.0020177033729851246\n",
      "26 14 loss: 0.03490424156188965\n",
      "26 15 loss: 0.006204884499311447\n",
      "26 16 loss: 0.008936119265854359\n",
      "26 17 loss: 0.002296724822372198\n",
      "26 18 loss: 0.009142322465777397\n",
      "26 19 loss: 0.004288519732654095\n",
      "26 20 loss: 0.016620105132460594\n",
      "26 21 loss: 0.011605329811573029\n",
      "26 22 loss: 0.005584547761827707\n",
      "26 23 loss: 0.0003062489558942616\n",
      "26 24 loss: 0.0006808906327933073\n",
      "26 25 loss: 0.0006317312945611775\n",
      "26 26 loss: 0.002588065341114998\n",
      "26 27 loss: 0.0010474056471139193\n",
      "26 28 loss: 0.0010928856208920479\n",
      "26 29 loss: 0.0022663665004074574\n",
      "26 30 loss: 0.0010662190616130829\n",
      "26 31 loss: 0.0006203654920682311\n",
      "26 32 loss: 0.00034430070081725717\n",
      "26 33 loss: 0.009660622105002403\n",
      "26 34 loss: 0.000580836902372539\n",
      "26 35 loss: 0.002799886977300048\n",
      "26 36 loss: 0.004144743084907532\n",
      "26 37 loss: 0.014809147454798222\n",
      "26 38 loss: 0.010700435377657413\n",
      "26 39 loss: 0.0014990846393629909\n",
      "26 40 loss: 0.0001770530070643872\n",
      "26 41 loss: 0.0005700797773897648\n",
      "26 42 loss: 0.0006286362768150866\n",
      "26 43 loss: 0.0007290064240805805\n",
      "26 44 loss: 0.005685599986463785\n",
      "26 45 loss: 0.010168022476136684\n",
      "26 46 loss: 0.00028498913161456585\n",
      "26 47 loss: 0.04584207758307457\n",
      "26 48 loss: 0.0005695324507541955\n",
      "26 49 loss: 0.015763280913233757\n",
      "26 50 loss: 0.02552737668156624\n",
      "26 51 loss: 0.014969957061111927\n",
      "26 52 loss: 0.010526805184781551\n",
      "26 53 loss: 0.060389913618564606\n",
      "26 54 loss: 0.020911987870931625\n",
      "26 55 loss: 0.014213369227945805\n",
      "26 56 loss: 0.007173024583607912\n",
      "26 57 loss: 0.011533081531524658\n",
      "26 58 loss: 0.002134159440174699\n",
      "26 59 loss: 0.0026177293621003628\n",
      "26 60 loss: 0.006207010243088007\n",
      "26 61 loss: 0.07634743303060532\n",
      "26 62 loss: 0.019025668501853943\n",
      "26 63 loss: 0.0004543648683466017\n",
      "26 64 loss: 0.0008751116693019867\n",
      "26 65 loss: 0.0096226641908288\n",
      "26 66 loss: 0.007112803868949413\n",
      "26 67 loss: 0.006633107550442219\n",
      "26 68 loss: 0.020700370892882347\n",
      "26 69 loss: 0.0029525235295295715\n",
      "26 70 loss: 0.020550355315208435\n",
      "26 71 loss: 0.023030981421470642\n",
      "26 72 loss: 0.013625681400299072\n",
      "26 73 loss: 0.028339821845293045\n",
      "26 74 loss: 0.05258619785308838\n",
      "26 75 loss: 0.09933244436979294\n",
      "26 76 loss: 0.007309404201805592\n",
      "26 77 loss: 0.0036128503270447254\n",
      "26 78 loss: 0.06439070403575897\n",
      "26 79 loss: 0.0018223279621452093\n",
      "26 80 loss: 0.004056371748447418\n",
      "26 81 loss: 0.051441606134176254\n",
      "26 82 loss: 0.036188021302223206\n",
      "26 83 loss: 0.004300238098949194\n",
      "26 84 loss: 0.027992339804768562\n",
      "26 85 loss: 0.011771013028919697\n",
      "26 86 loss: 0.0009363535209558904\n",
      "26 87 loss: 0.0017809484852477908\n",
      "26 88 loss: 0.0450080931186676\n",
      "26 89 loss: 0.0019629066810011864\n",
      "26 90 loss: 0.07032656669616699\n",
      "26 91 loss: 0.005532765761017799\n",
      "26 92 loss: 0.019251935184001923\n",
      "26 93 loss: 0.006547787692397833\n",
      "26 94 loss: 0.012757501564919949\n",
      "26 95 loss: 0.0012759168166667223\n",
      "26 96 loss: 0.003653737949207425\n",
      "26 97 loss: 0.08219137042760849\n",
      "26 98 loss: 0.010437380522489548\n",
      "26 99 loss: 0.02565743587911129\n",
      "26 100 loss: 0.008784587495028973\n",
      "26 101 loss: 0.040155183523893356\n",
      "26 102 loss: 0.010061321780085564\n",
      "26 103 loss: 0.0733959749341011\n",
      "26 104 loss: 0.030125219374895096\n",
      "26 105 loss: 0.0018087499774992466\n",
      "26 106 loss: 0.0025177444331347942\n",
      "26 107 loss: 0.025647766888141632\n",
      "26 108 loss: 0.009947160258889198\n",
      "26 109 loss: 0.0011645079357549548\n",
      "26 110 loss: 0.026257123798131943\n",
      "26 111 loss: 0.011635266244411469\n",
      "26 112 loss: 0.03869326040148735\n",
      "26 113 loss: 0.03140281140804291\n",
      "26 114 loss: 0.013662553392350674\n",
      "26 115 loss: 0.005285044200718403\n",
      "26 116 loss: 0.011562880128622055\n",
      "26 117 loss: 0.04400508850812912\n",
      "26 118 loss: 0.005761454813182354\n",
      "26 119 loss: 0.0010365612106397748\n",
      "26 120 loss: 0.09599290043115616\n",
      "26 121 loss: 0.004987090360373259\n",
      "26 122 loss: 0.017873167991638184\n",
      "26 123 loss: 0.003641277551651001\n",
      "26 124 loss: 0.020002640783786774\n",
      "26 125 loss: 0.006658444181084633\n",
      "26 126 loss: 0.0018994593992829323\n",
      "26 127 loss: 0.001710620359517634\n",
      "26 128 loss: 0.004357558209449053\n",
      "26 129 loss: 0.0007885679369792342\n",
      "26 130 loss: 0.010948240756988525\n",
      "26 131 loss: 0.025180716067552567\n",
      "26 132 loss: 0.001714445068500936\n",
      "26 133 loss: 0.005919846706092358\n",
      "26 134 loss: 0.009196075610816479\n",
      "26 135 loss: 0.001024286262691021\n",
      "26 136 loss: 0.0047011165879666805\n",
      "26 137 loss: 0.0004280134744476527\n",
      "26 138 loss: 0.00897478312253952\n",
      "26 139 loss: 0.02050674520432949\n",
      "26 140 loss: 0.017775315791368484\n",
      "26 141 loss: 0.00759463245049119\n",
      "26 142 loss: 0.03336871787905693\n",
      "26 143 loss: 0.04932217672467232\n",
      "26 144 loss: 0.016649704426527023\n",
      "26 145 loss: 0.0032007480040192604\n",
      "26 146 loss: 0.014398504979908466\n",
      "26 147 loss: 0.0018026410834863782\n",
      "26 148 loss: 0.013177287764847279\n",
      "26 149 loss: 0.010266676545143127\n",
      "26 150 loss: 0.03763597458600998\n",
      "26 151 loss: 0.0044175428338348866\n",
      "26 152 loss: 0.0020764353685081005\n",
      "26 153 loss: 0.00822823029011488\n",
      "26 154 loss: 0.030323369428515434\n",
      "26 155 loss: 0.00674591027200222\n",
      "26 156 loss: 0.007312302943319082\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313bf7aa80f7437ebc8c412daf79b335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0 loss: 0.005566351115703583\n",
      "27 1 loss: 0.023680349811911583\n",
      "27 2 loss: 0.0031151392031461\n",
      "27 3 loss: 0.013040799647569656\n",
      "27 4 loss: 0.0019548030104488134\n",
      "27 5 loss: 0.03125078231096268\n",
      "27 6 loss: 0.00844897236675024\n",
      "27 7 loss: 0.03688947483897209\n",
      "27 8 loss: 0.027911055833101273\n",
      "27 9 loss: 0.001968958182260394\n",
      "27 10 loss: 0.0019298868719488382\n",
      "27 11 loss: 0.004389924928545952\n",
      "27 12 loss: 0.0014345443341881037\n",
      "27 13 loss: 0.002289121737703681\n",
      "27 14 loss: 0.05951056629419327\n",
      "27 15 loss: 0.019980955868959427\n",
      "27 16 loss: 0.0012398614780977368\n",
      "27 17 loss: 0.0021541444584727287\n",
      "27 18 loss: 0.0018949367804452777\n",
      "27 19 loss: 0.007975883781909943\n",
      "27 20 loss: 0.013009521178901196\n",
      "27 21 loss: 0.0030793650075793266\n",
      "27 22 loss: 0.012531698681414127\n",
      "27 23 loss: 0.0012855236418545246\n",
      "27 24 loss: 0.006622892804443836\n",
      "27 25 loss: 0.008938828483223915\n",
      "27 26 loss: 0.00681835412979126\n",
      "27 27 loss: 0.005372252780944109\n",
      "27 28 loss: 0.002596631646156311\n",
      "27 29 loss: 0.006902789697051048\n",
      "27 30 loss: 0.0015974317211657763\n",
      "27 31 loss: 0.0014636155683547258\n",
      "27 32 loss: 0.0012534859124571085\n",
      "27 33 loss: 0.0008843606919981539\n",
      "27 34 loss: 0.002058831276372075\n",
      "27 35 loss: 0.006606310606002808\n",
      "27 36 loss: 0.007375194225460291\n",
      "27 37 loss: 0.01625043898820877\n",
      "27 38 loss: 0.005359569098800421\n",
      "27 39 loss: 0.0014278875896707177\n",
      "27 40 loss: 0.009292060509324074\n",
      "27 41 loss: 0.0005276061710901558\n",
      "27 42 loss: 0.0027692774310708046\n",
      "27 43 loss: 0.002123218262568116\n",
      "27 44 loss: 0.0015348568558692932\n",
      "27 45 loss: 0.0014656409621238708\n",
      "27 46 loss: 0.0012973446864634752\n",
      "27 47 loss: 0.013217350468039513\n",
      "27 48 loss: 0.000731898529920727\n",
      "27 49 loss: 0.042800985276699066\n",
      "27 50 loss: 0.0019638510420918465\n",
      "27 51 loss: 0.0011662396136671305\n",
      "27 52 loss: 0.004529764410108328\n",
      "27 53 loss: 0.001719326013699174\n",
      "27 54 loss: 0.013830017298460007\n",
      "27 55 loss: 0.028512701392173767\n",
      "27 56 loss: 0.04399062693119049\n",
      "27 57 loss: 0.004372903145849705\n",
      "27 58 loss: 0.004588739946484566\n",
      "27 59 loss: 0.0036302742082625628\n",
      "27 60 loss: 0.013892797753214836\n",
      "27 61 loss: 0.0010990333976224065\n",
      "27 62 loss: 0.0031224447302520275\n",
      "27 63 loss: 0.022823171690106392\n",
      "27 64 loss: 0.006432084366679192\n",
      "27 65 loss: 0.00386168179102242\n",
      "27 66 loss: 0.005047949030995369\n",
      "27 67 loss: 0.0017415618058294058\n",
      "27 68 loss: 0.0034708089660853148\n",
      "27 69 loss: 0.06012740358710289\n",
      "27 70 loss: 0.009377655573189259\n",
      "27 71 loss: 0.025113428011536598\n",
      "27 72 loss: 0.009366506710648537\n",
      "27 73 loss: 0.029553521424531937\n",
      "27 74 loss: 0.0039713080041110516\n",
      "27 75 loss: 0.00432899035513401\n",
      "27 76 loss: 0.004287782125174999\n",
      "27 77 loss: 0.0012997827725484967\n",
      "27 78 loss: 0.019234510138630867\n",
      "27 79 loss: 0.0047844452783465385\n",
      "27 80 loss: 0.057036012411117554\n",
      "27 81 loss: 0.0015649138949811459\n",
      "27 82 loss: 0.03146273270249367\n",
      "27 83 loss: 0.01069624349474907\n",
      "27 84 loss: 0.033577725291252136\n",
      "27 85 loss: 0.002016420243307948\n",
      "27 86 loss: 0.017982080578804016\n",
      "27 87 loss: 0.028854500502347946\n",
      "27 88 loss: 0.0318903811275959\n",
      "27 89 loss: 0.02397996000945568\n",
      "27 90 loss: 0.019521240144968033\n",
      "27 91 loss: 0.013365303166210651\n",
      "27 92 loss: 0.04074163734912872\n",
      "27 93 loss: 0.02107478864490986\n",
      "27 94 loss: 0.0007950932485982776\n",
      "27 95 loss: 0.02230791188776493\n",
      "27 96 loss: 0.0333750918507576\n",
      "27 97 loss: 0.003445778042078018\n",
      "27 98 loss: 0.0025404300540685654\n",
      "27 99 loss: 0.003853947389870882\n",
      "27 100 loss: 0.0323452390730381\n",
      "27 101 loss: 0.0076172370463609695\n",
      "27 102 loss: 0.033551961183547974\n",
      "27 103 loss: 0.0030968529172241688\n",
      "27 104 loss: 0.0335896871984005\n",
      "27 105 loss: 0.0024234186857938766\n",
      "27 106 loss: 0.004384065978229046\n",
      "27 107 loss: 0.0326455794274807\n",
      "27 108 loss: 0.0019777058623731136\n",
      "27 109 loss: 0.0015118613373488188\n",
      "27 110 loss: 0.0031731361523270607\n",
      "27 111 loss: 0.00467899814248085\n",
      "27 112 loss: 0.004688472952693701\n",
      "27 113 loss: 0.0014794871676713228\n",
      "27 114 loss: 0.002405555220320821\n",
      "27 115 loss: 0.06656229496002197\n",
      "27 116 loss: 0.0034858202561736107\n",
      "27 117 loss: 0.01600288599729538\n",
      "27 118 loss: 0.0016099571948871017\n",
      "27 119 loss: 0.003551349975168705\n",
      "27 120 loss: 0.003667698008939624\n",
      "27 121 loss: 0.001988978125154972\n",
      "27 122 loss: 0.010279681533575058\n",
      "27 123 loss: 0.09653296321630478\n",
      "27 124 loss: 0.006003316026180983\n",
      "27 125 loss: 0.005874466150999069\n",
      "27 126 loss: 0.010001858696341515\n",
      "27 127 loss: 0.013842007145285606\n",
      "27 128 loss: 0.006819799076765776\n",
      "27 129 loss: 0.08553671091794968\n",
      "27 130 loss: 0.003991866018623114\n",
      "27 131 loss: 0.0093277832493186\n",
      "27 132 loss: 0.008722441270947456\n",
      "27 133 loss: 0.018791431561112404\n",
      "27 134 loss: 0.005389103665947914\n",
      "27 135 loss: 0.0031203823164105415\n",
      "27 136 loss: 0.0031907178927212954\n",
      "27 137 loss: 0.02263636887073517\n",
      "27 138 loss: 0.002824451308697462\n",
      "27 139 loss: 0.004503970500081778\n",
      "27 140 loss: 0.011647834442555904\n",
      "27 141 loss: 0.0019068721449002624\n",
      "27 142 loss: 0.0011146655306220055\n",
      "27 143 loss: 0.011507704854011536\n",
      "27 144 loss: 0.011861692182719707\n",
      "27 145 loss: 0.002857882995158434\n",
      "27 146 loss: 0.04888129234313965\n",
      "27 147 loss: 0.005444424692541361\n",
      "27 148 loss: 0.012369757518172264\n",
      "27 149 loss: 0.008948891423642635\n",
      "27 150 loss: 0.007611231412738562\n",
      "27 151 loss: 0.006486836820840836\n",
      "27 152 loss: 0.007354001514613628\n",
      "27 153 loss: 0.00443096412345767\n",
      "27 154 loss: 0.003945651464164257\n",
      "27 155 loss: 0.039550282061100006\n",
      "27 156 loss: 2.7733471142710187e-05\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e910602c7bb44b6a390bee8a60f2f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 0 loss: 0.006476474925875664\n",
      "28 1 loss: 0.0010491901775822043\n",
      "28 2 loss: 0.00425384659320116\n",
      "28 3 loss: 0.03188919275999069\n",
      "28 4 loss: 0.0016144505934789777\n",
      "28 5 loss: 0.028713349252939224\n",
      "28 6 loss: 0.0017805984243750572\n",
      "28 7 loss: 0.0013502074871212244\n",
      "28 8 loss: 0.03345917537808418\n",
      "28 9 loss: 0.0012002987787127495\n",
      "28 10 loss: 0.018260009586811066\n",
      "28 11 loss: 0.0069276620633900166\n",
      "28 12 loss: 0.0033709038980305195\n",
      "28 13 loss: 0.0040510669350624084\n",
      "28 14 loss: 0.0018484113970771432\n",
      "28 15 loss: 0.006472433917224407\n",
      "28 16 loss: 0.04778840392827988\n",
      "28 17 loss: 0.003050491213798523\n",
      "28 18 loss: 0.0010416615987196565\n",
      "28 19 loss: 0.0019612612668424845\n",
      "28 20 loss: 0.003379985922947526\n",
      "28 21 loss: 0.0016920609632506967\n",
      "28 22 loss: 0.0015923792961984873\n",
      "28 23 loss: 0.001844647340476513\n",
      "28 24 loss: 0.018280593678355217\n",
      "28 25 loss: 0.058878056704998016\n",
      "28 26 loss: 0.0010222892742604017\n",
      "28 27 loss: 0.005092845298349857\n",
      "28 28 loss: 0.0011546118184924126\n",
      "28 29 loss: 0.017735859379172325\n",
      "28 30 loss: 0.0008555607055313885\n",
      "28 31 loss: 0.0015176536981016397\n",
      "28 32 loss: 0.0029394361190497875\n",
      "28 33 loss: 0.013189735822379589\n",
      "28 34 loss: 0.004079988691955805\n",
      "28 35 loss: 0.027805713936686516\n",
      "28 36 loss: 0.0023018568754196167\n",
      "28 37 loss: 0.00584279652684927\n",
      "28 38 loss: 0.0041413982398808\n",
      "28 39 loss: 0.0021604152861982584\n",
      "28 40 loss: 0.0822528526186943\n",
      "28 41 loss: 0.002484765602275729\n",
      "28 42 loss: 0.002483576303347945\n",
      "28 43 loss: 0.031179159879684448\n",
      "28 44 loss: 0.028875309973955154\n",
      "28 45 loss: 0.02029116079211235\n",
      "28 46 loss: 0.002811295446008444\n",
      "28 47 loss: 0.0008815608453005552\n",
      "28 48 loss: 0.008016170933842659\n",
      "28 49 loss: 0.010356215760111809\n",
      "28 50 loss: 0.008814601227641106\n",
      "28 51 loss: 0.04471614956855774\n",
      "28 52 loss: 0.004506528377532959\n",
      "28 53 loss: 0.004407797008752823\n",
      "28 54 loss: 0.040971431881189346\n",
      "28 55 loss: 0.002601804444566369\n",
      "28 56 loss: 0.003590787760913372\n",
      "28 57 loss: 0.011202629655599594\n",
      "28 58 loss: 0.037933606654405594\n",
      "28 59 loss: 0.058981817215681076\n",
      "28 60 loss: 0.009442530572414398\n",
      "28 61 loss: 0.0024950923398137093\n",
      "28 62 loss: 0.02230360545217991\n",
      "28 63 loss: 0.015485583804547787\n",
      "28 64 loss: 0.014742608182132244\n",
      "28 65 loss: 0.006401670165359974\n",
      "28 66 loss: 0.0023652915842831135\n",
      "28 67 loss: 0.01920396275818348\n",
      "28 68 loss: 0.010843537747859955\n",
      "28 69 loss: 0.002928036730736494\n",
      "28 70 loss: 0.001452628057450056\n",
      "28 71 loss: 0.0010906696552410722\n",
      "28 72 loss: 0.00871994812041521\n",
      "28 73 loss: 0.0006431859219446778\n",
      "28 74 loss: 0.04363352805376053\n",
      "28 75 loss: 0.006799293681979179\n",
      "28 76 loss: 0.003699145745486021\n",
      "28 77 loss: 0.0008782822405919433\n",
      "28 78 loss: 0.004199816845357418\n",
      "28 79 loss: 0.0037694131024181843\n",
      "28 80 loss: 0.003360120113939047\n",
      "28 81 loss: 0.003354843705892563\n",
      "28 82 loss: 0.0020837183110415936\n",
      "28 83 loss: 0.0021876043174415827\n",
      "28 84 loss: 0.004630208481103182\n",
      "28 85 loss: 0.008401774801313877\n",
      "28 86 loss: 0.0004175434587523341\n",
      "28 87 loss: 0.0022386619821190834\n",
      "28 88 loss: 0.0009880263824015856\n",
      "28 89 loss: 0.0638110563158989\n",
      "28 90 loss: 0.02819903753697872\n",
      "28 91 loss: 0.0010827272199094296\n",
      "28 92 loss: 0.0021681077778339386\n",
      "28 93 loss: 0.0029968642629683018\n",
      "28 94 loss: 0.006391420494765043\n",
      "28 95 loss: 0.0024385247379541397\n",
      "28 96 loss: 0.003911872394382954\n",
      "28 97 loss: 0.038787610828876495\n",
      "28 98 loss: 0.0012610664125531912\n",
      "28 99 loss: 0.042620882391929626\n",
      "28 100 loss: 0.025176886469125748\n",
      "28 101 loss: 0.0037894677370786667\n",
      "28 102 loss: 0.004685459658503532\n",
      "28 103 loss: 0.013818221166729927\n",
      "28 104 loss: 0.030575649812817574\n",
      "28 105 loss: 0.0018309734296053648\n",
      "28 106 loss: 0.0035781387705355883\n",
      "28 107 loss: 0.021626051515340805\n",
      "28 108 loss: 0.0048094503581523895\n",
      "28 109 loss: 0.0030419309623539448\n",
      "28 110 loss: 0.012642282992601395\n",
      "28 111 loss: 0.02234986051917076\n",
      "28 112 loss: 0.011494208127260208\n",
      "28 113 loss: 0.00677574472501874\n",
      "28 114 loss: 0.03042786382138729\n",
      "28 115 loss: 0.003665209049358964\n",
      "28 116 loss: 0.005150654353201389\n",
      "28 117 loss: 0.0016194782219827175\n",
      "28 118 loss: 0.00507086468860507\n",
      "28 119 loss: 0.013217361643910408\n",
      "28 120 loss: 0.0060319858603179455\n",
      "28 121 loss: 0.0329318568110466\n",
      "28 122 loss: 0.001767134410329163\n",
      "28 123 loss: 0.003099111607298255\n",
      "28 124 loss: 0.004739684052765369\n",
      "28 125 loss: 0.040754273533821106\n",
      "28 126 loss: 0.000930535898078233\n",
      "28 127 loss: 0.002569030737504363\n",
      "28 128 loss: 0.0015213001752272248\n",
      "28 129 loss: 0.014031961560249329\n",
      "28 130 loss: 0.0010928284609690309\n",
      "28 131 loss: 0.0011407393030822277\n",
      "28 132 loss: 0.002719041658565402\n",
      "28 133 loss: 0.001523998100310564\n",
      "28 134 loss: 0.0007743356982246041\n",
      "28 135 loss: 0.0015910315560176969\n",
      "28 136 loss: 0.015064701437950134\n",
      "28 137 loss: 0.0013650937471538782\n",
      "28 138 loss: 0.012601331807672977\n",
      "28 139 loss: 0.001974130980670452\n",
      "28 140 loss: 0.008636841550469398\n",
      "28 141 loss: 0.001751886447891593\n",
      "28 142 loss: 0.0019523210357874632\n",
      "28 143 loss: 0.0010434719733893871\n",
      "28 144 loss: 0.004638094920665026\n",
      "28 145 loss: 0.02847636304795742\n",
      "28 146 loss: 0.0034152271691709757\n",
      "28 147 loss: 0.023766590282320976\n",
      "28 148 loss: 0.011223405599594116\n",
      "28 149 loss: 0.006993409246206284\n",
      "28 150 loss: 0.0027338548097759485\n",
      "28 151 loss: 0.002911051269620657\n",
      "28 152 loss: 0.014893356710672379\n",
      "28 153 loss: 0.0027697391342371702\n",
      "28 154 loss: 0.0009063545148819685\n",
      "28 155 loss: 0.006147004198282957\n",
      "28 156 loss: 8.188486390281469e-05\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5445d27cdd2b4a59b132ecfda8feb7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0 loss: 0.00769854336977005\n",
      "29 1 loss: 0.002317601116374135\n",
      "29 2 loss: 0.0012314605992287397\n",
      "29 3 loss: 0.0037064754869788885\n",
      "29 4 loss: 0.0020807734690606594\n",
      "29 5 loss: 0.008603353053331375\n",
      "29 6 loss: 0.004566385876387358\n",
      "29 7 loss: 0.01874910667538643\n",
      "29 8 loss: 0.001350344973616302\n",
      "29 9 loss: 0.0009574509458616376\n",
      "29 10 loss: 0.0008129746420308948\n",
      "29 11 loss: 0.0029295908752828836\n",
      "29 12 loss: 0.0006618694169446826\n",
      "29 13 loss: 0.0015668454580008984\n",
      "29 14 loss: 0.0008722062921151519\n",
      "29 15 loss: 0.0017480660462751985\n",
      "29 16 loss: 0.07476504892110825\n",
      "29 17 loss: 0.0010003719944506884\n",
      "29 18 loss: 0.027779672294855118\n",
      "29 19 loss: 0.000731695385184139\n",
      "29 20 loss: 0.0004316282575018704\n",
      "29 21 loss: 0.007370827719569206\n",
      "29 22 loss: 0.0007251653005369008\n",
      "29 23 loss: 0.001799687510356307\n",
      "29 24 loss: 0.03543168678879738\n",
      "29 25 loss: 0.01805134303867817\n",
      "29 26 loss: 0.04131472483277321\n",
      "29 27 loss: 0.02505001612007618\n",
      "29 28 loss: 0.0036299657076597214\n",
      "29 29 loss: 0.019296659156680107\n",
      "29 30 loss: 0.011097617447376251\n",
      "29 31 loss: 0.027520380914211273\n",
      "29 32 loss: 0.009670479223132133\n",
      "29 33 loss: 0.006142060272395611\n",
      "29 34 loss: 0.005133371334522963\n",
      "29 35 loss: 0.016742920503020287\n",
      "29 36 loss: 0.0055337511003017426\n",
      "29 37 loss: 0.004000321961939335\n",
      "29 38 loss: 0.008756437338888645\n",
      "29 39 loss: 0.002056269673630595\n",
      "29 40 loss: 0.004749729298055172\n",
      "29 41 loss: 0.03492498770356178\n",
      "29 42 loss: 0.000969245913438499\n",
      "29 43 loss: 0.0005527065368369222\n",
      "29 44 loss: 0.0010342857567593455\n",
      "29 45 loss: 0.0008242644253186882\n",
      "29 46 loss: 0.002295948565006256\n",
      "29 47 loss: 0.00038466419209726155\n",
      "29 48 loss: 0.016177348792552948\n",
      "29 49 loss: 0.043478868901729584\n",
      "29 50 loss: 0.0007467130199074745\n",
      "29 51 loss: 0.00613176915794611\n",
      "29 52 loss: 0.0013757646083831787\n",
      "29 53 loss: 0.026890574023127556\n",
      "29 54 loss: 0.03244160860776901\n",
      "29 55 loss: 0.04236703738570213\n",
      "29 56 loss: 0.003588253166526556\n",
      "29 57 loss: 0.004184855613857508\n",
      "29 58 loss: 0.005871699657291174\n",
      "29 59 loss: 0.0060934158973395824\n",
      "29 60 loss: 0.021130042150616646\n",
      "29 61 loss: 0.03696838766336441\n",
      "29 62 loss: 0.004281014669686556\n",
      "29 63 loss: 0.005110164172947407\n",
      "29 64 loss: 0.004139887634664774\n",
      "29 65 loss: 0.010034125298261642\n",
      "29 66 loss: 0.0035686118062585592\n",
      "29 67 loss: 0.02774404175579548\n",
      "29 68 loss: 0.004594487138092518\n",
      "29 69 loss: 0.0006159095210023224\n",
      "29 70 loss: 0.001616652007214725\n",
      "29 71 loss: 0.011103501543402672\n",
      "29 72 loss: 0.004450085572898388\n",
      "29 73 loss: 0.004681786522269249\n",
      "29 74 loss: 0.07127846777439117\n",
      "29 75 loss: 0.0035514007322490215\n",
      "29 76 loss: 0.002406235784292221\n",
      "29 77 loss: 0.006495238281786442\n",
      "29 78 loss: 0.06539849936962128\n",
      "29 79 loss: 0.002686566673219204\n",
      "29 80 loss: 0.009575425647199154\n",
      "29 81 loss: 0.001247411360964179\n",
      "29 82 loss: 0.002623343374580145\n",
      "29 83 loss: 0.015950096771121025\n",
      "29 84 loss: 0.01724192500114441\n",
      "29 85 loss: 0.06404076516628265\n",
      "29 86 loss: 0.005792800337076187\n",
      "29 87 loss: 0.01066882535815239\n",
      "29 88 loss: 0.0040772720240056515\n",
      "29 89 loss: 0.004105560947209597\n",
      "29 90 loss: 0.007497094105929136\n",
      "29 91 loss: 0.03203389048576355\n",
      "29 92 loss: 0.007711329497396946\n",
      "29 93 loss: 0.003208580194041133\n",
      "29 94 loss: 0.0019010624382644892\n",
      "29 95 loss: 0.003504696302115917\n",
      "29 96 loss: 0.0018853552173823118\n",
      "29 97 loss: 0.023890912532806396\n",
      "29 98 loss: 0.0039605447091162205\n",
      "29 99 loss: 0.006533218547701836\n",
      "29 100 loss: 0.0012188621331006289\n",
      "29 101 loss: 0.0013192127225920558\n",
      "29 102 loss: 0.0018898941343650222\n",
      "29 103 loss: 0.003323302837088704\n",
      "29 104 loss: 0.016684111207723618\n",
      "29 105 loss: 0.0025093380827456713\n",
      "29 106 loss: 0.00022204325068742037\n",
      "29 107 loss: 0.0011503014247864485\n",
      "29 108 loss: 0.03729752078652382\n",
      "29 109 loss: 0.007293062750250101\n",
      "29 110 loss: 0.0002785446704365313\n",
      "29 111 loss: 0.0007147142896428704\n",
      "29 112 loss: 0.0004939882201142609\n",
      "29 113 loss: 0.014060438610613346\n",
      "29 114 loss: 0.0005364939570426941\n",
      "29 115 loss: 0.012044258415699005\n",
      "29 116 loss: 0.001921380520798266\n",
      "29 117 loss: 0.0005534696392714977\n",
      "29 118 loss: 0.011191739700734615\n",
      "29 119 loss: 0.005347948055714369\n",
      "29 120 loss: 0.01671430841088295\n",
      "29 121 loss: 0.005849593318998814\n",
      "29 122 loss: 0.010025478899478912\n",
      "29 123 loss: 0.006816108711063862\n",
      "29 124 loss: 0.004073310177773237\n",
      "29 125 loss: 0.0020831176079809666\n",
      "29 126 loss: 0.0005147962365299463\n",
      "29 127 loss: 0.0008474577334709466\n",
      "29 128 loss: 0.010739719495177269\n",
      "29 129 loss: 0.002212030813097954\n",
      "29 130 loss: 0.0006087460787966847\n",
      "29 131 loss: 0.00047427747631445527\n",
      "29 132 loss: 0.01716511882841587\n",
      "29 133 loss: 0.062145307660102844\n",
      "29 134 loss: 0.0008139660349115729\n",
      "29 135 loss: 0.0008818895439617336\n",
      "29 136 loss: 0.0007879143813624978\n",
      "29 137 loss: 0.06047871336340904\n",
      "29 138 loss: 0.0006591608398593962\n",
      "29 139 loss: 0.0008975479286164045\n",
      "29 140 loss: 0.01452244259417057\n",
      "29 141 loss: 0.00111640733666718\n",
      "29 142 loss: 0.0021338672377169132\n",
      "29 143 loss: 0.0008539154659956694\n",
      "29 144 loss: 0.002861838787794113\n",
      "29 145 loss: 0.022668257355690002\n",
      "29 146 loss: 0.0073670619167387486\n",
      "29 147 loss: 0.0046205585822463036\n",
      "29 148 loss: 0.004424573853611946\n",
      "29 149 loss: 0.0053764767944812775\n",
      "29 150 loss: 0.0009293177863582969\n",
      "29 151 loss: 0.016957545652985573\n",
      "29 152 loss: 0.0016427070368081331\n",
      "29 153 loss: 0.00135515327565372\n",
      "29 154 loss: 0.005900450982153416\n",
      "29 155 loss: 0.0014691450633108616\n",
      "29 156 loss: 0.0004953596508130431\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141dbeab706d4ab3a78fa4ad0456e397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 0 loss: 0.0005184750771149993\n",
      "30 1 loss: 0.0011795840691775084\n",
      "30 2 loss: 0.004821775946766138\n",
      "30 3 loss: 0.004598965402692556\n",
      "30 4 loss: 0.0003000882570631802\n",
      "30 5 loss: 0.010442828759551048\n",
      "30 6 loss: 0.0005409301957115531\n",
      "30 7 loss: 0.0337037555873394\n",
      "30 8 loss: 0.05583368241786957\n",
      "30 9 loss: 0.002017894061282277\n",
      "30 10 loss: 0.0009168143151327968\n",
      "30 11 loss: 0.00017169208149425685\n",
      "30 12 loss: 0.00045145017793402076\n",
      "30 13 loss: 0.005361748859286308\n",
      "30 14 loss: 0.01590864732861519\n",
      "30 15 loss: 0.008459744974970818\n",
      "30 16 loss: 0.01094420813024044\n",
      "30 17 loss: 0.0032454298343509436\n",
      "30 18 loss: 0.0054534487426280975\n",
      "30 19 loss: 0.002202940173447132\n",
      "30 20 loss: 0.022141309455037117\n",
      "30 21 loss: 0.0031852282118052244\n",
      "30 22 loss: 0.016311032697558403\n",
      "30 23 loss: 0.001965909032151103\n",
      "30 24 loss: 0.0014590061036869884\n",
      "30 25 loss: 0.0015257211634889245\n",
      "30 26 loss: 0.004495800007134676\n",
      "30 27 loss: 0.003442243905737996\n",
      "30 28 loss: 0.010601327754557133\n",
      "30 29 loss: 0.0008137632394209504\n",
      "30 30 loss: 0.0005718868924304843\n",
      "30 31 loss: 0.03593295067548752\n",
      "30 32 loss: 0.0017587089678272605\n",
      "30 33 loss: 0.001743591157719493\n",
      "30 34 loss: 0.0024342508986592293\n",
      "30 35 loss: 0.0007787330541759729\n",
      "30 36 loss: 0.01648336462676525\n",
      "30 37 loss: 0.00047803594497963786\n",
      "30 38 loss: 0.0028685713186860085\n",
      "30 39 loss: 0.00744685810059309\n",
      "30 40 loss: 0.005211664829403162\n",
      "30 41 loss: 0.010871617123484612\n",
      "30 42 loss: 0.0014155781827867031\n",
      "30 43 loss: 0.01082414761185646\n",
      "30 44 loss: 0.00205235811881721\n",
      "30 45 loss: 0.002623370150104165\n",
      "30 46 loss: 0.0026068747974932194\n",
      "30 47 loss: 0.0020252051763236523\n",
      "30 48 loss: 0.018766099587082863\n",
      "30 49 loss: 0.001552399480715394\n",
      "30 50 loss: 0.014688089489936829\n",
      "30 51 loss: 0.003395642153918743\n",
      "30 52 loss: 0.0018223002552986145\n",
      "30 53 loss: 0.008828001096844673\n",
      "30 54 loss: 0.0725942924618721\n",
      "30 55 loss: 0.003190205665305257\n",
      "30 56 loss: 0.0016066598473116755\n",
      "30 57 loss: 0.003194207325577736\n",
      "30 58 loss: 0.009032263420522213\n",
      "30 59 loss: 0.0005781220970675349\n",
      "30 60 loss: 0.0017600881401449442\n",
      "30 61 loss: 0.005138057749718428\n",
      "30 62 loss: 0.0010733997914940119\n",
      "30 63 loss: 0.0008121568826027215\n",
      "30 64 loss: 0.0011452530743554235\n",
      "30 65 loss: 0.001995252212509513\n",
      "30 66 loss: 0.0012134629068896174\n",
      "30 67 loss: 0.020573003217577934\n",
      "30 68 loss: 0.0005993674858473241\n",
      "30 69 loss: 0.05326002091169357\n",
      "30 70 loss: 0.0035124903079122305\n",
      "30 71 loss: 0.0031389074865728617\n",
      "30 72 loss: 0.002993791364133358\n",
      "30 73 loss: 0.005565137602388859\n",
      "30 74 loss: 0.0057626282796263695\n",
      "30 75 loss: 0.01398347970098257\n",
      "30 76 loss: 0.0026712892577052116\n",
      "30 77 loss: 0.0023948552552610636\n",
      "30 78 loss: 0.006705216597765684\n",
      "30 79 loss: 0.002029608702287078\n",
      "30 80 loss: 0.0020641295704990625\n",
      "30 81 loss: 0.0004401490150485188\n",
      "30 82 loss: 0.02666712924838066\n",
      "30 83 loss: 0.0032325643114745617\n",
      "30 84 loss: 0.014607153832912445\n",
      "30 85 loss: 0.0005349245620891452\n",
      "30 86 loss: 0.011342842131853104\n",
      "30 87 loss: 0.0006015008548274636\n",
      "30 88 loss: 0.0005751547869294882\n",
      "30 89 loss: 0.0012038073036819696\n",
      "30 90 loss: 0.0015305420383810997\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b29d2e387755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{epoch} {i} loss: {loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#         clip_grad_norm_(reward_function.parameters(), 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/imagineIOT/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/imagineIOT/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, batch in tqdm(enumerate(train_loader)):\n",
    "#         print(batch['reward'].float().mean())\n",
    "        optimizer.zero_grad()\n",
    "        reward = reward_function(state=batch['state'], instructions=batch['instruction']).view(-1)\n",
    "        loss = loss_func(reward, batch['reward'].float().to(params['device']))\n",
    "        print(f'{epoch} {i} loss: {loss.item()}')\n",
    "        loss.backward()\n",
    "#         clip_grad_norm_(reward_function.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:28:52.001279Z",
     "start_time": "2020-08-28T16:28:51.972380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T12:09:11.826989Z",
     "start_time": "2020-09-01T12:08:57.575098Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T12:58:29.774137Z",
     "start_time": "2020-09-01T12:58:29.184504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/imagineIOT/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nicolas/miniconda3/envs/imagineIOT/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nicolas/miniconda3/envs/imagineIOT/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1514: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>true_0</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>true_1</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now average</th>\n",
       "      <th>0</th>\n",
       "      <td>247.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now high</th>\n",
       "      <th>0</th>\n",
       "      <td>219.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now low</th>\n",
       "      <th>0</th>\n",
       "      <td>263.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very high</th>\n",
       "      <th>0</th>\n",
       "      <td>251.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.996016</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very low</th>\n",
       "      <th>0</th>\n",
       "      <td>229.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You decreased the luminosity of first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>269.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.996283</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You increased the luminosity of first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>246.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb colder</th>\n",
       "      <th>0</th>\n",
       "      <td>242.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb warmer</th>\n",
       "      <th>0</th>\n",
       "      <td>243.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to blue</th>\n",
       "      <th>0</th>\n",
       "      <td>263.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to green</th>\n",
       "      <th>0</th>\n",
       "      <td>211.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to orange</th>\n",
       "      <th>0</th>\n",
       "      <td>283.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to pink</th>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.996403</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to purple</th>\n",
       "      <th>0</th>\n",
       "      <td>251.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to red</th>\n",
       "      <th>0</th>\n",
       "      <td>245.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to yellow</th>\n",
       "      <th>0</th>\n",
       "      <td>262.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>268.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first plug</th>\n",
       "      <th>0</th>\n",
       "      <td>233.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>244.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first plug</th>\n",
       "      <th>0</th>\n",
       "      <td>253.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      count  true_0  pred_0  \\\n",
       "instruction                                                                   \n",
       "The luminosity of first light bulb is now average  0  247.0   245.0   245.0   \n",
       "The luminosity of first light bulb is now high     0  219.0   198.0   195.0   \n",
       "The luminosity of first light bulb is now low      0  263.0   258.0   258.0   \n",
       "The luminosity of first light bulb is now very ... 0  251.0   243.0   242.0   \n",
       "The luminosity of first light bulb is now very low 0  229.0   220.0   220.0   \n",
       "You decreased the luminosity of first light bulb   0  269.0   255.0   254.0   \n",
       "You increased the luminosity of first light bulb   0  246.0   220.0   220.0   \n",
       "You made the light of first light bulb colder      0  242.0   215.0   215.0   \n",
       "You made the light of first light bulb warmer      0  243.0   206.0   206.0   \n",
       "You set the color of first light bulb to blue      0  263.0   262.0   262.0   \n",
       "You set the color of first light bulb to green     0  211.0   211.0   211.0   \n",
       "You set the color of first light bulb to orange    0  283.0   282.0   282.0   \n",
       "You set the color of first light bulb to pink      0  278.0   274.0   273.0   \n",
       "You set the color of first light bulb to purple    0  251.0   250.0   250.0   \n",
       "You set the color of first light bulb to red       0  245.0   244.0   244.0   \n",
       "You set the color of first light bulb to yellow    0  262.0   261.0   261.0   \n",
       "You turned off the first light bulb                0  268.0   264.0   264.0   \n",
       "You turned off the first plug                      0  233.0   207.0   207.0   \n",
       "You turned on the first light bulb                 0  244.0   227.0   222.0   \n",
       "You turned on the first plug                       0  253.0   223.0   223.0   \n",
       "\n",
       "                                                      true_1  pred_1  \\\n",
       "instruction                                                            \n",
       "The luminosity of first light bulb is now average  0     2.0     2.0   \n",
       "The luminosity of first light bulb is now high     0    21.0    24.0   \n",
       "The luminosity of first light bulb is now low      0     5.0     5.0   \n",
       "The luminosity of first light bulb is now very ... 0     8.0     9.0   \n",
       "The luminosity of first light bulb is now very low 0     9.0     9.0   \n",
       "You decreased the luminosity of first light bulb   0    14.0    15.0   \n",
       "You increased the luminosity of first light bulb   0    26.0    26.0   \n",
       "You made the light of first light bulb colder      0    27.0    27.0   \n",
       "You made the light of first light bulb warmer      0    37.0    37.0   \n",
       "You set the color of first light bulb to blue      0     1.0     1.0   \n",
       "You set the color of first light bulb to green     0     0.0     0.0   \n",
       "You set the color of first light bulb to orange    0     1.0     1.0   \n",
       "You set the color of first light bulb to pink      0     4.0     5.0   \n",
       "You set the color of first light bulb to purple    0     1.0     1.0   \n",
       "You set the color of first light bulb to red       0     1.0     1.0   \n",
       "You set the color of first light bulb to yellow    0     1.0     1.0   \n",
       "You turned off the first light bulb                0     4.0     4.0   \n",
       "You turned off the first plug                      0    26.0    26.0   \n",
       "You turned on the first light bulb                 0    17.0    22.0   \n",
       "You turned on the first plug                       0    30.0    30.0   \n",
       "\n",
       "                                                      accuracy  precision  \\\n",
       "instruction                                                                 \n",
       "The luminosity of first light bulb is now average  0  1.000000   1.000000   \n",
       "The luminosity of first light bulb is now high     0  0.986301   0.875000   \n",
       "The luminosity of first light bulb is now low      0  1.000000   1.000000   \n",
       "The luminosity of first light bulb is now very ... 0  0.996016   0.888889   \n",
       "The luminosity of first light bulb is now very low 0  1.000000   1.000000   \n",
       "You decreased the luminosity of first light bulb   0  0.996283   0.933333   \n",
       "You increased the luminosity of first light bulb   0  1.000000   1.000000   \n",
       "You made the light of first light bulb colder      0  1.000000   1.000000   \n",
       "You made the light of first light bulb warmer      0  1.000000   1.000000   \n",
       "You set the color of first light bulb to blue      0  1.000000   1.000000   \n",
       "You set the color of first light bulb to green     0  1.000000   0.000000   \n",
       "You set the color of first light bulb to orange    0  1.000000   1.000000   \n",
       "You set the color of first light bulb to pink      0  0.996403   0.800000   \n",
       "You set the color of first light bulb to purple    0  1.000000   1.000000   \n",
       "You set the color of first light bulb to red       0  1.000000   1.000000   \n",
       "You set the color of first light bulb to yellow    0  1.000000   1.000000   \n",
       "You turned off the first light bulb                0  1.000000   1.000000   \n",
       "You turned off the first plug                      0  1.000000   1.000000   \n",
       "You turned on the first light bulb                 0  0.979508   0.772727   \n",
       "You turned on the first plug                       0  1.000000   1.000000   \n",
       "\n",
       "                                                      recall  f1_score  \n",
       "instruction                                                             \n",
       "The luminosity of first light bulb is now average  0     1.0  1.000000  \n",
       "The luminosity of first light bulb is now high     0     1.0  0.933333  \n",
       "The luminosity of first light bulb is now low      0     1.0  1.000000  \n",
       "The luminosity of first light bulb is now very ... 0     1.0  0.941176  \n",
       "The luminosity of first light bulb is now very low 0     1.0  1.000000  \n",
       "You decreased the luminosity of first light bulb   0     1.0  0.965517  \n",
       "You increased the luminosity of first light bulb   0     1.0  1.000000  \n",
       "You made the light of first light bulb colder      0     1.0  1.000000  \n",
       "You made the light of first light bulb warmer      0     1.0  1.000000  \n",
       "You set the color of first light bulb to blue      0     1.0  1.000000  \n",
       "You set the color of first light bulb to green     0     0.0  0.000000  \n",
       "You set the color of first light bulb to orange    0     1.0  1.000000  \n",
       "You set the color of first light bulb to pink      0     1.0  0.888889  \n",
       "You set the color of first light bulb to purple    0     1.0  1.000000  \n",
       "You set the color of first light bulb to red       0     1.0  1.000000  \n",
       "You set the color of first light bulb to yellow    0     1.0  1.000000  \n",
       "You turned off the first light bulb                0     1.0  1.000000  \n",
       "You turned off the first plug                      0     1.0  1.000000  \n",
       "You turned on the first light bulb                 0     1.0  0.871795  \n",
       "You turned on the first plug                       0     1.0  1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score\n",
    "\n",
    "def compute_stats(g):\n",
    "    count = len(g)\n",
    "    pred_1 = g.pred.sum()\n",
    "    pred_0 = (1 - g.pred).sum()\n",
    "    true_1 = g.true.sum()\n",
    "    true_0 = (1 - g.true).sum()\n",
    "    stats = [count, true_0, pred_0, true_1, pred_1]\n",
    "    stats_name = ['count', 'true_0', 'pred_0', 'true_1', 'pred_1']\n",
    "    result = pd.DataFrame(stats).T\n",
    "    result.columns = stats_name\n",
    "    return result\n",
    "\n",
    "def compute_classification_metrics(g):\n",
    "    accuracy = accuracy_score(g.true, g.pred)\n",
    "    precision = precision_score(g.true, g.pred)\n",
    "    recall = recall_score(g.true, g.pred)\n",
    "    f1 = f1_score(g.true, g.pred)\n",
    "    scores = [accuracy, precision, recall, f1]\n",
    "    score_name = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    result = pd.DataFrame(scores).T\n",
    "    result.columns = score_name\n",
    "    return result\n",
    "    \n",
    "def compute_metrics(g, data_stats=False):\n",
    "    df_score = compute_classification_metrics(g)\n",
    "    df_stats = compute_stats(g) if data_stats else pd.DataFrame()\n",
    "    result = pd.concat([df_stats, df_score], axis=1)\n",
    "    return result\n",
    "\n",
    "test_reward = reward_function(state=test_batch['state'], instructions=test_batch['instruction'])#.view(-1)\n",
    "torch.cat([test_reward.cpu(), test_batch['reward'].float().view(-1, 1)], dim=1)\n",
    "pred_true_tensor = torch.cat([(test_reward >0.5).float().cpu(), test_batch['reward'].float().view(-1, 1)], dim=1) \n",
    "df = pd.DataFrame(pred_true_tensor.detach().numpy(), columns=['pred', 'true'])\n",
    "df['instruction'] = test_batch['instruction']\n",
    "stats = df.groupby('instruction').apply(compute_metrics, data_stats=True)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T12:58:37.152498Z",
     "start_time": "2020-09-01T12:58:37.119467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930035540299232"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f1_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T17:04:00.632938Z",
     "start_time": "2020-08-28T17:04:00.550720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.683014</td>\n",
       "      <td>0.718773</td>\n",
       "      <td>0.700437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall  f1_score\n",
       "0    0.9726   0.683014  0.718773  0.700437"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n",
    "compute_classification_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T17:05:42.710267Z",
     "start_time": "2020-08-28T17:05:42.644665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255</td>\n",
       "      <td>9745</td>\n",
       "      <td>You turned off the first light bulb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248</td>\n",
       "      <td>9752</td>\n",
       "      <td>The luminosity of first light bulb is now very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>9938</td>\n",
       "      <td>You set the color of first light bulb to orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>9963</td>\n",
       "      <td>You set the color of first light bulb to green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1076</td>\n",
       "      <td>8924</td>\n",
       "      <td>You made the light of first light bulb warmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>826</td>\n",
       "      <td>9174</td>\n",
       "      <td>You turned on the first light bulb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1102</td>\n",
       "      <td>8898</td>\n",
       "      <td>You made the light of first light bulb colder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>516</td>\n",
       "      <td>9484</td>\n",
       "      <td>The luminosity of first light bulb is now high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>292</td>\n",
       "      <td>9708</td>\n",
       "      <td>The luminosity of first light bulb is now very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>113</td>\n",
       "      <td>9887</td>\n",
       "      <td>The luminosity of first light bulb is now low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>9953</td>\n",
       "      <td>You set the color of first light bulb to purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1270</td>\n",
       "      <td>8730</td>\n",
       "      <td>You turned off the first plug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>9935</td>\n",
       "      <td>You set the color of first light bulb to pink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>544</td>\n",
       "      <td>9456</td>\n",
       "      <td>You decreased the luminosity of first light bulb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1185</td>\n",
       "      <td>8815</td>\n",
       "      <td>You increased the luminosity of first light bulb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114</td>\n",
       "      <td>9886</td>\n",
       "      <td>The luminosity of first light bulb is now average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1232</td>\n",
       "      <td>8768</td>\n",
       "      <td>You turned on the first plug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>67</td>\n",
       "      <td>9933</td>\n",
       "      <td>You set the color of first light bulb to red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>65</td>\n",
       "      <td>9935</td>\n",
       "      <td>You set the color of first light bulb to yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>45</td>\n",
       "      <td>9955</td>\n",
       "      <td>You set the color of first light bulb to blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1                                        instruction\n",
       "0    255  9745                You turned off the first light bulb\n",
       "1    248  9752  The luminosity of first light bulb is now very...\n",
       "2     62  9938    You set the color of first light bulb to orange\n",
       "3     37  9963     You set the color of first light bulb to green\n",
       "4   1076  8924      You made the light of first light bulb warmer\n",
       "5    826  9174                 You turned on the first light bulb\n",
       "6   1102  8898      You made the light of first light bulb colder\n",
       "7    516  9484     The luminosity of first light bulb is now high\n",
       "8    292  9708  The luminosity of first light bulb is now very...\n",
       "9    113  9887      The luminosity of first light bulb is now low\n",
       "10    47  9953    You set the color of first light bulb to purple\n",
       "11  1270  8730                      You turned off the first plug\n",
       "12    65  9935      You set the color of first light bulb to pink\n",
       "13   544  9456   You decreased the luminosity of first light bulb\n",
       "14  1185  8815   You increased the luminosity of first light bulb\n",
       "15   114  9886  The luminosity of first light bulb is now average\n",
       "16  1232  8768                       You turned on the first plug\n",
       "17    67  9933       You set the color of first light bulb to red\n",
       "18    65  9935    You set the color of first light bulb to yellow\n",
       "19    45  9955      You set the color of first light bulb to blue"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_count = [len(v) for v in dts.positive_record.values()]\n",
    "negative_count = [len(v) for v in dts.negative_record.values()]\n",
    "df = pd.DataFrame([positive_count, negative_count]).T\n",
    "df['instruction'] = list(dts.positive_record)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:19:43.671021Z",
     "start_time": "2020-08-28T10:14:56.601726Z"
    }
   },
   "outputs": [],
   "source": [
    "dts_batch = next(iter(dts_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T11:26:36.739126Z",
     "start_time": "2020-08-28T11:26:36.641887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now average</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4934</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now high</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4791</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now low</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4946</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very high</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4856</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The luminosity of first light bulb is now very low</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4894</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You decreased the luminosity of first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4757</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You increased the luminosity of first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4443</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb colder</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4441</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You made the light of first light bulb warmer</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4431</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to blue</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4982</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to green</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4982</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to orange</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4979</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to pink</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4979</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to purple</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4981</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to red</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4981</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You set the color of first light bulb to yellow</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4964</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4890</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned off the first plug</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4399</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first light bulb</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4619</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You turned on the first plug</th>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>4339</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      count   neg  pos\n",
       "instruction                                                           \n",
       "The luminosity of first light bulb is now average  0   5000  4934   66\n",
       "The luminosity of first light bulb is now high     0   5000  4791  209\n",
       "The luminosity of first light bulb is now low      0   5000  4946   54\n",
       "The luminosity of first light bulb is now very ... 0   5000  4856  144\n",
       "The luminosity of first light bulb is now very low 0   5000  4894  106\n",
       "You decreased the luminosity of first light bulb   0   5000  4757  243\n",
       "You increased the luminosity of first light bulb   0   5000  4443  557\n",
       "You made the light of first light bulb colder      0   5000  4441  559\n",
       "You made the light of first light bulb warmer      0   5000  4431  569\n",
       "You set the color of first light bulb to blue      0   5000  4982   18\n",
       "You set the color of first light bulb to green     0   5000  4982   18\n",
       "You set the color of first light bulb to orange    0   5000  4979   21\n",
       "You set the color of first light bulb to pink      0   5000  4979   21\n",
       "You set the color of first light bulb to purple    0   5000  4981   19\n",
       "You set the color of first light bulb to red       0   5000  4981   19\n",
       "You set the color of first light bulb to yellow    0   5000  4964   36\n",
       "You turned off the first light bulb                0   5000  4890  110\n",
       "You turned off the first plug                      0   5000  4399  601\n",
       "You turned on the first light bulb                 0   5000  4619  381\n",
       "You turned on the first plug                       0   5000  4339  661"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_stats(g):\n",
    "    count = len(g)\n",
    "    pos = g.reward.sum()\n",
    "    neg = (1 - g.reward).sum()\n",
    "    stats = [count, neg, pos]\n",
    "    stats_name = ['count', 'neg', 'pos']\n",
    "    result = pd.DataFrame(stats).T\n",
    "    result.columns = stats_name\n",
    "    return result\n",
    "\n",
    "df_dts = pd.DataFrame(dts_batch['reward'].numpy(), columns=['reward'])\n",
    "df_dts['instruction'] = dts_batch['instruction']\n",
    "df_dts.groupby('instruction').apply(compute_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T17:19:13.518811Z",
     "start_time": "2020-09-01T17:19:13.470576Z"
    }
   },
   "source": [
    "## Compare reward function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T14:52:33.088627Z",
     "start_time": "2020-09-02T14:52:33.063308Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Net, self).__init__()\n",
    "        self.shared_encoding = nn.Sequential(nn.Linear(1, 100),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Linear(100, n_inputs))\n",
    "        self.out_layer = nn.Sequential(nn.Linear(n_inputs, 100),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(100, 1),\n",
    "                                       nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.shared_encoding(x.unsqueeze(dim=2))\n",
    "        latent = latent.sum(dim=1)\n",
    "        out = self.out_layer(latent)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T15:15:04.872559Z",
     "start_time": "2020-09-02T15:15:04.258485Z"
    }
   },
   "outputs": [],
   "source": [
    "language_model = LanguageModel(**params['language_model_params'])\n",
    "reward = RewardModel(context_model=params['model_params']['context_model'], language_model=language_model,\n",
    "                     reward_params=params['reward_params']['net_params'])\n",
    "\n",
    "reward_net_params = params['reward_params']['net_params'].copy()\n",
    "reward_net_params.update(aggregate='diff_or',\n",
    "                         scaler_layer_params=dict(hidden1_out=256, latent_out=1, last_activation='sigmoid')\n",
    "                         )\n",
    "prelearned_or_reward = RewardModel(context_model=params['model_params']['context_model'],\n",
    "                                   language_model=language_model,\n",
    "                                   reward_params=reward_net_params)\n",
    "\n",
    "prelearned_or_reward = RewardModel(context_model=params['model_params']['context_model'],\n",
    "                                   language_model=language_model,\n",
    "                                   reward_params=reward_net_params)\n",
    "reward_list= [reward, prelearned_or_reward]\n",
    "evaluator = RewardComparision(reward_list, fit_params=params['reward_params']['fit_params'],\n",
    "                              device=params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-02T15:15:10.363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: loss: [0.49062734842300415, 0.5331212282180786]\n",
      "Epoch: 1: loss: [0.42949768900871277, 0.5039872527122498]\n",
      "Epoch: 2: loss: [0.38533565402030945, 0.4924776554107666]\n",
      "Epoch: 3: loss: [0.3754216730594635, 0.5010824203491211]\n",
      "Epoch: 4: loss: [0.36204811930656433, 0.5044633150100708]\n",
      "Epoch: 5: loss: [0.31432783603668213, 0.4790242612361908]\n",
      "Epoch: 6: loss: [0.30259013175964355, 0.48583856225013733]\n",
      "Epoch: 7: loss: [0.2990313172340393, 0.48466721177101135]\n",
      "Epoch: 8: loss: [0.27609536051750183, 0.48269522190093994]\n",
      "Epoch: 9: loss: [0.2726542353630066, 0.4854130446910858]\n",
      "Epoch: 10: loss: [0.25814196467399597, 0.4773463010787964]\n",
      "Epoch: 11: loss: [0.2654891312122345, 0.4790959358215332]\n",
      "Epoch: 12: loss: [0.2476426512002945, 0.49161896109580994]\n",
      "Epoch: 13: loss: [0.23864726722240448, 0.47595205903053284]\n",
      "Epoch: 14: loss: [0.24070262908935547, 0.48695698380470276]\n",
      "Epoch: 15: loss: [0.23039725422859192, 0.48434388637542725]\n",
      "Epoch: 16: loss: [0.23314276337623596, 0.47656306624412537]\n",
      "Epoch: 17: loss: [0.22677968442440033, 0.48371997475624084]\n",
      "Epoch: 18: loss: [0.2112976759672165, 0.4767827093601227]\n",
      "Epoch: 19: loss: [0.20975908637046814, 0.4743362069129944]\n",
      "Epoch: 20: loss: [0.21740466356277466, 0.48426249623298645]\n",
      "Epoch: 21: loss: [0.2006184458732605, 0.47649461030960083]\n",
      "Epoch: 22: loss: [0.19944505393505096, 0.4753374457359314]\n",
      "Epoch: 23: loss: [0.20273935794830322, 0.48295196890830994]\n",
      "Epoch: 24: loss: [0.19458064436912537, 0.4787411093711853]\n",
      "Epoch: 25: loss: [0.17316533625125885, 0.4819565415382385]\n",
      "Epoch: 26: loss: [0.20447766780853271, 0.4753974378108978]\n",
      "Epoch: 27: loss: [0.18977265059947968, 0.48181143403053284]\n",
      "Epoch: 28: loss: [0.18593257665634155, 0.4805524945259094]\n",
      "Epoch: 29: loss: [0.1889590620994568, 0.47785332798957825]\n",
      "Epoch: 30: loss: [0.18511933088302612, 0.47719135880470276]\n",
      "Epoch: 31: loss: [0.17594574391841888, 0.4736176133155823]\n",
      "Epoch: 32: loss: [0.1864503175020218, 0.48891937732696533]\n",
      "Epoch: 33: loss: [0.16858205199241638, 0.4631795883178711]\n",
      "Epoch: 34: loss: [0.1688673347234726, 0.4741148352622986]\n",
      "Epoch: 35: loss: [0.17924495041370392, 0.48290449380874634]\n",
      "Epoch: 36: loss: [0.18091867864131927, 0.47978970408439636]\n",
      "Epoch: 37: loss: [0.16996730864048004, 0.475883811712265]\n",
      "Epoch: 38: loss: [0.15426617860794067, 0.47860947251319885]\n",
      "Epoch: 39: loss: [0.14375276863574982, 0.4644807279109955]\n",
      "Epoch: 40: loss: [0.16714249551296234, 0.4707900285720825]\n",
      "Epoch: 41: loss: [0.1658010333776474, 0.4797607958316803]\n",
      "Epoch: 42: loss: [0.15323367714881897, 0.4739050567150116]\n",
      "Epoch: 43: loss: [0.1581009477376938, 0.48382511734962463]\n",
      "Epoch: 44: loss: [0.14395633339881897, 0.4776635468006134]\n",
      "Epoch: 45: loss: [0.1586236208677292, 0.4682549238204956]\n",
      "Epoch: 46: loss: [0.16132298111915588, 0.47090548276901245]\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluator.run(train_dts, test_batch, data_stats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>The luminosity of first light bulb is now average</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>The luminosity of first light bulb is now high</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>The luminosity of first light bulb is now low</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>The luminosity of first light bulb is now very...</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>The luminosity of first light bulb is now very...</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>You decreased the luminosity of first light bulb</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>You increased the luminosity of first light bulb</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>You made the light of first light bulb colder</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>You made the light of first light bulb warmer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>You set the color of first light bulb to blue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>You set the color of first light bulb to green</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>You set the color of first light bulb to orange</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>You set the color of first light bulb to pink</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>You set the color of first light bulb to purple</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>You set the color of first light bulb to red</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>You set the color of first light bulb to yellow</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>You turned off the first light bulb</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>You turned off the first plug</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>You turned on the first light bulb</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>You turned on the first plug</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>model</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.251572</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  index  precision    recall  \\\n",
       "2079  The luminosity of first light bulb is now average   0.100000  0.666667   \n",
       "2080     The luminosity of first light bulb is now high   0.153846  1.000000   \n",
       "2081      The luminosity of first light bulb is now low   0.078947  1.000000   \n",
       "2082  The luminosity of first light bulb is now very...   0.291667  0.875000   \n",
       "2083  The luminosity of first light bulb is now very...   0.205128  1.000000   \n",
       "2084   You decreased the luminosity of first light bulb   0.333333  0.625000   \n",
       "2085   You increased the luminosity of first light bulb   0.740741  0.800000   \n",
       "2086      You made the light of first light bulb colder   0.000000  0.000000   \n",
       "2087      You made the light of first light bulb warmer   0.000000  0.000000   \n",
       "2088      You set the color of first light bulb to blue   0.000000  0.000000   \n",
       "2089     You set the color of first light bulb to green   0.100000  1.000000   \n",
       "2090    You set the color of first light bulb to orange   0.142857  0.500000   \n",
       "2091      You set the color of first light bulb to pink   0.357143  1.000000   \n",
       "2092    You set the color of first light bulb to purple   0.000000  0.000000   \n",
       "2093       You set the color of first light bulb to red   0.200000  1.000000   \n",
       "2094    You set the color of first light bulb to yellow   0.100000  1.000000   \n",
       "2095                You turned off the first light bulb   0.333333  0.818182   \n",
       "2096                      You turned off the first plug   0.000000  0.000000   \n",
       "2097                 You turned on the first light bulb   0.440000  0.733333   \n",
       "2098                       You turned on the first plug   0.000000  0.000000   \n",
       "2099                                              model   0.196078  0.350877   \n",
       "\n",
       "      f1_score  epoch  \n",
       "2079  0.173913     99  \n",
       "2080  0.266667     99  \n",
       "2081  0.146341     99  \n",
       "2082  0.437500     99  \n",
       "2083  0.340426     99  \n",
       "2084  0.434783     99  \n",
       "2085  0.769231     99  \n",
       "2086  0.000000     99  \n",
       "2087  0.000000     99  \n",
       "2088  0.000000     99  \n",
       "2089  0.181818     99  \n",
       "2090  0.222222     99  \n",
       "2091  0.526316     99  \n",
       "2092  0.000000     99  \n",
       "2093  0.333333     99  \n",
       "2094  0.181818     99  \n",
       "2095  0.473684     99  \n",
       "2096  0.000000     99  \n",
       "2097  0.550000     99  \n",
       "2098  0.000000     99  \n",
       "2099  0.251572     99  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0].tail(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>The luminosity of first light bulb is now average</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>The luminosity of first light bulb is now high</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>The luminosity of first light bulb is now low</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>The luminosity of first light bulb is now very...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>The luminosity of first light bulb is now very...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>You decreased the luminosity of first light bulb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>You increased the luminosity of first light bulb</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>You made the light of first light bulb colder</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>You made the light of first light bulb warmer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>You set the color of first light bulb to blue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>You set the color of first light bulb to green</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>You set the color of first light bulb to orange</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>You set the color of first light bulb to pink</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>You set the color of first light bulb to purple</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>You set the color of first light bulb to red</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>You set the color of first light bulb to yellow</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>You turned off the first light bulb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>You turned off the first plug</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>You turned on the first light bulb</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>You turned on the first plug</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>model</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  index  precision    recall  \\\n",
       "2079  The luminosity of first light bulb is now average   0.000000  0.000000   \n",
       "2080     The luminosity of first light bulb is now high   0.200000  0.500000   \n",
       "2081      The luminosity of first light bulb is now low   0.000000  0.000000   \n",
       "2082  The luminosity of first light bulb is now very...   0.666667  0.500000   \n",
       "2083  The luminosity of first light bulb is now very...   0.000000  0.000000   \n",
       "2084   You decreased the luminosity of first light bulb   0.000000  0.000000   \n",
       "2085   You increased the luminosity of first light bulb   1.000000  0.240000   \n",
       "2086      You made the light of first light bulb colder   0.000000  0.000000   \n",
       "2087      You made the light of first light bulb warmer   0.000000  0.000000   \n",
       "2088      You set the color of first light bulb to blue   0.000000  0.000000   \n",
       "2089     You set the color of first light bulb to green   0.125000  1.000000   \n",
       "2090    You set the color of first light bulb to orange   0.200000  0.500000   \n",
       "2091      You set the color of first light bulb to pink   0.000000  0.000000   \n",
       "2092    You set the color of first light bulb to purple   0.000000  0.000000   \n",
       "2093       You set the color of first light bulb to red   0.375000  1.000000   \n",
       "2094    You set the color of first light bulb to yellow   0.142857  1.000000   \n",
       "2095                You turned off the first light bulb   0.000000  0.000000   \n",
       "2096                      You turned off the first plug   0.000000  0.000000   \n",
       "2097                 You turned on the first light bulb   1.000000  0.133333   \n",
       "2098                       You turned on the first plug   0.000000  0.000000   \n",
       "2099                                              model   0.149254  0.087719   \n",
       "\n",
       "      f1_score  epoch  \n",
       "2079  0.000000     99  \n",
       "2080  0.285714     99  \n",
       "2081  0.000000     99  \n",
       "2082  0.571429     99  \n",
       "2083  0.000000     99  \n",
       "2084  0.000000     99  \n",
       "2085  0.387097     99  \n",
       "2086  0.000000     99  \n",
       "2087  0.000000     99  \n",
       "2088  0.000000     99  \n",
       "2089  0.222222     99  \n",
       "2090  0.285714     99  \n",
       "2091  0.000000     99  \n",
       "2092  0.000000     99  \n",
       "2093  0.545455     99  \n",
       "2094  0.250000     99  \n",
       "2095  0.000000     99  \n",
       "2096  0.000000     99  \n",
       "2097  0.235294     99  \n",
       "2098  0.000000     99  \n",
       "2099  0.110497     99  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[1].tail(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
